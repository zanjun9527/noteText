起步dubbo

1、<dubbo:protocol name="dubbo" port="20880"/> 使用dubbo在某端口暴露服务

2、缓存提供者的地址后，consumer调用provider是直接invoke调用的，不在经过zookeeper。
	消费者启动获得提供者地址后，可以不依赖zookkeper
	
3、	dubbo的三种运行方式：
	1、使用servlet容器运行   缺点：浪费资源，内存、端口和管理
	2、自建main方法运行
		context.start()
	3、dubbo框架提供的main方法运行 com.alibaba.dubbo.container.Main启动类
		这里需要包spring的配置文件打包到META-INF下，dubbo默认
	
linux强杀进程	kill -9 pid 
	
	在spring-context中<import resource="classpath:spring/spring-mybatis.xml">,只有两者在同级目录才能省略前缀目录
	，当道meta-inf下后需要加上前缀的目录
	maven配置的时候还是要加path的，不然不识别mvn命令
	
dubbo源码编译遇到的坑：
在cmd中使用mvn install 打包全部的工程
POM中的maven-plugin一定要带上版本号，
maven-resources-plugin-2.4.3.jar使用这个版本，2.6报错

更换jdk版本后的eclipse启动失败，在eclipse.ini加入
-vm
C:\Program Files\Java\jdk1.7.0_79\bin

jdk版本之间更换后instal失败：
Unsupported major.minor version 52.0（jdk8用的）  项目的库和java版本都要统一，最好使用一个版本的jdk，不要随意切换

win7系统编辑的文本内容，默认需要gbk编码，才能避免乱码

困扰好几天的dubbo的install问题，终于在StackOverflow 上找到了答案，<fork>false</fork> 很关键。很关键
<plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-compiler-plugin</artifactId>
                <configuration>
                    <fork>false</fork>
                    <source>${java_source_version}</source>
                    <target>${java_target_version}</target>
                    <encoding>${file_encoding}</encoding>
                </configuration>
            </plugin>
			

	mkdir -p 递归创建目录
	
2、mq中的相关观念
jms消息模型
 1、点对点模型，消息一次性消费
 
 2、发布者/订阅者模型
	
	

数据库建表的经验：
	1、统一把主键设置为bigint类型，int类型最大值才20亿左右
	2、tinyint 默认4，smallint 默认6，mediumint 默认9，int 默认11，bigint 默认20。一般使用默认，varchar需要按需设置显示长度
	3、整型数系统已经限制了取值范围，tinyint占1个字节、int占4个字节。
		所以整型数后面的m不是表示的数据长度，而是表示数据在显示时显示的最小长度。
		没有zerofill(长度不足就补零)，(m)就是无用的。
		总结：int(11)，tinyint(1)，bigint(20)，后面的数字，不代表占用空间容量。
			而代表最小显示位数。这个东西基本没有意义，除非你对字段指定zerofill。
	4、	字符类型若为gbk，每个字符最多占2个字节
		字符类型若为utf8，每个字符最多占3个字节



	dubbo的子服务的划分：
	1、a服务和b服务之间的库耦合，考虑以后的分库问题
	2、服务子系统避免出现环状调用，依赖的关系链不要过长 a\b\c
	3、尽量避免分布式事务
	
	dubbo接口的设计原则
	1、接口的粒度大点，通常是包含完成业务作为一个接口，减少系统之间的交互，dubbo暂未提供分布式事务支持。
	2、不建议使用过于抽象的通用接口，如map query（map），不便于后期的维护
	3、接口都应定义版本号，为后续的不兼容升级提供可能（暂不理解）
	4、必要的接口参数校验
	5、provider上尽量多配置consumer端属性，优先server端，比如超时时间，重试次数，并发数量
	
	dubbo的启动检查：
	1、<dubbo:consumer check="false">  关闭所有服务的启动时检查
	2、<dubbo:register check="false">	关闭注册中心启动时检查
	3、也可以单独关闭某个服务的检查
	4、	dubbo.reference.check=false，强制改变所有reference的check值，就算配置中有声明，也会被覆盖。
		dubbo.consumer.check=false，是设置check的缺省值，如果配置中有显式的声明，如：<dubbo:reference check="true"/>，不会受影响。
		dubbo.registry.check=false，前面两个都是指订阅成功，但提供者列表是否为空是否报错，如果注册订阅失败时，也允许启动，需使用此选项，将在后台定时重试
		
	eclipse中也可以安装相应的反编译插件
	dubbo的服务提供者有不同的调用策略，轮询等，类似nginx的负载均衡
	性能调优：
		1、linux用户线程数限制导致内存溢出
		2、尽量不要使用root用户来部署应用程序，避免资源耗尽后无法登陆操作系统
		3、普通用户的线程数限制值要看物理内存容量来配置
		
		
	第一本笔记本的相关内容：
		1、 request.getQueryString() 获取get请求，？后面的内容字符串
		2、window.onload=function()
		3、char长度固定，varchar长度可变
		4、sql中的concat时字符串的拼接
		5、<input type="button" value="" onclick="a()"/> 按钮点击js
			<input type="submit" value="" />
		6、父pom工程中一般定义jar的版本信息和maven插件的版本
		如果dependencies里的dependency自己没有声明version元素，那么maven就
		会倒dependencyManagement里面去找有没有对该artifactId和groupId进行过版本声明，如果有，就继承它，如果
		没有就会报错，告诉你必须为dependency声明一个version
		如果dependencies中的dependency声明了version，那么无论dependencyManagement中有无对该jar的version声明，都以dependency里的version为准。
		//只是对版本进行管理，不会实际引入jar  
		<dependencyManagement>  可以看到dependecies元素下的dependency里并没有声明版本，这是因为在manager中已经将版本管理起来了
		
		消费端，在dubbo配置reference时候，指定接口url="dubbo：//localhost：20818" 绕过zookeeper直连提供者（开发测试用）
		只订阅：register="false"     只注册：subscribe="false"



GRANT ALL PRIVILEGES ON *.* TO kaifa@"%" IDENTIFIED BY '123123'; 后面的数据库是要加密后存进mysql的

跳过权限登录linux的mysql
# mysqld_safe --user=mysql --skip-grant-tables --skip-networking &
# mysql -u root mysql
mysql> UPDATE user SET Password=PASSWORD('newpassword') where USER='root';
mysql> FLUSH PRIVILEGES;
mysql> quit



消息队列：
mq选型重点：存储 通讯
	mq：消息中间件 异步通讯
	rocketmq 分布式的消息队列
三个点：生产者:
		消费者： 
		消息存储与转发  broker :
		
		分布式系统:
			通讯协议: tcp/ip、http、
			数据传输: 序列化，
			分布式事务：
		
		2、通讯层的设计：rpc 自定义的协议请求头
		3、存储层设计：数据文件+索引文件
		刷盘方式  同步/异步刷盘
		pagecache  内存页  通过异步线程回写磁盘		
			三种发送消息的机制：1、同步发送 	返回消息发送成功
								2、异步发送 	有消息丢失的可能		
								3、oneway		kafak日志收集 肯定丢失
		
		broker设计，横向扩容两个，支持大数据量：
			topic 主题
			queue 队列
			topic中存在多个消息队列，有下标

生产者发送msg发送给namesrv（路由管理），namesrv通过broker存储转发消息到consumer集群，再消费给consumer	
重复消费可以在消费端控制


ln -s 源文件 目标文件。  linux中的软链接
mkdir -p	参数P代表parents，表示递归创建目录。

consumer需要配合listener订阅主题

业界比较广泛的分布式事务处理是两阶段提交   jta  xa  
网络传输问题  网络应答

ajax表单提价除了基础的js，还要引入form.js
$(...).ajaxsubmit() is not function，<script src="../jquery-easyui-1.3.1/jquery.form.js" type="text/javascript">
   
大事务=小事务+异步   可通过mq处理 

幂等性 去重处理即可，一般建议业务去重   
https://www.cnblogs.com/wxd0108/p/6038543.html

mq的部署问题：
	1、4.2.0需要jdk8，需要设置rocketmq_home 启动.cmd格式的就ok
	2、项目中netty-tcnative jar找不到，需要将maven的中无关修饰去掉
	3、启动broker   mqbroker -n localhost:9876 制定nameserver地址即可

mq视频教程：

好的讲解博客  https://www.jianshu.com/p/453c6e7ff81c

	1、放弃zookeeper，使用namerserver实现服务发现和路由
	2、pushconsumer是通过监听器获取消息，属于长连接，实时被动接受消息
	   pullconsumer是主动去获取信息，属于短连接，主动拉取消息
	3、广播消费：发送给组中的每一个consumer，即发送给订阅topic中的组的每个消费者
	   集群消费：订阅topic中的其中一个consumer组中的成员均分消息，自带多层次（组和组成员）负载均衡，一个topic/queue可以被多个组消费，组之间也是均分的，  
	4、2m模式，其中一台宕机，消费可能延迟。起不来就消费补了上次的信息，重点不是双m获得同样的信息，是分配的，
	   多m/s，异步复制 ，主从数据同步的方式：异步复制  m刷盘（未刷盘或尚未同步，m挂了，信息丢失），返回ack给客户端，同时异步复制到s上
	   多m/s，同步双写，写完m，刷盘，同步s成功后返回ack，数据不丢失，性能低，安全高
	5、默认一个topic下带4个队列，
	每个broker\consumer与nameserver集群中的每个节点建立长连接，定期从nameserver取topic路由信息，并向broker建立长连接，发送心跳
	6、默认的rocketmq的启动内存是4g，哈哈，在runserver和runbroker中修改参数，brokerid为0表示主节点
	7、mq核心的存储概念
		commitlog：消息体存放
		consumequeue：记录消息的位置
	8、输盘方式：同步异刷盘
	9、rockeqmq的producer三种方式：
		1、normalProducer
		2、orderProducer 搭配consumer的实现order监听，一般一轮顺序消费指定一个队列，同一消息下的指定队列
		3、transactionProducer（两阶段提交）
			第一阶段：将消息传递给mq，但是消费端不可见，但是数据已经发送到broker
			第二阶段是本地回调处理，成功返回commit_message，则再broker上对消费者可见，失败为rollback_message，消费端不可见
			
			producer端的关键配置： 	1、重试次数，生产端消息是不能少，
									2、也可以设置消息的maxsize 
									3、timeout
	10、顺序消费：针对同一队列中的顺序
		生产端是messagequeueselector，同时指定队列，消费端是注册监听，实现的接口是messagelilstenerorderly
		 
	注意思想，生产者的可靠性投递和消费者的幂等性去重
	11、事务消息机制，生产者发送消息到broker，暂不可见，本地事务ok后发送ack到broker，消息对消费者可见。发送ack失败，broker也有定时的回调检查。*******之后研究分布式事务再仔细看*******
	12、consumer		push模式建议单条消费    pull目前用的不多
	13、消息重试机制：
			生产者：消息重投重试，保证数据可靠
			***自定义属性，msg.putUserProperty("a","1")单独设置属性，传递后面是map形式,msg.getUserProperty("a")***
	
			
			消费者：消息异常处理，失败返回重试标记consumer_later，1s,5s,10s执行重试的策略
					同一个组中两个consumer，其中一个终端，没有返回ack和status，则重试另一个consumer，msg.getconsumertimes，获取重试次数，也可以获取上次的originid（第一次是null）
	14、*******消息幂等性处理*******：
			去重原则：1、幂等性 2业务去重
			去重策略：去重表机制（key去重，主键比如msgid），业务拼接去重策略（比如指纹码、唯一流水号等，联合索引）
			高并发下去重：redis去重（key天然支持原子性且要求不可重复），但是由于不在一个事务内，所以需要适当的补偿策略
							1、利用redis的事务、主键（我们必须把全量的操作数据，都存放到redis，然后定时和db同步）
							2、利用redis和关系型数据库  一起做去重机制
			不允许补偿（大额转账）
			
	15、消息模式：
	创建consumer的时候，指定同一groupname，即在同一组中
			集群模式：消息均摊，天然的负载均衡
			广播模式：全接收
			
	16、消息过滤：暂时了解
			1、简单是订阅使用tags过滤即可
			2、在broker端的机器，开启mqfiltersrv，自定义filter的java文件实现msssagefilter,实现match方法，mixall.file2String(),subscribe(a，b，c)即可，filter不允许有中文
	17、activemq是面向单机的，rocketmq是面向分布式的系统的	
	18、分布式事务，后者失败，前者需要做相应的补偿，适应事务较少的情况
		处理多个服务之间的一致性：
			1、创建不可见的订单，执行多个小事务，并且这些是同时监听一个回滚topic的，只要有一失败就发送消息到mq，其他的监听到并进行回滚操作
			2、需要执行另一个查询订单状态的任务，异常的全部取消
			
			
		在下单支付后，第三方有异步的回调操作，可以把回调结果发送给mq，解耦支付的业务耦合。
		消费者要去重和幂等处理，不仅仅以消息id区别，还可以在消息体中增加唯一业务编号
		对于失败的消息需要失败重试处理（失败次数），保证消息完全消费
		
		生产者的投递消息的可靠性：
			在发之前将mq消息持久化，发送成功后再删除，开启job定时扫描长时间存在的消息并重新发送
			
			
	cmd 下cd 是不能换盘符的，直接相应的盘就行了
	dependencymanagement 依赖管理
	在消费端：可以自定义listener实现源码中的messagelistenerconcurrently接口，在consumer端，监听消息的时候，可以定义一个接口，专门用于处理监听到的消息，这样可以解耦业务处理，这个思想不错
	在使用数据库的链接的时候，需要指定字符集为utf8
	
	rpc框架   client——server 需要使用统一的api接口
	
	@controller 加上responsebody 也可以实现http的请求，不推荐吧
	一般server端都是打成war，放在容器下运行，一般需要web.xml，这是常规的web项目的部署，springboot另说，这里使用jetty当作容器运行，简单的创建的jetty相关，启动了起来。
	使用简单的httpclient请求即可，这里使用Spring提供RestTemplate用于访问Rest服务的客户端实践
	但是者两个都不是最简洁的，最好的注入接口直接调用：
	使用工厂模式，，将工厂类加入容器，初始化就会返回的代理类添加到容器中，创建接口的代理类，将http的请求封装在代理方法中，使用代理类，这样实现了类似本地化的远程调用，前提是知道了访问的地址，路径默认是方法名
	则这样，调用接口，直接就能找到bean，是实现远程调用
	Spring 中有两种类型的Bean,一种是普通Bean,另一种是工厂Bean,即FactoryBean.
	工厂 Bean 跟普通Bean不同,其返回的对象不是指定类的一个实例,其返回的是该工厂Bean的getObject方法所返回的对象，加入spring容器即可，不同的api返回不同的工程对象
	在mq下 10-12rpc的简单封装
	
	使用mq解决数据一致性的问题还需要整理：
	1、检查校验
	2、创建不可见订单
	3、调用远程服务，扣优惠券，扣余额，如果调用成功——》更改订单状态可见，失败-》发送mq消息，进行取消订单
	
	
	1、具体的思路，本地的步骤1和2，全部写完，
	2、开始分步调用远程的服务，优惠券，成功了进行下一个，失败直接异常抛出
	3、扣余额，返回失败，异常抛出
	4、扣库存，返回失败，异常抛出
	5、try catch全部步骤，将相关的回退参数传过去，异常发送mq，每个server端监听，这里使用了topic和tag的监听
	6、全部成功，更改订单状态
	7、后续会有定时器轮询，长时间订单状态没改变的，有可能是mq发送失败，补发消息
	8、consumer端，最好的是使用统一的消息处理接口，重点重点重点：监听业务有没有操作记录，有记录回退，没有记录不用处理，即每个server都需要做相应的处理，处理逻辑看情况和操作日志来定
	9、消费端可以启动多个消费端，这样可以将处理的实现类，注入到通用的consumer配置中，实现，可配置处理
		每种类型的监听者都应该有自己的实现逻辑
		每个server端都有自己的consumer，
		增加统一的message处理接口，每个server端的consumer，都有自己的对应的接口实现，直接调用即可
		
		并发的where限制，并发查询都是ok的，但是有一条已经完成，所以必须加上where的条件限制
	
	关于mq的消费去重，可以增加mq消息去重表，groupname，tag ，key，msgid作为联合唯一键，用于并发时主键冲突，
	对于想要重试的消息，直接返回false即可，mq有重试的机制，一般超过3次人工处理
	

	防止并发，乐观锁的方式：即初始查询的某个数据为条件，再更新时需要保持一致，比如消费次数，更新的版本号
	
	只有runtimeexception，才能让spring自动回滚事务@transactional
	目前看service异常回滚了，controller还是能捕获的
	
	为了保证消息的可靠性，再关键重要的消息发送前，一定要有消息的备份，创建消息临时表
	再事务结束后想发mq消息，防止宕机的情况，两者又需要再统一事务中，这样可以创建消息临时表，后期job轮询发送，
	这样的好处是，可以确保，事务1和mq发送消息间接的事务一致性，只能说是一种思路吧
	为了加快发送的速度，可以使用线程池发送消息，excutorservice.submit(new runable(){}),发送成功，清楚临时表中的数据，主要就是保证mq发送消息的可靠性
	使用mq实现系统之间的通信，业务处理

关于复杂对象的相等和排序问题
	总结，自定义类要重写equals方法来进行等值比较，自定义类要重写compareTo方法来进行不同对象大小的比较，重写hashcode方法为了将数据存入HashSet/HashMap/Hashtable类时进行比较
	以维护 hashCode 方法的常规协定，该协定声明相等对象必须具有相等的哈希码。如下：
	(1)当obj1.equals(obj2)为true时，obj1.hashCode() == obj2.hashCode()必须为true 
	(2)当obj1.hashCode() == obj2.hashCode()为false时，obj1.equals(obj2)必须为false
	如果不重写equals，那么比较的将是对象的引用是否指向同一块内存地址，重写之后目的是为了比较两个对象的value值是否相等
	hashcode是用于散列数据的快速存取，如利用HashSet/HashMap/Hashtable类来存储数据时，都是根据存储对象的hashcode值来进行判断是否相同的。
	当原对象.equals（新对象）等于true时，两者的hashcode却是不一样的，由此将产生了理解的不一致，如在存储散列集合时（如Set类），将会存储了两个值一样的对象，
	导致混淆，因此，就也需要重写hashcode()
	即hashCode() 和equals()比较的是两个不同的内容
	
	总的来说，Java中的集合（Collection）有两类，一类是List，再有一类是Set。前者集合内的元素是有序的，元素可以重复；后者元素无序，但元素不可重复。那么这里就有一个比较严重的问题了：要想保证元素不重复，可两个元素是否重复应该依据什么来判断呢？
	这就是 Object.equals方法了。但是，如果每增加一个元素就检查一次，那么当元素很多时，后添加到集合中的元素比较的次数就非常多了。
	也就是说，如果集合中现在已经有1000个元素，那么第1001个元素加入集合时，它就要调用1000次equals方法。这显然会大大降低效率。
	于是，Java采用了哈希表的原理。哈希算法也称为散列算法，是将数据依特定算法直接指定到一个地址上。
	关于哈希算法，这里就不详细介绍。可以这样简单理解，hashCode方法实际上返回的就是对象存储位置的映像。
	这样一来，当集合要添加新的元素时，先调用这个元素的hashCode方法，就能定位到它应该放置的存储位置。如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了；
	如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就表示发生冲突了，散列表对于冲突有具体的解决办法，但最终还会将新元素保存在适当的位置。
	这样一来，实际调用equals方法的次数就大大降低了，几乎只需要一两次。
	
	为什么必须要重写hashcode方法，其实简单的说就是为了保证同一个对象，保证在equals相同的情况下hashcode值必定相同，
	如果重写了equals而未重写hashcode方法，可能就会出现两个没有关系的对象equals相同的（因为equal都是根据对象的特征进行重写的），但hashcode确实不相同的。
	
	HashMap对象的key、value值均可为null。
    HahTable对象的key、value值均不可为null。
	
	
	
timestamp和datetime：
只能表示从1970年到2038年的时间，而datetime不受此限制。
结论：永远使用datetime来表示时间，决不使用timestamp，除非每次更新都要更新的时间，才考虑使用timestamp


获取客户端的IP地址：
	代理服务器在转发请求的HTTP头信息中，增加了X-FORWARDED-FOR信息。用以跟踪原有的客户端 IP地址和原来客户端请求的服务器地址。
			String ip = request.getHeader("x-forwarded-for");
			if (StringUtils.isEmpty(ip) || IP_UNKNOWN.equalsIgnoreCase(ip))
			{
				ip = request.getHeader("Proxy-Client-IP");
			}
			if (StringUtils.isEmpty(ip) || IP_UNKNOWN.equalsIgnoreCase(ip))
			{
				ip = request.getHeader("WL-Proxy-Client-IP");
			}
			if (StringUtils.isEmpty(ip) || IP_UNKNOWN.equalsIgnoreCase(ip))
			{
				ip = request.getRemoteAddr();
			}
			return ip;
			
指定参数加上系统的key生成md5码，用户两个系统之间的校验
	
SpringMVC BindingResult验证框架Validation，一个paramdmo后面更一个BindingResult。aop相关

xml的解析文件，dom解析，也行吧
String.equalsIgnoreCase() 字符串忽略大小写的比较

BigDecimal.setScale()方法用于格式化小数点
log.info("add Backlog -> employeeId={}, backlogHead={}, scheduledDate={}", new Object[]{a, b, c});


Collections.sort 排序的使用    类的内部实现compare接口，或者外部使用比较器
List<String> keys = new ArrayList<String>(payParams.keySet());
Collections.sort(keys);//基本类型的直接排就行


在Linux下查看所有java进程命令：ps -ef | grep java
停止所有java进程命令：pkill - 9 java
停止特定java进程命令：kill -9 java进程序号


hashcode和equals方法的相关：
	equals 方法  原本是 == 比较两个对象的地址是否相等(即，是否是同一个对象)
	散列表，Java集合中本质是散列表的类，如HashMap，Hashtable，HashSet。
	hashCode() 在散列表中才有用，在其它情况下没用。在散列表中hashCode() 的作用是获取对象的散列码，进而确定该对象在散列表中的位置。
	由此可知，若两个元素相等，它们的散列码一定相等；但反过来确不一定。在散列表中，
	1、如果两个对象相等，那么它们的hashCode()值一定要相同；
	2、如果两个对象hashCode()相等，它们并不一定相等。

	在散列表中，重写equals方法，一定要重写hashcode方法
	hashmap的原理
	//判断当前确定的索引位置是否存在相同hashcode和相同key的元素，如果存在相同的hashcode和相同的key的元素，那么新值覆盖原来的旧值，并返回旧值。  
	//如果存在相同的hashcode，那么他们确定的索引位置就相同，这时判断他们的key是否相同，如果不相同，这时就是产生了hash冲突。  
	//Hash冲突后，那么HashMap的单个bucket里存储的不是一个 Entry，而是一个 Entry 链。  
	//系统只能必须按顺序遍历每个 Entry，直到找到想搜索的 Entry 为止——如果恰好要搜索的 Entry 位于该 Entry 链的最末端（该 Entry 是最早放入该 bucket 中），  
	//那系统必须循环到最后才能找到该元素。

	总结就是更具key的hash值确定tables中的存储位置，一般是单槽存放entry，hash冲突时，就是一个entry链，key相同覆盖，不同链表。取的时候遍历获取
	hashset中的必须满足hashcode和equals方法一样，才算重复
	hashmap的底层结构:Entry数组 + 链表
	
mysql:统计查询出现次数大于2的记录
	查询某字段大于2的记录统计
	   SELECT COUNT(ue.User_Id) AS 抬头数量 ,ue.user_id,ub.user_name AS 实名 
		FROM user_enter_vali_log ue ,user_base_info ub  
		WHERE ue.Delete_Mark = 0
		AND ue.User_Id = ub.id
		AND ub.Individual_Type='2'
		GROUP BY ue.User_Id HAVING COUNT(ue.User_Id)>1
	
	外部键约束，再删除外键相关记录时，主表如果有相关的引用，是会报错，即操作的数据，如果作为外键被其他表引用，是可能错误的。一般不用，烦不烦，约束来约束去的
	
	InstantiationException，实例化异常，缺少无参构造，
	一般场景newInstance()方法创建某个类的实例，而该类是一个抽象类或接口时，抛出该异常，或者在orm框架中实现对象的映射，缺少无参构造也会异常

	因为iBATIS在对象建立中，会使用不带参数的构造函数来建立对象，
	在Hibernate中就有明确的要求：每一个持久化类都必须带一个不带参数的构造方法
	
	查询自增的返回SELECT table_name,AUTO_INCREMENT FROM information_schema.tables WHERE table_schema="db_xiaoyuer"  
	
	重要提示信息// TODO info 标注起来,也算小技巧吧
	EXPLAIN sql
	D:\alibaba-rocketmq-3.2.6\alibaba-rocketmq\bin\mqbroker.exe -n 192.168.6.222:9876  直接编程bat的文件内容
	
	String getServerName()：获取服务器名，localhost；
	String getServerPort()：获取服务器端口号，8080；
	String getContextPath()：获取项目名，/Example；
	String getServletPath()：获取Servlet路径，/AServlet；
	String getQueryString()：获取参数部分，即问号后面的部分：username=zhangsan
	String getRequestURI()：获取请求URI，等于项目名+Servlet路径：/Example/AServlet
	String getRequestURL()：获取请求URL，等于不包含参数的整个请求路径：http://localhost:8080/Example/AServlet 。
	
	springboot会自动加载启动类所在包,及其同级包及其子包下的所有组件。
	
	tomcat 和nginx的ssl相同吗，不一样，nginx使用的是，wohaha.crt，nihaha.key;使用openssl创建吧应该，
	tomcat中的使用jdk自带的keystool工具生成
	
	在filter中，response.getWriter().print()后,chain.do()到controller后，继续，
	也可以继续response.getWriter().print()，但是不能通过view层直接返回字符串信息
	
	关键点就是用jar包起就可以实现优雅停机，前提是不用内嵌tomcat起
	kill -9 就是直接终止
	kill pid就是优雅停机
	
	cherry pick 的挑选分支commit，需要同源挑选，不然会出现冲突

