18页

JDK，Java标准开发包，包括Java编译器、Java运行时环境，以及常用的Java类库等 
JRE，Java运行环境，用于运行Java的字节码文件。
JVM，Java虚拟机，是JRE的一部分，跨平台，负责运行字节码文件。

如果我们要开发Java程序，那就需要JDK，因为要编译Java源文件。 
如果我们只想运行已经编译好的Java字节码文件，也就是*.class文件，那么就只需要JRE。 
JDK中包含了JRE，JRE中包含了JVM。


String是不可变的，如果尝试去修改，会新生成一个字符串对象，如String类，虽然是引用类型
StringBuffer和StringBuilder是可变的
StringBuffer是线程安全的，StringBuilder是线程不安全的，所以在单线程环境下StringBuilder效 率会更高

List：有序，按对象插⼊的顺序保存对象，可重复，允许多个Null元素对象

每个Segment相对于一个小型的HashMap
每个Segment内部会进行扩容，和HashMap的扩容逻辑类似

扩容的判断也是每个Segment内部单独判断的，判断是否超过阈值

1.7到1.8 hashmap的变化
	1.7中底层是数组+链表，1.8中底层是数组+链表+红黑树，加红黑树的目的是提高HashMap插入和查询整体效率
	2. 1.7中链表插入使用的是头插法，1.8中链表插入使用的是尾插法，因为1.8中插入key和value时需要判断链表元素个数，所以需要遍历链表统计链表元素个数，所以正好就直接使⽤尾插法
	3. 1.7中哈希算法比较复杂，存在各种右移与异或运算，1.8中进行了简化，因为复杂的哈希算法的目的就是提高散列性，来提供HashMap的整体效率，1.8中新增了红黑树，所以可以适当的简化哈希算法，节省CPU资源

堆区和方法区是所有线程共享的，栈、本地⽅法栈、程序计数器是每个线程独有的

jvm问题排查，
	对于还在正常运⾏的系统：
	1. 可以使用jmap来查看JVM中各个区域的使用情况
	2. 可以通过jstack来查看线程的运⾏情况，如哪些线程阻塞、是否出现了死锁
	3. 可以通过jstat命令来查看垃圾回收的情况，特别是fullgc，如果发现fullgc⽐较频繁，那么就得进行调优了
	4. 通过各个命令的结果，或者jvisualvm等工具具来进行分析
	5. 首先，初步猜测频繁发送fullgc的原因，如果频繁发生fullgc但是又一直没有出现内存溢出，那么表示fullgc实际上是回收了很多对象了，所以这些对象最好能在younggc过程中就直接回收掉，避免这
	些对象进⼊入到老年代，对于这种情况，就要考虑这些存活时间不长的对象是不是比较大，导致年轻代放不下，直接进到了老年代，尝试加大年轻代的大小，如果改完之后，fullgc减少，则证明修改有效
	6. 同时，还可以找到占CPU最多的线程，定位到具体的法，优化这个方法的执行，看是否能避免某些对象的创建，从而节省内存

	对于已经发⽣了OOM的系统：
	1. 一般生产系统中都会设置当系统发生了OOM时，生成当时的dump文件（-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/usr/local/base）
	2. 我们可以利⽤jsisualvm等工具来分析dump文件
	3. 根据dump文件找到异常的实例对象，和异常的线程（占用CPU高），定位到具体的代码
	4. 然后再进⾏详细的分析和调试
	总之，调优需要分析、推理、实践、总结、再分析，最终定位到具体的问题
	
对象从加载jvm到清除的过程(忽略)
先把字节码文件内容加载到方法区
2. 然后再根据类信息在堆区创建对象
3. 对象先会分配在堆区中年轻代的Eden区，经过1次Minor GC后，对象如果存活，就会进Suvivor区。在后续的每次Minor GC中，如果对象一直存活，就会在Suvivor区来回拷贝，每移动1次，年龄加1
4. 当年龄超过15后，对象依然存活，对象就会进老年代
5. 如果经过Full GC，被标记为垃圾对象，那么就会被GC线程清理掉


JVM参数⼤致可以分为三类：
1. 标注指令： -开头，这些是所有的HotSpot都⽀持的参数。可以用java -help 打印出来。
2. 非标准指令： -X开头，这些指令通常是跟特定的HotSpot版本对应的。可以用java -X 打印出来。
3. 不稳定参数： -XX 开头，这类参数是跟特定HotSpot版本对应的，并且变化非常大

用完回收的问题
如果在线程池中使⽤ThreadLocal会造成内存泄漏，因为当ThreadLocal对象使⽤完之后，应该要把
设置的key，value，也就是Entry对象进⾏回收，但线程池中的线程不会回收，⽽线程对象是通过强
引⽤指向ThreadLocalMap，ThreadLocalMap也是通过强引⽤指向Entry对象，线程不被回收，
Entry对象也就不会被回收，从⽽出现内存泄漏，解决办法是，在使⽤了ThreadLocal对象之后，⼿
动调⽤ThreadLocal的remove⽅法，⼿动清楚Entry对象

死锁主要就是环形等待
在开发过程中：
1. 要注意加锁顺序，保证每个线程按同样的顺序加锁
2. 要注意加锁时限，可以针对所设置一个超时时间
3. 要注意死锁检查，这是⼀种预防机制，确保在第⼀时间发现死锁并进⾏解决

当线程池中的线程数量大于 corePoolSize时，如果某线程空闲时间超过keepAliveTime，线程将被终止。这样，线程池可以动态的调整池中的线程数

lock()方法法加锁时
不管是公平锁还是非公平锁，一旦没竞争到锁，都会排队，当锁释放时，都是唤醒排在最前面的线程，所以非公平锁只是体现在了线程加锁阶段，没有体现在线程被唤醒阶段。

CountDownLatch
对应的底层原理就是，调⽤await()⽅法的线程会利⽤AQS排队，⼀旦数字被减为0，则会将AQS中
排队的线程依次唤醒。

如果没有许可可⽤则线程阻塞，并通过AQS来排队，可以通过release(),方法来释放许可，当某个线程释放了某个许可后，会从AQS中正在排队的第⼀个线程开始依次唤
醒，直到没有空闲许可

偏向锁：在锁对象的对象头中记录⼀下当前获取到该锁的线程ID，该线程下次如果又来获取该锁就可以直接获取到了
自旋锁是线程通过CAS获取预期的一个标记，如果没有获取到，则继续循环获取，如果获取到了则表示获取到了锁，这个过程线程一直在运行中，没有使用太多的操作系统资源，比较轻量。


1. sychronized是个关键字，ReentrantLock是个类
2. sychronized会自动的加锁与释放锁，ReentrantLock需要程序员⼿动加锁与释放锁
3. sychronized的底层是JVM层⾯的锁，ReentrantLock是API层⾯的锁
4. sychronized是非公平锁，ReentrantLock可以选择公平锁或非公平锁
5. sychronized锁的是对象，锁信息保存在对象头中，ReentrantLock通过代码中int类型的state标识来标识锁的状态
6. sychronized底层有个锁升级的过程

spring事务失效的问题
方法不是public的：@Transactional 只能用于 public 的方法上，否则事务不会失效，如果要用在非public方法上，可以开启 AspectJ 代理模式

同时如果某个方法是private的，那么@Transactional也会失效，因为底层cglib是基于父子类来实现
的，子类是不能重载父类的private方法的，所以无法很好的利用代理，也会导致@Transactianal失效


bean的生命周期？
初始化前，处理@PostConstruct注解
初始化，处理InitializingBean接⼝
初始化后，进行AOP

但是ApplicationContext除开继承了BeanFactory之外，还继承了诸如
EnvironmentCapable、MessageSource、ApplicationEventPublisher等接⼝，从⽽
ApplicationContext还有获取系统环境变量、国际化、事件发布等功能，这是BeanFactory所不具备的


spring代理事务的时候，
Spring事务的隔离级别对应的就是数据库的隔离级别
10. Spring事务的传播机制是Spring事务自己实现的，也是Spring事务中最复杂的
11. Spring事务的传播机制是基于数据库连接来做的，一个数据库连接一个事务，如果传播机制配置为
需要新开一个事务，那么实际上就是先建立一个数据库连接，在此新数据库连接上执行sql


在源码中会更复杂，如源码中会提供一些模板方法，让子类来实现，如源码中还涉及到一些
BeanFactoryPostProcessor和BeanPostProcessor的注册，Spring的扫描就是通过
BenaFactoryPostProcessor来实现的，依赖注入就是通过BeanPostProcessor来实现的


@SpringBootApplication注解：这个注解标识了⼀个SpringBoot⼯程，它实际上是另外三个注解的
组合，这三个注解是：
Spring⽤到了哪些设计模式
Spring Boot中常⽤注解及其底层实现
27
a. @SpringBootConfiguration：这个注解实际就是⼀个@Configuration，表示启动类也是⼀个配置类
b. @EnableAutoConfiguration：向Spring容器中导⼊了⼀个Selector，⽤来加载ClassPath下SpringFactories中所定义的⾃动配置类，将这些⾃动加载为配置Bean
c. @ComponentScan：标识扫描路径，因为默认是没有配置实际扫描路径，所以SpringBoot扫描的路径是启动类所在的当前⽬录

#{}是预编译处理、是占位符， ${}是字符串替换、是拼接符

Mybatis在处理#{}时，会将sql中的#{}替换为?号，调⽤ PreparedStatement 来赋值；
Mybatis在处理${}时，会将sql中的${}替换成变量的值，调⽤ Statement 来赋值；

索引覆盖
所需要的字段都在当前索引的叶子节点上存在，可以直接作为结果返回了

B树的特点：
1. 节点排序
2. ⼀个节点了可以存多个元素，多个元素也排序了
B+树的特点：
1. 拥有B树的特点
2. 叶⼦节点之间有指针
3. ⾮叶⼦节点上的元素在叶⼦节点上都冗余了，也就是叶⼦节点中存储了所有的元素，并且排好顺序
Mysql索引使⽤的是B+树，因为索引是⽤来加快查询的，⽽B+树通过对数据进⾏排序所以是可以提⾼查
询速度的，然后通过⼀个节点中可以存储多个元素，从⽽可以使得B+树的⾼度不会太⾼，在Mysql中⼀
个Innodb⻚就是⼀个B+树节点，⼀个Innodb⻚默认16kb，所以⼀般情况下⼀颗两层的B+树可以存2000
万⾏左右的数据，然后通过利⽤B+树叶⼦节点存储了所有数据并且进⾏了排序，并且叶⼦节点之间有指
针，可以很好的⽀持全表扫描，范围查找等SQL语句

共享锁：也就是读锁，⼀个事务给某⾏数据加了读锁，其他事务也可以读，但是不能写
2. 排它锁：也就是写锁，⼀个事务给某⾏数据加了写锁，其他事务不能读，也不能写


RDB：Redis DataBase，在指定的时间间隔内将内存中的数据集快照写⼊磁盘，实际操作过程是fork一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的⽂件，用二进制压缩存储。
性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是 IO 最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis 的⾼性能

整个Redis数据库将只包含一个文件 dump.rdb，方便持久化

通过 append 模式写文件，即使中途服务器宕机也不会破坏已经存在的内容，可以通过 redis-check-aof 工具解决数据一致性问题。

AOF文件比RDB更新频率搞，优先使用AOF还原数据，AOF比RDB更安全也更大，RDB性能比AOF好，如果两个都配了优先加载AOF

一般通过bgsave命令，fork出⼀一个子进程执行持久化，主进程只在fork过程中有短暂的阻塞，子进程创建之后，主进程就可以响应客户端请求了。save命令会阻塞redis，不用


redis主从复制

主从同步：全量同步时会自动触发bgsave命令，生成rdb发送给从节点

全量复制：
1. 主节点通过bgsave命令fork⼦进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的
2. 主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗
3. 从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗

数据安全性低。RDB 是间隔⼀段时间进⾏持久化，如果持久化之间 redis 发⽣故障，会发⽣数据丢
失。所以这种⽅式更适合数据要求不严谨的时候)
2. 由于RDB是通过fork⼦进程来协助完成数据持久化⼯作的，因此，如果当数据集较⼤时，可能会导
致整个服务器停⽌服务⼏百毫秒，甚⾄是1秒钟。会占⽤cpu


1. 所有的写命令会追加到 AOF 缓冲中。
2. AOF 缓冲区根据对应的策略向硬盘进⾏同步操作。
3. 随着 AOF ⽂件越来越⼤，需要定期对 AOF ⽂件进⾏重写，达到压缩的⽬的。
4. 当 Redis 重启时，可以加载 AOF ⽂件进⾏数据恢复


分布式锁
同时还要考虑到redis节点挂掉后的情况，所以需要采用红锁的方式来同时向N/2+1个节点申请锁，都申请到了才证明获取锁成功，这样就算其中某个redis节点挂掉了，锁也不能被其他客户端获取到


Redis锁核心是Redis，可任务服务都有挂掉的风险，Redis也不例外，一旦Redis挂了，Redis锁就无法正常使用了，为了解决这个弊端，所以出现红锁
红锁的原理
红锁本质上就是使用多个Redis做锁。例如有5个Redis，一次锁的获取，会对每个请求都获取一遍，如果获取锁成功的数量超过一半(2.5)，则获取锁成功，反之失败；
释放锁也需要对每个Redis释放




Redis的主从复制是提高Redis的可靠性的有效措施，主从复制的流程如下：
1. 集群启动时，主从库间会先建立连接，为全量复制做准备
2. 主库将所有数据同步给从库。从库收到数据后，在本地完成数据加载，这个过程依赖于内存快照RDB
3. 在主库将数据同步给从库的过程中，主库不会阻塞，仍然可以正常接收请求。否则，redis的服务就被中断了。但是，这些请求中的写操作并没有记录到刚刚生成的RDB文件中。为了保证主从库的数据一致性，主库会在内存中用专门的replication buffer，记录RDB文件生成收到的所有写操作。
4. 最后，也就是第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体的操作是，当主库完成RDB文件发送后，就会把此时replocation buffer中修改操作发送给从库，从库再执⾏这些操作。这样，主从库就实现同步了
5. 后续主库和从库都可以处理客户端读操作，写操作只能交给主库处理，主库接收到写操作后，还会将写操作发送给从库，实现增量同步


Redis提供了三种集群策略：
1. 主从模式：这种模式较简单，主库可以读写，并且会和从库进行数据同步，这种模式下，客户端直接连主库或某个从库，
但是但主库或从库宕机后，客户端需要手动修改IP，另外，这种模式也较难进行扩容，整个集群所能存储的数据受到某台机器的内存容量，所以不可能支持特大数据量

2. 哨兵模式：这种模式在主从的基础上新增了哨兵节点，但主库节点宕机后，哨兵会发现主库节点宕机，然后在从库中选择一个库作为进的主库，另外哨兵也可以做集群，从而可以保证但某一个哨兵
节点宕机后，还有其他哨兵节点可以继续工作，这种模式可以较好的保证Redis集群的高可用，但是仍然不能很好的解决Redis的容量上限问题。

3. Cluster模式：Cluster模式是用得较多的模式，它支持多主多从，这种模式会按照key进行槽位的分配，可以使得不同的key分散到不同的主节点上，利用这种模式可以使得整个集群支持更大的数据
容量，同时每个主节点可以拥有自己的多个从节点，如果该主节点宕机，会从它的从节点中选举一个新的主节点。

对于这三种模式，如果Redis要存的数据量不大，可以选择哨兵模式，如果Redis要存的数据量大，并且需要持续的扩容，那么选择Cluster模式


缓存雪崩
解决办法就是在过期时间上增加⼀点随机值，另外如果搭建⼀个⾼可⽤的Redis集群也是防⽌缓
存雪崩的有效手段

缓存数据的过期时间设置随机，防⽌同⼀时间⼤量数据过期现象发⽣。
给每⼀个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓
存。
缓存预热互斥锁



缓存击穿
是指某一个热点key突然失效，也导致了大量请求直接访问Mysql数据库，这就是缓存击穿，解决⽅案就是考虑这个热点key不设过期时间




是指缓存中没有但数据库中有的数据（⼀般是缓存时间到期），这时由于并发⽤户特别多，同
时读缓存没读到数据，⼜同时去数据库去取数据，引起数据库压⼒瞬间增⼤，造成过⼤压⼒。和缓存雪
崩不同的是，缓存击穿指并发查同⼀条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从⽽
查 数据库。


设置热点数据永远不过期。加互斥锁



缓存穿透
假如某时刻访问redis的大量key都在redis中不存在（⽐如⿊客故意伪造⼀些乱七⼋糟
的key），那么也会给数据造成压力，这就是缓存穿透，解决⽅案是使⽤布隆过滤器，它的作⽤就是
如果它认为某个key不存在，那么这个key就肯定不存在，所以可以在缓存之前加一层布隆过滤器来拦截不存在的key

指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承
受⼤量请求⽽崩掉

解决⽅案：
接⼝层增加校验，如⽤户鉴权校验，id做基础校验，id<=0的直接拦截；
从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有
效时间可以设置短点，如30秒（设置太⻓会导致正常情况也没法使⽤）。这样可以防⽌攻击⽤户
反复用同一个id暴力攻击
采⽤布隆过滤器，将所有可能存在的数据哈希到⼀个⾜够⼤的 bitmap 中，⼀个⼀定不存在的数据
会被这个 bitmap 拦截掉，从⽽避免了对底层存储系统的查询压⼒


Redis和Mysql如何保证数据一致

延时双删，步骤是：先删除Redis缓存数据，再更新Mysql，延迟几百毫秒再删除Redis缓存数据，这样就算在更新Mysql时，有其他线程读了Mysql，把老数据读到了Redis中，那么也会被删除掉，从而把数据保持一致

删redis-正更新数据库，这个期间会有其他线程读取旧的数据去填入redis，这里会有问题



redis快
它采用IO多路复用机制来同时监听多个Socket，根据Socket上的事件类型来选择对应的事件处理器来处理这个事件。
1. 纯内存操作
2. 核心是基于非阻塞的IO多路复用机制
3. 单线程反⽽避免了多线程的频繁上下文切换带来的性能问题


分区容错性表示，⼀个系统虽然是分布式的，但是对外看上去应该是⼀个整体，不能由于分布式系统内
部的某个结点挂点，或⽹络出现了故障，⽽导致系统对外出现异常。所以，对于分布式系统⽽⾔是⼀定
要保证分区容错性的。



强⼀致性表示，⼀个分布式系统中各个结点之间能及时的同步数据，在数据同步过程中，是不能对外提
供服务的，不然就会造成数据不⼀致，所以强⼀致性和可⽤性是不能同时满⾜的

可⽤性表示，⼀个分布式系统对外要保证可⽤。


表示最终一致性，不要求分布式系统数据实时达到⼀致，允许在经过一段时间后再达到一致，在达到一致过程中，系统也是可用的

rpc和http
，RPC表示的是⼀种调⽤远程⽅法的⽅式，可以使⽤HTTP协议、或直接基于TCP
协议来实现RPC，在Java中，我们可以通过直接使⽤某个服务接⼝的代理对象来执⾏⽅法，⽽底层则通
过构造HTTP请求来调⽤远端的⽅法，所以，有⼀种说法是RPC协议是HTTP协议之上的⼀种协议，也是
可以理解的。


如果是单体架构，我们可以通过数据库的主键，或
直接在内存中维护⼀个⾃增数字来作为ID都是可以的，但对于⼀个分布式系统，就会有可能会出现ID冲
突，此时有以下解决⽅案：
1. uuid，这种方案复杂度最低，但是会影响存储空间和性能
2. 利用单机数据库的⾃增主键，作为分布式ID的生成器，复杂度适中，ID⻓度较之uuid更短，但是受到单机数据库性能的限制，并发量大的时候，此方案也不是最优方案
3. 利⽤redis、zookeeper的特性来⽣成id，⽐如redis的自增命令、zookeeper的顺序节点，这种方案
和单机数据库(mysql)相比，性能有所提高，可以适当选用
4. 雪花算法，利⽤雪花算法也可以生成分布式ID，底层原理就是通过某台机器在某一毫秒内对某一个数字自增，这种方案也能保证分布式架构中
的系统id唯一，但是只能保证趋势递增。业界存在tinyid、leaf等开源中间件实现了雪花算法


1.zookeeper：利⽤的是zookeeper的临时节点、顺序节点、watch机制来实现的，zookeeper分布式
锁的特点是高一致性，因为zookeeper保证的是CP，所以由它实现的分布式锁更可靠，不会出现混乱
2. redis：利⽤redis的setnx、lua脚本、消费订阅等机制来实现的，redis分布式锁的特点是高可用，
因为redis保证的是AP，所以由它实现的分布式锁可能不可靠，不稳定（一旦redis中的数据出现了不一致），可能会出现多个客户端同时加到锁的情况


mq的事务消息

常见分布式事务解决方案有：
1. 本地消息表：创建订单时，将减库存消息加⼊在本地事务中，一起提交到数据库存入本地消息表，
然后调用库存系统，如果调用成功则修改本地消息状态为成功，如果调用库存系统失败，则由后台
定时任务从本地消息表中取出未成功的消息，重试调用库存系统

2. 消息队列：目前RocketMQ中支持事务消息，它的工作原理是：
	a. 生产者订单系统先发送一条half消息到Broker，half消息对消费者是不可见的
	b. 再创建订单，根据创建订单成功与否，向Broker发送commit或rollback
	c. 并且生产者订单系统还可以提供Broker回调接口，当Broker发现一段时间half消息没有收到任何操作命令，则会主动调此接口来查询订单是否创建成功
	d. 一旦half消息commit了，消费者库存系统就会来消费，如果消费成功，则消息销毁，分布式事务成功结束
	e. 如果消费失败，则根据重试策略进行重试，最后还失败则进入死信队列，等待进一步处理

3. Seata：阿里开源的分布式事务框架，支持AT、TCC等多种模式，底层都是基于两阶段提交理论来实现的



ZAB协议是Zookeeper用来实现一致性的原子广播协议，该协议描述了Zookeeper是如何实现一致性的，分为三个阶段：
1. 领导者选举阶段：从Zookeeper集群中选出一个节点作为Leader，所有的写请求都会由Leader节点来处理
2. 数据同步阶段：集群中所有节点中的数据要和Leader节点保持⼀致，如果不一致则要进行同步
3. 请求广播阶段：当Leader节点接收到写请求时，会利用两阶段提交来广播该写请求，使得写请求像事务一样在其他节点上执行，达到节点上的数据实时一致
但值得注意的是，Zookeeper只是尽量的在达到强一致性，实际上仍然只是最终⼀致性的。


可以利用Zookeeper的临时节点和watch机制来实现注册中心的自动注册和发现，另外Zookeeper中的
数据都是存在内存中的，并且Zookeeper底层采⽤了nio，多线程模型，所以Zookeeper的性能也是比较
高的，所以可以⽤来作为注册中心，
但是如果考虑到注册中心应该是注册可用性的话，那么Zookeeper
则不太合适，因为Zookeeper是CP的，它注重的是一致性，所以集群数据不一致时，集群将不可用，所以Redis、Eureka、Nacos来作为注册中心将更合适。


Zookeeper集群中节点之间数据是如何同步的(忽略)
采用发送快照和发送Diff日志的方式
通过同步机制和两阶段提交机制来达到集群中节点数据一致

dubbo消费者
根据查询得到的服务提供者信息生成一个服务接口的代理对象，并放在Spring容器中作为Bean

dubbo的一些模块层次
config配置层 ServiceConfig , ReferenceConfig


唯一id。每次操作，都根据操作和内容⽣成唯⼀的id，在执⾏之前先判断id是否存在，如果不存在则执行后续操作，并且保存到数据库或者redis等。

服务端提供发送token的接口，业务调用接⼝前先获取token,然后调⽤业务接⼝请求时，把token携
带过去,务器判断token是否存在redis中，存在表示第一次请求，可以继续执行业务，执行业务完成后，最后需要把redis中的token删除

建去重表。将业务中有唯一标识的字段保存到去重表，如果表中存在，则表示已经处理过了
版本控制。增加版本号，当版本号符合时，才能更新数据
状态控制。例如订单有状态已⽀付 未支付 支付中 支付失败，当处于未支付的时候才允许修改为支付中等


Zookeeper中的watch机制(忽略)
客户端，可以通过在znode上设置watch，实现实时监听znode的变化
Watch事件是一个一次性的触发器，当被设置了Watch的数据发生了改变的时候，则服务器将这个改变发送给设置了Watch的客户端


Zookeeper和Eureka的区别
zk：CP设计(强一致性)，目标是一个分布式的协调系统，用于进行资源的统一管理。
当节点crash后，需要进行leader的选举，在这个期间内，zk服务是不可用的。

eureka：AP设计（高可用），目标是一个服务注册发现系统，专门用于微服务的服务发现注册。
Eureka各个节点都是平等的，几个节点挂掉不会影响正常节点的工作，剩余的节点依然可以提供注册和
查询服务。⽽Eureka的客户端在向某个Eureka注册时如果发现连接失败，会自动切换至其他节点，只要
有一台Eureka还在，就能保证注册服务可用（保证可用性），只不过查到的信息可能不是最新的（不保证强一致性）
同时当eureka的服务端发现85%以上的服务都没有心跳的话，它就会认为自己的网络出了问题，就不会
从服务列表中删除这些失去心跳的服务，同时eureka的客户端也会缓存服务信息。eureka对于服务注册
发现来说是非常好的选择。


存储拆分后如何解决唯一主键问题

UUID：简单、性能好，没有顺序，没有业务含义，存在泄漏mac地址的⻛险
数据库主键：实现简单，单调递增，具有一定的业务可读性，强依赖db、存在性能瓶颈，存在暴露业务 信息的风险
redis，mongodb，zk等中间件：增加了系统的复杂度和稳定性
雪花算法


映射：将查询条件的字段与分区键进行映射，建⼀张单独的表维护(使用覆盖索引)或者在缓存中维护
冗余：查询字段冗余存储

cloud组件
1.Eureka：注册中心
2. Nacos：注册中心、配置中心
3. Consul：注册中心、配置中心
4. Spring Cloud Config：配置中心
5. Feign/OpenFeign：RPC调用
6. Kong：服务网关
7. Zuul：服务网关
8. Spring Cloud Gateway：服务⽹关
9. Ribbon：负载均衡
10. Spring CLoud Sleuth：链路追踪
11. Zipkin：链路追踪
12. Seata：分布式事务
13. Dubbo：RPC调用
14. Sentinel：服务熔断
15. Hystrix：服务熔断






服务雪崩，解决⽅式就是服务降级和服务熔断

服务限流是指在⾼并发请求下，为了保护系统，可以对访问服务的请求进⾏数量上的限制，从⽽防
⽌系统不被⼤量请求压垮，在秒杀中，限流是⾮常重要的

服务熔断是指，当服务A调用的某个服务B不可用时，上游服务A为了保证自己不受影响，从而不再
调用服务B，直接返回一个结果，减轻服务A和服务B的压力，直到服务B恢复

服务降级是指，当发现系统压力过载时，可以通过关闭某个服务，或限流某个服务来减轻系统压
力，这就是服务降级。


熔断 降级
都是为了防⽌系统崩溃
2. 都让用户体验到某些功能暂时不用
不同点：熔断是下游服务故障触发的，降级是为了降低系统负载


为什么RocketMQ不使⽤Zookeeper作为注册中心 (忽略)
zookeeper满足的是CP，也就是说zookeeper并不能保证
服务的可用性，zookeeper在进行选举的时候，整个选举的时间太长，期间整个集群都处于不可用的状
态，这对于一个注册中心来说肯定是不能接受的，作为服务发现来说就应该是为可用性而设计

基于性能的考虑，NameServer本身的实现⾮常轻量，⽽且可以通过增加机器的⽅式⽔平扩展，增加集
群的抗压能⼒，⽽zookeeper的写是不可扩展的，⽽zookeeper要解决这个问题只能通过划分领域，划

分多个zookeeper集群来解决，首先操作起来太复杂，其次这样还是违反了CAP中的A的设计，导致服务之间是不连通的。
持久化的机制来带的问题，ZooKeeper 的 ZAB 协议对每一个写请求，会在每个 ZooKeeper 节点上保
持写一个事务日志，同时再加上定期的将内存数据镜像（Snapshot）到磁盘来保证数据的一致性和持久
性，对于一个简单的服务发现的场景来说，这其实没有太大的必要，这个实现方案太重了。且本身
存储的数据应该是高度定制化的。

消息发送应该弱依赖注册中心，⽽RocketMQ的设计理念也正是基于此，生产者在第一次发送消息的时
候从NameServer获取到Broker地址后缓存到本地，如果NameServer整个集群不可用，短时间内对于生
产者和消费者并不会产生太大影响。





可靠性
生产者发送消息时，要确认broker确实收到并持久化了这条消息，⽐如RabbitMQ的confirm机制，
Kafka的ack机制都可以保证⽣产者能正确的将消息发送给broker
6. broker要等待消费者真正确认消费到了消息时才删除掉消息，这⾥通常就是消费端ack机制，消费
者接收到⼀条消息后，如果确认没问题了，就可以给broker发送⼀个ack，broker接收到ack后才会
删除消息

死信队列也是一个消息队列，它是⽤来存放那些没有成功消费的消息的，通常可以⽤来作为消息重
试
2. 延时队列就是⽤来存放需要在指定时间被处理的元素的队列，通常可以⽤来处理⼀些具有过期性操
作的业务，如几分钟内未支付则取消订单





在建⽴TCP连接时，需要通过三次握⼿来建⽴，过程是：
1. 客户端向服务端发送⼀个SYN
2. 服务端接收到SYN后，给客户端发送⼀个SYN_ACK
3. 客户端接收到SYN_ACK后，再给服务端发送⼀个ACK


在断开TCP连接时，需要通过四次挥⼿来断开（忽略）


1.浏览器解析⽤户输⼊的URL，⽣成⼀个HTTP格式的请求
2. 先根据URL域名从本地hosts⽂件查找是否有映射IP，如果没有就将域名发送给电脑所配置的DNS进行域名解析，得到IP地址
3. 浏览器通过操作系统将请求通过四层⽹络协议发送出去
4. 途中可能会经过各种路由器、交换机，最终到达服务器
5. 服务器收到请求后，根据请求所指定的端口，将请求传递给绑定了该端⼝的应用程序，⽐如8080被
tomcat占用了
6. tomcat接收到请求数据后，按照http协议的格式进⾏解析，解析得到所要访问的servlet
7. 然后servlet来处理这个请求，如果是SpringMVC中的DispatcherServlet，那么则会找到对应的
Controller中的⽅法，并执行该方法得到结果
8. Tomcat得到响应结果后封装成HTTP响应的格式，并再次通过⽹络发送给浏览器所在的服务器
9.浏览器所在的服务器拿到结果后再传递给浏览器，浏览器则负责解析并渲染


协议、域名、端⼝一致
如果使⽤ajax去访问
www.jd.com是不⾏的，但是如果是img、iframe、script等标签的src属性去访问则是可以的，之所以浏
览器要做这层限制，是为了⽤户信息安全。但是如果开发者想要绕过这层限制也是可以的：
1. response添加header，⽐如resp.setHeader("Access-Control-Allow-Origin", "*");表示可以访问所有网站，不受是否同源的限制
2. jsonp的方式，该技术底层就是基于script标签来实现的，因为script标签是可以跨域的
3. 后台自己控制，先访问同域名下的接口，然后在接口中再去使用HTTPClient等⼯具去调用目标接口
4. 网关，和第三种方式类似，都是交给后台服务来进行跨域访问













