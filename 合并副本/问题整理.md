重核

设计模式，单例模式
分布式事务
秒杀系统
  核心思想：层层过滤，尽量将请求拦截在上游，降低下游的压力，逐渐递减瞬时访问压力(主要是数据库的压力)
  流程， 用户抢购（请求）->是否是异常用户（账号安全检查,ip检查等）->缓存中的库存是否足够（商品库存检查）->扔给mq去慢慢操作->异步消费订单处理，附带超时补偿操作


  有效请求和无效请求
      1.针对一个用户的无效恶意请求，可以增加图片验证码
      2.短信验证，进一步的限制请求，比如限制用户在单位时间的操作次数，降低请求量， 
      3.一人多账号的，最终集中到实名那步，限制到人信息即可
      4.多人多账号的，僵尸账号排除法，平时没交易，只在特殊节日交易
      5.当然还能使IP封禁，尤其是通过同一IP或者网段频繁请求的，但是可能误伤有效请求，需注意


  充分利用缓存与消息队列，提高请求处理速度以及削峰填谷的作用
  针对扣库存的地方，利用redis实现分布式锁(一般是集群，用分布式锁),锁住针对库存的减操作。可以使用redisson已经有对 Reentrantlock的封装操作。


平台提升即可，在公司的主要工作内容，技术只谈技术，杂的不要谈，问一回一，不要多说
尊重和平等




## 数据结构
treeMap的自定义排序（comparator，排list<entry>或者key，key是初始化比较器）

hashmap的不安全性在于多个线程同时resize时候，但是有的执行完 有的正在resize，这样数量就会出现问题。所以要加锁控制
定位的时候，先hash定位数组，在key定位链表位置（链表中元素超过8个时，就将链表转化为红黑树）
扩容，初始容量为 16，负载因子为 0.75 的 HashMap。超过16*0.75=12，就扩容一倍，并重新散列

ConcurrentHashMap主要特点，分段锁Segment，默认16段

ConcurrentHashMap = Segment[] 和 HashEntry[] 组成
一个Segment里包含一个HashEntry数组,本身segment继承ReentrantLock实现锁控制(这里是jdk7，jdk8有变化)

通过两次Hash定位到元素位置，第一次是定位segment，第二次是定位hashEntry。

确定该元素的放在哪个Segment；再确定该元素放置在哪个HashEntry


了解即可
JDK1.8的实现已经摒弃了Segment的概念，而是直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用Synchronized和CAS来操作，整个看起来就像是优化过且线程安全的HashMap。
虽然在JDK1.8中还能看到Segment的数据结构，但是已经简化了属性，只是为了兼容旧版本。


HashSet通过 hashCode 值来确定元素在内存中的位置。一个 hashCode 位置上可以存放多个元素。
哈希值相同 equals 为 false 的元素，就是在同样的哈希值下顺延（可认为哈希值相同的元素放在一个哈希桶中）。也就是哈希一样的存一列。类似map


## 线程相关
线程池介绍，工作机制,优点
  线程池的工作流程和包和策略，主要核心线程参数corePoolSize,maximumPoolSize，队列等

  流程：corePoolSize - 工作队列(workQueue) - maximumPoolSize,必要时创建非核心线程，满了交给饱和策略(无法处理新任务时抛出异常)

  使用线程池的好处:
  线程池可以减少创建和销毁的开销，避免频繁切换线程，任务调度
  控制线程数量,集中管理线程

ExecutorService 接口继承了Executor 接口，是Executor 的子接口
Executors是工具类(创建线程池)，他提供对ThreadPoolExecutor的封装产生ExecutorService的具体实现类


创建三种线程池，
  ExecutorService executorService = Executors.newFixedThreadPool(11);
  newSingleThreadExecutor()
  newFixedThreadPool(int numOfThreads)     常用
  newCachedThreadPool()， 一般不用，因为newCachedThreadPool可无限新建线程，容易造成内存溢出


executorService.submit()方法可以接收Runnable和Callable接口对象,后者有返回Future对象，get()获取

阻塞优化
使用CompletionService按照线程完成顺序获取，原始的是按加入线程池顺序(submit顺序)的阻塞
监听future返回结果阻塞问题，引入Guava Future
使用ListenableFuture Guava帮我们监听检测Future是否完成了，如果完成就自动调用回调函数，不必手工get数据

事务特性 ACID   
原子性、一致性、隔离性和持久性


ThreadLocal，主要用作隐式传参，
    Threadlocal操作对象，是获取当前线程的Threadlocalmap对象，线程独享，key是Threadlocal对象，value是待存值，
    本质就是操作Thread.ThreadLocalMap<ThreadLocal, Object>这个对象


线程中断的概念
只是加中断标记，不立刻执行，按需终止。
interrupt加标记，isInterrupted()判断后决定是否去终止

interrupt
给线程设置中断状态，只设置状态，不会立刻停止，后续可检查自己的中断状态isInterrupted()，自行判断要做啥


终止线程常用
1.正常运行结束
2.Interrupt中断
3.异常终止


常见方法 sleep，wait，nofity，yield
wait() 和 notify() 实现的基础是基于对象存在

所有的对象都会有一个wait set，用来存放调用该对象wait方法之后进行block状态的线程。
线程从wait set中唤醒的顺序不一定是FIFO(先入先出模式)。但是线程被唤醒后，必须重新获取锁
对象的等待队列WaitQueue中，进入等待状态

阻塞：等待，sleep，io阻塞，同步阻塞

java内存模型(工作内存，主内存，堆栈内存)
  线程访问对象值时，先通过对象引用找到对应在堆内存的变量的值，然后load到本地内存，建立变量副本，最后再回写回去，也就是所说的线程工作内存和主内存之间的操作
线程实现方式 3种


线程的生命周期：新建（start），就绪，运行，阻塞（synchronized，sleep，wait，可以notify唤醒），死亡



### 锁相关
常见的锁类型，自旋锁，偏向锁，轻量级锁，可重入锁，公平锁，非公平锁，乐观锁，悲观锁
  自旋锁使用场景
  自选等待时间小于持锁时间，减少线程切换

实现分布式锁

CountDownLatch 也可以实现join功能


a，b，c三个线程执行顺序,   a>(b,c)
CountDownLatch(1)，countDown() 和  await()
Semaphore(0)，acquire() 和 release()


countdownlatch是线程执行完后再释放锁吗
  不是，线程a只要countDown后为0，另一个b中await线程直接唤醒，不需要等a全部执行完。锁定只是countdownlatch这个共享变量




关键点就是，后执行的要阻塞，由先执行的唤醒或者释放锁

使用countDownlatch
思路是，先执行的countDownLatcha.countDown(),后执行的await等待即可，同理a-b，b-c
```
  public static void main(String[] args) {
		
    for (int i = 0; i < 6; i++) {
			Thread.sleep(2000);
			System.out.println("=======================");
			CountDownLatch countDownLatcha = new CountDownLatch(1);
			CountDownLatch countDownLatchb = new CountDownLatch(1);
			
			Runnable runnablea = new  Runnable() {
				public void run() {
					
					System.out.println("执行a");
					countDownLatcha.countDown();
				}
			};
			Runnable runnableb = new  Runnable() {
				public void run() {
					try {
						countDownLatcha.await();
					} catch (InterruptedException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
					
					System.out.println("执行b");
					countDownLatchb.countDown();
				}
			};
			Runnable runnablec = new  Runnable() {
				public void run() {
					try {
						countDownLatchb.await();
					} catch (InterruptedException e) {
						// TODO Auto-generated catch block
						e.printStackTrace();
					}
					
					
					System.out.println("执行c");
				}
			};
			
			Thread threada = new Thread(runnablea);
			Thread threadb = new Thread(runnableb);
			Thread threadc = new Thread(runnablec);
			
			threada.start();
			threadb.start();
			threadc.start();
		}
	}
```

使用lock的condition

```
  思路：
  首先是 static int 变量 nextNumber ，通过对这个数值的控制，来实现依次启用不同类型的线程。分别为ThreadA，ThreadB，ThreadC，三类线程均对nextNumber的值进行判断，然后进行相应的代码处理
  nextNumber初始值为1。

  引入nextNumber判断是否需要await，是因为，a和b的顺序不可知，如果先a中的signal(),后面b中await就释放不了。
  CountDownLatch中 countDown   await 顺序影响不大，但newCondition中 await 和signalAll，必须是await先执行，signalAll后执行，所以要引入nextNumber判断是否需要await

  //使用 Condition 实现 线程顺序执行
  public class ConditionOrderRun {
      private  static  int nextNumber = 1;
      private static Lock lock = new ReentrantLock();
      private static Condition con1 = lock.newCondition();
      private static Condition con2 = lock.newCondition();
      private static Condition con3 = lock.newCondition();

      public static void main(String[] args) {

          Thread threadA = new Thread(()->{
              try {
                  lock.lock();
                  while(nextNumber != 1){
                      con1.await();
                  }

                  System.out.println("AAA 名称： " + Thread.currentThread().getName());

                  nextNumber = 2;

                  con2.signalAll();//唤醒阻塞到condition2上的所有线程
              } catch (InterruptedException e) {
                  e.printStackTrace();
              } finally {
                  lock.unlock();
              }
          });

          Thread threadB = new Thread(()->{
              try {
                  lock.lock();
                  while(nextNumber != 2){
                      con2.await();
                  }
                  System.out.println("BBBB + 名称: " + Thread.currentThread().getName());
                  nextNumber = 3;
                  con3.signalAll();

              } catch (InterruptedException e) {
                  e.printStackTrace();
              } finally {
                  lock.unlock();
              }
          });

          Thread threadC = new Thread(()->{
              try {
                  lock.lock();
                  while(nextNumber != 3){
                      con3.await();
                  }
                  System.out.println("CCCC + 名称: " + Thread.currentThread().getName());
                  nextNumber = 1;
                  con1.signalAll();

              } catch (InterruptedException e) {
                  e.printStackTrace();
              } finally {
                  lock.unlock();
              }
          });

          Thread[] arrayTA= new Thread[5];
          Thread[] arrayTB = new Thread[5];
          Thread[] arrayTC = new Thread[5];

          for(int i=0;i<=4;i++){
              arrayTA[i] = new Thread(threadA);
              arrayTA[i].start();
              arrayTB[i] = new Thread(threadB);
              arrayTB[i].start();
              arrayTC[i] = new Thread(threadC);
              arrayTC[i].start();
          }
      }
  }
```



当一个线程进入一个对象的 synchronized方法A之后，其它线程是否可进入此对象的synchronized方法B，不能
对于同一个对象obj的两个synchronized方法a，b，一个线程占用方法a后，另一个线程不能进入对象的方法b，因为这里是前者线程持有了obj的锁，锁的是整个实例对象


condition是对wait方法的补充，可以选择唤醒顺序，
注意线程B中的signal()后必须要lock.unlock();后才会唤醒执行之前的等待线程，和之前的wait/notify方法类似。

synchronized 和 lock 的区别
公平、可中断、获取释放锁tryLock/unlock，系统自带和api级别,多个锁(ReentrantLock可能通过Condition来控制各个低粒度的边界)


悲观锁和乐观锁
select for update
version

使用场景
  系统之前的是同时锁住需求者和服务者，两个线程相反锁顺序就会造成交叉的死锁了,原先的互锁会出现问题，ab 和 ba
    1.控制访问锁的顺序
    2.trylock，通过timeout获取锁，时间过长就失败
    3.线程转储thread dump分析

    1：杀死进程id（就是 SELECT * FROM INFORMATION_SCHEMA.INNODB_TRX; 命令的trx_mysql_thread_id列）
        kill 线程ID   

    2：引入分布式锁解决。（推荐）

    3：修改事务隔离策略。（没用）
        这样间隙锁就失效了，从而升级为表锁。会阻塞所有的请求。
  
#### 事务隔离级别
  脏读 幻读，不可重复读

    简单概括，
      1.可重复读怎么实现，
          mvcc实现，原理是读取独有的那个版本的数据，每条记录都有隐藏列(创建、删除版本号)

      2.幻读怎么解决
          rr下，mvcc解决快照度的幻读，间隙所解决当前读的幻读



    脏读：读取未提交的数据称为脏数据

    * READ UNCOMMITTED：脏读（未提交读）
        可以读取未提交的数据，未提交的数据称为脏数据。此时：幻读，不可重复读和脏读均允许；
        比如A事务读取到了B事务还没有提交的数据，因为什么原因B事务回滚了，那么A事务读取的数据和数据库中的数据不同，也就是读到了其他事务没有提交的数据

    * READ COMMITTED：不可重复读
      ​	只能读取已经提交的数据；
      ​	同一个事务中多次执行同一个select, 读取到的数据发生了改变(被其它事务update并且提交)；
      ​	此时：允许幻读和不可重复读，但不允许脏读，这里的RC要求解决脏读；
      
      比如A事务读取数据，开始是100，事务还没有提交，此时B事务对这个数据修改为80，然后提交了事务，此时A事务再次读取就是80，因为B已经提交了，但是两次的结果不一样，就产生了不可重复读的现象。

    * REPEATABLE READ：默认级别
      ​	同一个事务中多次执行同一个select,读取到的数据没有发生改变((一般使用MVCC实现))；
      ​	此时：允许幻读，但不允许不可重复读和脏读，这里的RR要求解决不可重复读；

        这个级别下，当前读无法锁住insert操作，所以会出现幻读

    * SERIALIZABLE: 幻读，
      ​	同一事务中多次执行同一select, 读取到的数据行发生改变。即行数减少或者增加了(被其它事务delete/insert并且提交)。
      ​	不可重复读和脏读都不允许，所以serializable要求解决幻读

      **不可重复读 和 幻读区别：**
          不可重复读的重点是修改:
            同样的条件的select, 你读取过的数据, 再次读取出来发现值不一样了

          幻读的重点在于新增或者删除:
            同样的条件的select, 第1次和第2次读出来的记录数不一样

    GAP锁使用场景
          保证两次当前读返回一致的记录，那就需要在第一次当前读与第二次当前读之间，其他事务不会插入新满足条件的记录并提交。
          主要是防止的幻读，读多条数据
          将当前数据的上下两条数据的间隙锁定。

          RR隔离级别下间隙锁才有效，RC隔离级别下没有间隙锁；
          RR隔离级别下为了解决“幻读”问题：“快照读”依靠MVCC控制，“当前读”通过间隙锁解决；
          间隙锁和行锁合称next-key lock，每个next-key lock是前开后闭区间；
          间隙锁的引入，可能会导致同样语句锁住更大的范围，影响并发度。
          不仅对扫描到的行进行加锁，还对行之间的间隙进行加锁，这样就能杜绝新数据的插入和更新

      rr模式下，幻读问题在 "当前读" 下才会出现。因为快照读的mvcc方式是ok的。
        产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，操作的是锁住的行之间的 “间隙”。
        MVCC解决的是快照读的幻读，临键锁next-key locks(行锁和gap间隙锁共同组成)解决的是当前读的幻读。
        RR隔离级别下，当前读结果是其他事务已经提交的最新结果，快照读是读当前事务之前读到的结果


        快照读：读取的是快照中的数据（可能是过期的数据），不用加锁
                普通select是快照读。快照读用 MVCC 机制解决幻读。
                读取已提交和可重复读这俩隔离级别

        当前读：读取的是最新版本的数据，且对读取的记录加锁，保证其他事务不会再并发的修改这条记录。
                select for update、update、insert、delete 都是当前读。排它锁,有加锁行为
                当时无法锁住insert的数据,,存在幻读问题

        多版本并发控制(MVCC)是一种用来解决读-写冲突的无锁并发控制，就是为事务分配单向增长的版本号，为每个修改保存一个版本，读操作只读该事务开始前的数据库的快照。
          
            MVCC，就是一个多版本并发控制(类似于乐观锁)，这种读是属于快照读，不是当前读，当前读需要加锁，悲观锁。
            在读取事务开始时，系统会给事务一个当前版本号(事务ID)，事务会读取版本号<=当前版本号的数据，
            其核心思想就是：只能查找事务id小于等于当前事务ID的行；只能查找删除时间大于等于当前事务ID的行，或未删除的行
            
            InnoDB在每行记录后面保存两个隐藏的列，分别保存了这个行的创建时间和行的删除时间。这里存储的并不是实际的时间值,而是系统版本号，当数据被修改时，版本号加1。
            若其他写事务修改了这条数据(增删改)，那么这条数据的版本号就会加1，从而比当前读事务的版本号高，读事务就读不到更新后的数据,而是当前事务对应版本下的数据

            InnoDB是通过维护两个隐藏列来实现mvcc，记录数据行创建版本号和删除版本号，每开始一个事务，版本号就会递增；事务开始时刻的版本号就是事务的版本号，用来和查询到的数据行的版本号进行比较；
            
            案例详见：https://blog.csdn.net/wxd772113786/article/details/117198017

            mvcc在可重复读级别下的具体实现：
              简单说就是，读取属于自己的那个版本的数据，不受别的操作的影响

              SELECT
                  读取创建版本小于或等于当前事务版本号，并且删除版本为空或大于当前事务版本号的记录。这样可以保证在读取之前记录是存在的
              INSERT
                  将当前事务的版本号保存至行的创建版本号
              UPDATE
                  新插入一行，并以当前事务版本号作为新行的创建版本号，同时将原记录行的删除版本号设置为当前事务版本号
              DELETE
                  将当前事务的版本号保存至行的删除版本号



#### 分布式锁，
    常用的是redis的setnx搭配expire(改进版是getset()方法)，或者zookeeper锁，使用了目录节点的唯一性
    expire()命令对 lockkey 设置超时时间，为的是避免死锁问题。（这里宕机会出现死锁问题）

    如果是集群环境，使用红锁本质上就是使用多个Redis做锁，同时获取多个，超过半数为成功
    当且仅当从大多数（这里是3个节点）的Redis节点都取到锁，并且使用的时间小于锁失效时间时，锁才算获取成功。


    Redis SETNX(SET if Not eXists) 
      当 key 不存在,将key的值设value，当key已经存在，则SETNX不做任何动作。
    SETNX key value 等效于 set key value nx
    setex key second value 等效于 set key value ex second

    nxxx-nx(只在key不存在时才可以set)|xx(只在key存在的时候set)

    主要要解决的几个问题
      1设置锁的过期时间，解决持有锁的客户端A挂了却一直持有锁，导致B客户端无法获得锁。
      2如何保证锁不会被误删除，通过设置锁的value，使用lua脚本保证释放锁的原子性，防止出现i++问题
      3过期时间如何保证大于业务执行时间，设置定时开启刷新过期时间线程，业务完成，释放锁时同时取消定时刷新过期时间任务，(这里也可以程序内部适当判断时间延长)


      1.过期了，不执行
      2.过期了，需要租约续期
      3.粗暴的方式就是将租约时间设置的时间加长，缺点是可能造成服务阻塞
      解决还是决定使用定时任务去查询是否过期，根据是否过期来确定执行与否。


      SetNx-自己封装的
        public boolean setnx(String key, String value, long timeout, TimeUnit unit) {
              boolean setRes = stringRedisTemplate.opsForValue().setIfAbsent(key, value);
              if(setRes) {
                setRes = stringRedisTemplate.expire(key, timeout, unit);
                return setRes;
              }else {
                return false;
              }
          }

      redisson分布式锁
        重点是锁的自动续期，使用的是看门狗机制，同步锁默认时间为lockWatchdogTimeOut【30s】,每30/3=10s就自动续一次锁
        watchdog只有在未显示指定加锁时间(leaseTime)时才会生效,不指定默认-1

        public boolean tryLock(long waitTime, long leaseTime, TimeUnit unit)
                        waitTime，请求获取锁的等待时间，超过时间就失败， 
                        leaseTime，获取锁后，锁的失效时间，该参数为-1，才会自动续期

        直接lock会阻塞，单独tryLock()不会阻塞，会立刻返回获取结果

        redisson在加锁成功后，会注册一个定时任务监听这个锁，每隔10秒就去查看这个锁，如果还持有锁，就对过期时间进行续期。默认过期时间30秒。这个机制也被叫做：“看门狗”，
        定时任务，ScheduleTask,监听功能，类似job或者while(true)执行
        while尝试获取锁(可自定义等待时间，超时返回失败)


## spring,mvc,mybatis相关
    动态代理
      jdk-invocationhandler,ciglib-MethodInterceptor
      Proxy.newProxyInstance(target.getClass().getClassLoader(), i.getClass().getInterfaces(), this);

    常用aop是@Aspect
    所有的service在注入使用时候，都是使用的代理对象，这样可以实现事务控制
    
    当@service标注的bean在容器中检查到有@transaction，则会创建一个代理对象，
    开启事务--->创建sqlsession--->使用jdbc连接执行sql--->最后提交事务
    client-aop动态代理-@transaction-service-@transaction提交或回滚，实质上service是被aop代理了，
    这里事务全交给spring管理了，mapper的那层代理也就是执行对应的sql



    事务
      编程式事务，允许用户在代码中精确定义事务的边界，侵入业务代码，使用 TransactionTemplate,直接事务模板处理，可以返回自定义的result。
      声明式事务，基于AOP，有助于用户将操作与事务规则进行解耦。@transactional

      事务自调用失效
         方法：1.使用注入的service调用， 2.从springcontext中获取bean(是一个代理对象)，调用也行

         必须是走代理才能使用事务
        
      隔离级别(默认可重复读) 和 事务传播行为

      Transactional并没有捕获异常的功能，遇到运行异常自己回滚后会向上抛出。除非上层捕获才不影响上层

      serviceA中 try{ serviceB.do();} catch (Exception e) {}   
		  如果B是默认事务，那么B中异常后，即使try了，整体commit还是会异常，因为同一事务已经被标记过回滚了。

    主流初始化，使用@PostConstruct注解初始化,Bean实现InitializingBean 接口
      
    解决springbean循环依赖
        解决方案：
        1.spring的循环依赖问题：在注入@Autowired 下加@Lazy 注解即可(两边都加比较保险)
          Spring的懒加载是在需要用到bean的时候，就是getBean的时候才创建，这样就不会报BeanCurrentlyInCreationException。

          类A的创建：A a=new A(B)，需要依赖对象B，发现构造函数的形参上有@Lazy注解，就不直接创建B，而是动态代理创建一个代理类B1，此时A跟B就不是相互依赖了，变成了A依赖一个代理类B1，B依赖A。
          但因为在注入依赖时，类A并没有完全的初始化完，实际上注入的是一个代理对象，只有当他首次被使用的时候才会被完全的初始化。

        2.将相互依赖的两个Bean中的其中一个Bean采用Setter注入(也就是属性注入)的方式即可。


    springbean生命周期
      主要的是4个关键阶段和多个扩展点(实现Aware接口)
        1.实例化 Instantiation		对应构造方法
        2.属性赋值 Populate		    对应setter方法的注入
            扩展：检查Spring Awareness 这里是一个扩展点  基本都实现了aware接口
        3.初始化 Initialization			beanpostprcessor，初始化前后自定义初始化逻辑。所有Aware接口的注入就是在这前置完成的。
        4.销毁 Destruction


    属性赋值
      @PropertySource("classpath:application.properties")		#添加自定义的属性文件进来,将属性文件加入到容器，后续可以直接用@value注入
      @ConfigurationProperties(prefix = "application.dubbo.demo.server")	#写在类上，省略前缀，匹配后面的名字，但是注意要有set方法


    mvc和spring是父子容器关系

    mvc流程
      request-dispatcherservlet-HandlerExecutionChain-handler-mv给dispatcherservlet-视图解析


    级联查询
    mybatis不支持多对多，可以拆分成两个一对多级联处理。暂时忽略
		1. 关联-association				用于一对一
		2. 集合-collection				用于一对多

    mvc全局异常
      @ControllerAdvice 或者 实现接口handlerExceptionResolver


    PageHelper原理也是使用了threadlocal变量


     ***核心思路***
         mapper的动态代理，最后核心处理方法是sqlsession对象去运行对应的sql。mapper通过关联xml中的namespace，找到对应的执行方法。
         sqlSessioη.getMapper(RoleMapper.class);
         configuration.<T>getMapper(type, this)
         最终代理的是sqlsession的操作。通过namespace将sql和代理对象绑定起来
    ***核心思路***

  创建拦截器两种方法
      1.继承HandlerInterceptorAdapter类，可重写其中一个或多个方法
      2.实现HandlerInterceptor接口，需要同时实现其中三个方法


  mybatis会为mapper接口生成一个动态代理，去处理相关的实现逻辑

  sqlsession会话，SqlSession中定义的全是对数据库增删改查的各种方法，mybatis的核心接口对象、 mybatis中的主要操作对象
      类似jdbc中的connection对象，代表一个连接资源的启用。1.获取mapper接口，2.发送sql给数据库 3.控制数据库事务
      存在一个业务请求中，操作事务，请求完成，关闭连接，归还给sqlsessionfactory。

  这里spring和mapper的代理事务
    因为mybatis已经整合到了spring中，所以最终控制事务sqlsession的是spring来控制的，mybatis的代理只是执行mapper映射对应的sql语句

  			
  演示动态代理mapper的生成
        ProductMapper productMapper = sqlSession.getMapper(ProductMapper.class) ;
				Product product= productMapper.getRole(productid);



## boot相关
    自动配置原理
      自动配置是通过spring-boot-autoconfigure的jar包实现的(配置核心)，其中有很多的配置类，加载默认配置。

      1. @SpringBootApplication启动入口，是boot的入口
      2. boot在springapplication对象实列化时会加载META-INF/spring.factories文件，将该文件中的配置加入到spring的容器（对应是各自功能的AutoConfigurationBean
      3. 根据条件注解@ConditionalOnMissingBean等，配置相关的功能bean(由jar引入)，）各bean根据属性读取自动配置
		
      @conditionalOnClass、@ConditionalOnMissingBean实现自动的条件加载

      简单的说就是1.启动类入口，2.引入jar，读取spring.factories文件，搭配条件注解实现自动加载

      实际上spring.factories的作用就是做上下文初始化，加载配置文件中的bean到Ioc容器，加载配置项等。
      springboot执行时或扫描所有的META-INF/spring.factories的内容，会将classLoader加载类路径下的所有spring.factories的配置内容，loadSpringFactories方法将返回一个key=接口名，value=实现类集合的Map结构。

      *****
        启动自动装配流程
          主要模块spring-boot-autoconfigure 的jar负责
          1.启动类入口
          2.通过SpringFactoriesLoader加载META-INF/spring.factories中的配置，各个jar引入
          3.在结合 @Conditional 对加载到的自动装配配置bean进行过滤，从而实现模块的自动装配
              @conditionalOnClass、@ConditionalOnMissingBean实现自动的条件加载
            （如果自动装配bean能够被ComponentScan扫描到，不配置到META-INF/spring.factories中也是会生效的）
      *****


    web方面的配置
      WebMvcConfigurer接口，主要是配置拦截器，过滤器，servlet，静态资源等一些web配置。


    拦截器，过滤器，Servlet

    过滤器，Servlet，关注的是前者的dofilter(),后者的service()方法，其他就是初始化和销毁方法
    拦截器prehandle、posthandle 和 aftercompletion

    prehandler按顺序执行，posthandler，afterCompletion按拦截器配置的逆向顺序执行


## jvm相关
类加载 双亲委派(向上递归检查，向下递归加载),一个类只能被一个类加载器加载
  双亲委派机制，就是一个类只能被一个类加载器加载，不会重复加载

  采用双亲委派的一个好处是比如加载位于 rt.jar 包中的类 java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同样一个Object对象

  向上递归检查，向下递归加载
  原则：1.自底向上检查类是否已经装载  2.自顶向下尝试加载类
  逐层往上(接待就返回，没有就抛给上层，直到有一级接待或者上级返回没有接待且不应由上级接待，那么本层就会加载)

  类加载器一般是三层的classLoader， 启动类加载器 BootstrapclassLoader:   扩展类加载器 ExtClassLoader： 应用程序类加载器 AppClassLoader：



JVM 参数，线上问题
生产线上内存参数配置多少
分代回收，年轻代、老年代
大对象直接进入老年代

内存三大部分，堆,栈,方法区
判断对象存活，根路径可达性

什么情况下触发垃圾回收？
minor GC: 当 eden 区满以后会触发。
Full GC：
          当老年代空间不足以支持下一次 Minor GC 时会触发一次 Full GC
          发生minor gc时，虚拟机会检测之前每次晋升到老年代中的平均大小是否大于老年代的剩余空间大小，若大于，则改为直接进行一次full gc


## 分布式
  cap理论

  一般是ap
  一致性(Consistency) ：  强一致性,    客户端知道一系列的操作都会同时发生(生效)，数据一致更新，所有数据变动都是同步的。最终一致和强一致性  这里一致性用最终一致即可。
  可用性(Availability) ： 高可用性,   每个操作都必须以可预期的响应结束，这是集群概念
  分区容错性(Partition tolerance) ：分布式容忍性,  即使出现单个组件无法可用,操作依然可以完成，这是模块的概念


  分布式事务常见方案，二三阶段提交，tcc, 补偿型

  一致性可以减点，其他两个重要，主要是ap

  Eureka是基于AP原则构建的，而ZooKeeper是基于CP原则构建的
  zk的在于leader的选举时没有高可用性，Eureka是高可用的
    但是从zk架构分析，zk在leader选举期间，会暂停对外提供服务（为啥会暂停，因为zk依赖leader来保证数据一致性)，所以丢失了可用性，保证了一致性，即cp。
    再细点话，这个c不是强一致性，而是最终一致性。即上面的写案例，数据最终会同步到一致，只是时间问题。


## mysql相关

      每个索引在InnoDB里面对应一棵B+树，索引的b+树结构
      id索引对应一个B+树索引结构，主键索引的叶子节点存储了整行的记录，就是数据本身
      普通列class_id也对应一个的索引树，普通索引的叶子节点保存的是其行记录中的id，也就是主键id

      InnoDB数据是存在B+树这一点没错，只不过是存在主键索引构成的B+树中的叶子节点中，普通索引的叶子节点存的是主键id


      联合索引的最左原则

      联合索引，肯定只有一棵B+ 树，联合索引中，最左前缀原则(只针对联合索引)

      建立联合索引，能更大可能实现索引覆盖，因为包括的索引字段变多了

      索引覆盖和回表
      			只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表。
            联合索引更容易实现索引覆盖

      这个叫回表(从普通索引树到主键索引树的二次树查询)，如果查询列是索引本身，一次就ok，不用回表，这里既是索引覆盖到了查询列(索引覆盖)    

      如果辅助索引上已经存在我们需要的数据,那么引擎就不会去主键上去搜索数据了。 ---- 这个就是所谓的"**覆盖索引**"
      其核心就是只从辅助索引要数据。那么, 普通索引(单字段)和联合索引,以及唯一索引都能实现覆盖索引的作用。


    主从架构，(主要作用)数据容灾恢复（主从备份），读写分离暂不做
    主备的，就说是冷热备，
    主从定义：从的存在主要是避免主宕机导致数据丢失。而不是让备机来分担并发压力，所以，主业务建议尽量在主上操作

    降低主从复制延迟的方法：1.写的缓存在客户端侧，2.重要读转发到主服务器上，3.减少延迟	
    主库能处理业务就全放在主库吧（特别是更新后的数据），从库只做灾备，备份，对实时性要求不高的统计报表类工作；
    如果你需要主从的业务时，你可以在中间层加个分布式缓存如redis，缓存组装数据，优先从缓存中读取刚刚写入的数据，


    分库分表后只能是多次查询组装数据，或者是做冗余
    难点扩容，  方法1.将所有的映射关系保存在一个独立的数据库中。好处是不用分片计算
               方法2.还有一张方法是 预算最大的服务器数量,比如是32  先搞两台物理机，2*16个db,之后扩容每次增加一倍，这样通过扩容逐渐减小服务器压力

    sql的优化主要就是针对走不走索引的优化，一般函数，in，null列，%开头，<>等都不走索引


## io相关
字节流继承于inputStream和outputStream
字符流继承于inputStreamReader和outputStreamwriter

二者的转换
使用流进行序列化和反序列化，objectoutputStream 和 objectinputStream
只处理纯文本优先用字符流（用writer和reader操作），其他都用字节流，

nio的优点

nio 主要就是一个线程对应多个socket连接,多路复用的核心是，多个socket复用一个线程

Java NIO 实际上就是多路复用IO，通过一个线程就可以管理多个socket(一个线程不断去轮询多个socket的状态)，只有当socket 真正有读写事件发生时，才调用实际的IO来进行读写操作。

Selector(选择器)是 Java NIO 中能够检测到一到多个 NIO 通道，并能够知道通道是否为读写事件做好准备。这样，一个单独的线程可以管理多个Channel，从而管理多个网络连接。


  ***
      nio	主要就是一个线程对应多个socket连接
      Selector(选择区)用于监听多个通道的事件。因此，单个线程可以监听多个数据通道。

      client socket->socketchannel->selector-handle process thread
  ***

IO
    服务器端的socket编程，最早的Java是所谓的阻塞IO(Blocking IO)， 想处理多个socket的连接的话需要创建多个线程， 一个线程对应一个。数量一多，效率降低
    *** 一个线程控制一个socket来读写，容易阻塞 ***
NIO     
    非阻塞IO(NIO：Non-Blocking IO)， 通过多路复用的方式让一个线程去处理多个Socket。	
    *** 一个线程通过一个selector，控制多个socket的读写 ***
    只需要使用少量的线程就可以搞定多个socket了，线程只需要通过Selector去查一下它所管理的socket集合，哪个Socket的数据准备好了，就去处理哪个Socket。



缓冲区
  Buffer的核心作用是用来缓冲，缓和冲击（对输出设备的冲击，包括磁盘、打印机、显示器）。
  比如你每秒要写100次硬盘，对系统冲击很大，浪费了大量时间在忙着处理开始写和结束写这两件事嘛。用个buffer暂存起来，变成每10秒写一次硬盘，对系统的冲击就很小，写入效率高了，

  缓冲区是内存空间的一部分，这些存储空间用来缓冲输入或输出的数据
  对缓冲区的操作速度更快，且减少了磁盘读写次数



NIO 主要有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector。

IO 是面向流的，NIO 是面向缓冲区的。
IO 的各种流是阻塞的，NIO 是非阻塞模式。


为什么nio是非阻塞的
    一个线程可以哪个socket空闲处理哪个，不想原来的每个线程socket都可能阻塞
    一个面向流，一个面向缓冲区

  IO
    服务器端的socket编程，最早的Java是所谓的阻塞IO(Blocking IO)， 想处理多个socket的连接的话需要创建多个线程， 一个线程对应一个。数量一多，效率降低
    一个线程控制一个socket来读写，容易阻塞 
  NIO     
    通过多路复用的方式让一个线程去处理多个Socket。	一个线程通过一个selector，控制多个socket的读写 
    只需要使用少量的线程就可以搞定多个socket了，线程只需要通过Selector去查一下它所管理的socket集合，哪个Socket的数据准备好了，就去处理哪个Socket。

## 数据库
覆盖索引 和 回表查询，mysql的索引树,B+树，B-树结构
隔离级别
InnoDB特点
行级锁都是基于索引的，   用不到索引是不会使用行级锁的，走表锁

namespace+id 作为Map<String,MappedStatement>的key使用，namespace不能重复

 主从数据库不一致问题解决
    1.忽略这个不一致，
    2.强制读取主库，读写都在主库，添加缓存提高性能
    3.选择性读主库，添加一个缓存用来记录必须读主库的数据，将库表键作为缓存的key，设置失效时间为主从同步时间，缓存中没有该数据主键就直接读主库



  大数据的limit优化
    mysql LIMIT 10000, 20的意思扫描满足条件的10020行，扔掉前面的10000行，返回最后的20行
    核心还是找到limit m,n  的那个起始的下标offsetid，然后使用limit n 来查询
    1.上一页的id带过来 
      思路就是在where语句根据id或者别的字段做一些限制。
      只能提供“上一页”、“下一页”这样的跳转，因为你需要拿到上一页或者下一页的id然后再根据where语句筛选，再使用LIMIT N来做。不管翻多少页，每次查询只扫描20行
    
    2.索引覆盖查到id
        子查询是在索引上完成的，而普通查询是在数据文件上完成的，索引文件要比数据文件小很多


## 缓存相关
  
  MQ如何保证顺序性

  redis的持久化 和主从备份去区别

  缓存同步
    spring session，全部存放在redis中
    之前是tomcat简单session缓存共享(现在已经不用，忽略)  Tomcat-redis-session-manager
    SpringSession 技术是解决同域名下的多服务器集群session共享问题的,实现了单点的缓存共享
    配置的springSessionRepositoryFilter必须得是在所有filter的前面。用了springsession后，已存储在redis的session中

  查询级别缓存 用springcache
    针对mybatis的一二级缓存，实际使用springcache更好
    范围可以到service级别
    引入springcache，需要自定义缓存管理器，场景：高查询  低改动
	  默认使用rediscache，最终存在Redis中，可跨系统

  redis常用的就是常用string和hash(类似map结构)

  redis持久化方式：
  rdb           
    默认的存储方式，默认写入dump.rdb的二进制文件中，可以配置redis在n秒内如果超过m个key被修改过就自动做快照
 
  aof
    默认是everysec  同步到磁盘

  键值回收，Redis的内存废弃策略
      redis采用的是定期删除+惰性删除策略  
      定期删除：每隔100ms就随机抽取一些，有的可能删不掉

     补充操作，内存淘汰机制allkeys-lru，当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key
    
     如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。 
     默认是，allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。


  redis的主从，主备 和持久化
    前者侧重读写分离，高可用
    后者侧重重启redis，恢复数据

  主从同步，绝大多数的迁移步骤，先迁移整体，同时开启临时记录区域，同步进行，延迟性可以通过临时缓存解决


这里单点用的是sringsession结合redis使用共享缓存
本质上还是使用了cookie的共享和redis缓存的共享，sessionid本质是获取用户信息数据。


## 事务相关
  

## 消息队列

特点：异步处理，流量削峰

关注的地方有，消息可靠性，幂等性

业务去重 和 索引，唯一键，分布式锁


1.数据库联合唯一键去重， 2.业务状态查询去重，3.redis这种分布式锁，redis-key的去重（唯一流水号）

rocketmq
  采用的是发布-订阅的模式，系统使用的是2master模式，简单实用
  RQ的基本组成包括nameserver、broker、producer、consumer四种节点，前两种构成服务端，后两种在客户端上。
  broker存储消息(消息存储与转发)，namesrv（路由管理,功能类似zookeeper）

  生产者发送msg发送给namesrv（路由管理,功能类似zookeeper），namesrv路由后通过broker存储转发消息到consumer集群，再消费给consumer(配合listener订阅topic)
  开启vpn会使rocketmq的broker的ip地址发生变化
  客户端是先从NameServer寻址的，得到可用Broker的IP和端口信息，然后自己去连接broker。

  producer生产消息，consumer消费消息，broker存储消息(消息存储与转发)，broker可以是集群部署，其中topic位于broker中
  rocketmq的消息模型简单来说，producer投递消息到topic中的各个队列(默认是4个队列)，各消费者组订阅topic,消费者组中的消费者并行消费队列中的消息


  Producer:　生产者生产消息到broker,broker接受消息写入topic，需要ack确认。消费同理
  Topic:表示一类消息的集合，每一个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位


  集群消费模式，消费一次
  消费者中同一个Group中的实例，在集群模式下，以均摊的方式消费；在广播模式下，每个实例都全部消费。

  ******这里一般是监听某个group下的某个topic******
        defaultMQPushConsumer = new DefaultMQPushConsumer(consumerGroup);
        defaultMQPushConsumer.setNamesrvAddr(namesrvAddr);
        defaultMQPushConsumer.setVipChannelEnabled(false);
        // 订阅指定中信topic下tags不限制
        defaultMQPushConsumer.subscribe(MQConstants.TOPIC_CITIC_ORDER, "*");
        // 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费<br>
        // 如果非第一次启动，那么按照上次消费的位置继续消费
        defaultMQPushConsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);
        // 设置为集群消费(区别于广播消费)
        defaultMQPushConsumer.setMessageModel(MessageModel.CLUSTERING);
        defaultMQPushConsumer.registerMessageListener(...)


可靠性和幂等性

适合解决分布式事务
 mq处理事务
    处理多个服务之间的一致性：后者失败，前者补偿操作，事务不要太多
      1、创建不可见的订单，执行多个小事务，并且这些是同时监听一个回滚topic的，只要有一失败就发送消息到mq，其他的监听到并进行回滚操作
      2、需要执行另一个查询订单状态的任务，异常的全部取消

    ***mq解决分布式事务的思路*****
        分支事务id-总事务id，每个分支事务自己独立执行，失败就回滚，并发送mq，更新总事务失败，其他服务监听到总事务失败自行回滚
    ***mq解决分布式事务的思路*****

    consumer端，最好的是使用统一的消息处理接口，重点重点重点：监听业务有没有操作记录，有记录回退，没有记录不用处理，即每个server都需要做相应的处理，处理逻辑看情况和操作日志来定


## 杂项

dubbo原理
    dubbo默认的配置	
    使用zookeeper作为注册中心，
    dubbo协议作为传输协议，
    使用netty异步传输作为底层通信框架，
    hessian序列化，
    javassist动态代理(实现MethodHandler接口)

    常见问题，https://baijiahao.baidu.com/s?id=1708712113848437910



    dubbo的线程模型

    dubbo的线程模型中有两个重要角色 ，ThreadPool（业务线程池）和Dispatcher(调度器，调度io线程处理)
    对于Dubbo集群中的Provider角色，有IO线程池（默认无界）和业务处理线程池（默认200）两个线程池，

    Dispatcher，默认是all，所有消息都发送发线程池
    配置成message，只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在IO线程上执行。

    threadpool 默认 fixed 固定大小线程池，启动时建立线程，不关闭，一直持有。(缺省)
         dubbo默认线程池大小200 和tomcat一样,tomcat 可创建的最大线程数默认是200
         dubbo默认线程池是fixed


  客户端，地址列表本地缓存

  常用模块，
    注册模块，注册中的的订阅和发布，
    dubbo的remoting，底层netty的通信
    dubbo的container模块，默认只会启动dubbo-container-spring的这个container，主要负责jar启动，优雅停机
		
    spi机制 服务提供接口 动态加载机制，一种服务发现机制
    javaspi就是提供这样的一个机制：为某个接口寻找服务实现的机制。工具类：java.util.ServiceLoader
    一般是在META-INF/services目录下


    xml中的dubbo标签,自定义标签解析，和spring的类似
    解析类DubboNamespaceHandler，其中定义了xml中标签的解析类,能看到有哪些配置类
		DubboBeanDefinitionParser类根据xml中的内容，加载了dubbo的详细配置，具体的配置类加载。

    *******
					ZK的本质就是为两端提供服务地址的发布/订阅服务，让消费者及时感知最新的服务列表，consumer真正调用provider是通过某种通信协议直接调用，并不依赖ZK。
					即使zk宕机，不影响两端调用，只是让本地缓存的服务列表有可能过时的。
		*******

    RpcContext.getContext().setAttachment,传参用，本质是一个ThreadLocal的临时状态记录器

zookeeper原理
    文件系统和通知机制
    zookeeper中的数据是目录树结构,本身是一个树型的目录服务，每个目录节点为znode，支持变更推送，适合做注册中心.

    znode的结构
        主要属性	
            zxid：	每次变化都会产生一个唯一的事务zxid（整个zk唯一）。通过zxid，可以确定更新操作的先后顺序。
            version:	节点的每次修改，都将使得版本号增加1
            data:		每个znode默认能够存储1M数据

     ZooKeeper的临时节点不允许拥有子节点
        四种类型的znode：  持久 临时 有序
            -持久化目录节点：客户端与zookeeper断开连接后，该节点依旧存在
            -持久化顺序编号目录节点：断开后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号
            -临时目录节点：断开后，该节点被删除，一旦创建这个 znode 的客户端与服务器失去联系，这个 znode 也将自动删除。
            -临时顺序编号目录节点：断开后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号

      所有的增删改查操作都是针对znode节点进行的

      zookeeper提供了文件系统和通知机制，client端会对某个znode建立一个watcher事件，当znode变化时，cleint会受到zk通知并根据变化做出改变
      一种是创建一个唯一路径，只有一个会成功
      如果路径存在，在下面创建临时顺序编号目录节点，编号最小的获取锁


netty原理

单例模式，懒汉饿汉静态内部类，实际推荐静态内部类模式
单例实现方式：构造私有化 + synchronized	实现单例模式的获取(防止多线程同时获取),并提供static访问实例的方法即可


quartz中的三要素，Scheduler、Trigger、JobDetai&Job。

Quartz 中两种可用的Job存储类型：
      * 1.内存存储(RAMJobStore),简单优先的解决方案
      * 2.持久化存储(jdbcjobstore)


### 基础知识


三种加密算法
    单向加密算法
      只能加密数据，不能解密回原来的明文。
      常会拼接一个salt字符串。密文＝ MDS(MDS(明文) + salt)
      常用：MD5,SHA,HMAC
    
    对称加密算法
      又称为单秘钥加密或密钥加密，指加密和解密使用的是相同的密钥
      加密后的信息可以解密成原值	des(适用数据库密码的加密)
      常用：DES,AES,和PBE
    
    非对称加密算法
      也叫公钥加密，就是指加密和解密使用了不同的密钥，一个公钥，一个私钥，公钥加密数据，私钥解密数据。		
      私钥用来签名，公钥用来验证签名。判断公私钥的正确性，就是ca证书做的事。
      私钥能解开公钥加密的数据，但忽略了一点，私钥加密的数据，同样可以用公钥解密出来（公钥是公开的，那么由服务器-》客户端的就存在安全隐患）
      常用： RSA 和 DH，重点RSA


  
HTTPS证书

filter 拦截器，servlet

本地私有仓库nexus，发布jenkins

内存模型中，线程间的变量值传递，需要通过主内存

单点登录主要就是cookie中的缓存和session中的缓存值,判断cookie中没有登录相关name的cookie value,有还要和session的userinfo信息一致，才具有登录信息
先看cookie，再看是否和session中值一致，登录的话，先server端设置session，然后返回客户端认证后写登录cookie，实现登录


shiro 了解即可
    *****
      shiro三大核心模块：Subject（用户）、SecurityManager(框架核心)、Realm（Shiro与应用安全数据间的“桥梁”，主要用来权限校验和密码校验）
      重点是shirofilter  securitymanager，和realm(AuthorizingRealm)。
    *****


简单点说，Java 中的传递，是值传递，而这个值，实际上是对象的引用。
传递的值在栈中，直接拷贝一份值传递，改变的形参不会对实参造成影响
传递的值在栈中存放的是地址（引用），先根据栈中的地址找到在堆上的值，然后把地址拷贝一份（拷贝的地址是一个值），此时形参和实参指向堆上同一个地址，形参的修改导致了实参的改变。


es分词，使用的默认的standard分词，ik是中文分词，前者只能是分成单个字，后者可以分成词语等

官网推荐默认使用的是RestHighLevelClient，添加使用的是indexrequest,搜索使用的是SearchRequest,
多条件查询使用BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery()，然后.must拼接各种query即可
最终是sourceBuilder.query(boolQueryBuilder)---> request.source(sourceBuilder)---> client.search(searchRequest)
查询结构SearchHits hits = response.getHits();然后迭代器迭代后getSourceAsString获取jsonString

最终是client执行SearchRequest，这里的searchRequest组合了BoolQueryBuilder布尔多条件过滤。

复合过滤器，bool（布尔）过滤器。 
其中QueryBuilders是用来生成不同功能的query.


es中的文档的定义
  	  文档元数据	
				_index 		文档在哪存放
					名字必须小写，不能以下划线开头，不能包含逗号
				_type		文档表示的对象类别，可在索引中对数据进行逻辑分区
					命名可以是大写或者小写，但是不能以下划线或者句号开头，不应该包含逗号
				_id			文档唯一标识
					和 _index 以及 _type 组合就可以唯一确定 Elasticsearch 中的一个文档
				

这里的分词是针对搜索词分词，分词后与字段分词对比

matchQuery：模糊查询，会将搜索词分词，再与目标查询字段进行匹配，若分词中的任意一个词与目标字段匹配上，则可查询到。
termQuery：精确查询，不会对搜索词进行分词处理，而是作为一个整体与目标字段进行匹配，若完全匹配，则可查询到


match
	  match中，这里的分词是针对搜索输入的字符串进行分词
term
    term本身搜索的参数字符串不分词，属性词分词后包含参数串即可


term决定查询词不分词，keyword决定文档中的值不分词
查询条件不分词精确匹配分词数据，命中一个分词即匹配

fieldName.keyword决定是否采用es分词数据源，不带keyword即查询text格式数据（分词），带即查询keyword格式数据（不分词）

搜索整段词，
match query中查询，operator：表示单个字段如何匹配查询条件分词，默认是or，设置成and就是全部满足
你直接想查一整个词  加上.keyword，fieldName.keyword	

analyzed字段无法使用term

和原来的正排索引是，找标题，进去找详细字段，倒排就是先找到详细字段，然后关联到具体的文档。
Elasticsearch 使用一种称为 倒排索引 的结构，它适用于快速的全文搜索。
一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表

bool 查询(常用),复合过滤器，组合查询

QueryBuilders.boolQuery()
                .must(QueryBuilders.termQuery(“key”, “value2”))
                .mustNot(QueryBuilders.termQuery(“key”, “value3”))
                .should(QueryBuilders.termQuery(“key”, “value4”))
                .filter(QueryBuilders.termQuery(“key”, “value5”));

  must		文档必须匹配这些条件才能被包含进来。
  must_not	文档必须不匹配这些条件才能被包含进来。
  should		如果满足这些语句中的任意语句，将增加 _score ，否则，无任何影响。它们主要用于修正每个文档的相关性得分。
      返回的文档可能满足should子句的条件.在一个bool查询中,如果没有must或者filter,有一个或者多个should子句,那么只要满足一个就可以返回.
      minimum_should_match参数定义了至少满足几个子句.
  filter		必须匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。


	复合查询
    must： AND
    must_not：NOT
    should：OR


对es的操作最终都是落实到具体的request上
  增，IndexRequest
  删，DeleteRequest
  改，UpdateRequest
  查，searchRequest，组合了boolQueryBuilder多条件查询



创建索引和新增索引
    创建新的索引(1.java程序 2.head插件上创建),创建索引时要把mapping结构也创建好

    ES中，一个字段的mapping在定义并且导入数据之后是不能再修改的，但是添加字段是可以的
	
	  ElasticSearch是不允许修改字段的type类型的，原因是一个字段的类型进行修改之后，ES会重新建立对这个字段的索引信息，
    ElasticsSearch的底层是Lucene库，字段类型修改至少需要设设计到分词方式，相关度等倒排的生成,不允许修改在我看来应该是Lucene机制导致的。

    Reindex：场景
      当数据量过大，而索引最初创建的分片数量不足，导致数据入库较慢的情况，此时需要扩大分片的数量，此时可用Reindex。
      当数据的mapping需要修改，但是大量的数据已经导入到索引中了，重新导入数据到新的索引太耗时；
	
	    默认情况下，_reindex使用1000进行批量操作，您可以在source中调整batch_size。提升批量写入大小值


      使用reindex的时候不要修改 type

      es创建索引后，不支持直接修改field 类型，可以使用创建中间索引，用_reindex来实现
      比如需要修改test_index索引中的字段类型

      1.先创建test_index_copy索引，这里的test_index_copy的field类型是正确的类型
      2.将test_index 索引 _reindex 到test_index_copy ，相当于copy

      POST _reindex
      {
        "source": {
          "index":"test_index"
        },
        "dest": {
          "index": "test_index_copy"
        }
      }
      3.DELETE  test_index    删除test_index索引，再重新创建test_index，字段更新成你想要的

      4 再将test_index_copy索引 _reindex 到 test_index ，成功后删除test_index_copy

      POST _reindex
      {
        "source": {
          "index":"test_index_copy"
        },
        "dest": {
          "index": "test_index"
        }
      }


    当Es索引因需求需要添加字段时，有三种方案
      通过删除旧索引，新建新索引来解决，需要全量跑数据，且平台会出现短暂不可用，不推荐
      新创建一个临时索引，然后把旧索引数据导入后，再把新索引别名命名为旧索引，但这种方式，索引别名让虽然不影响使用，费劲
      直接通过命令来实现
	
    创建方式：
      1.使用java代码创建index，配置mapping相关，java api
      2.kibana 打开对应的dev Tools，直接输入es相关api语句即可，put  delete 等命令,restful api,也可以在postman中提交rest请求


    比如：为已存在索引库添加映射关系
      PUT person/_mapping
        {
          "properties":{
            "name":{
              "type":"text"
            },
            "age":{
              "type":"integer"
            }
          }
        }


      创建索引并添加映射
        PUT user
          {
            "mappings":{
              "properties":{
                "name":{
                  "type":"text"
                },
                "age":{
                  "type":"integer"
                }
              }
            }
          }


    对于映射 只可以添加字段 不能删除、修改




服务化的好处，减压，公用，解耦

对接接口安全性   
    1、使用同一的token校验（获取动态口令，优先时间60秒，一般是account-key，先请求key，计入缓存，然后二次请求过来）
    2、增加ip白名单过滤，
    3、使用https证书
    4、增加sign校验

熔断，降级，限流 

   Hystrix断路器，快速失败
   自动阻断对服务的访问和调用，转而调用备用方法，或者快速失败


   限流的维度，01开关，设置固定值(每秒请求次数QPS)，超过请求次数，拒绝请求
        1.根据服务端自身的接口，方法控制，每个负载不一样。
        2.根据来源做控制，设置不同的限制，根据请求来源不同级别进行不同的流控处理。

      对于请求过多的时刻，可以告知用户系统繁忙，稍后再试，从而保证系统持续可用



      当达到阀值 时，后续的请求被降级，比如进入排队页面，比如跳转 到错误页（活动太火爆，稍后重试等）



  断路器很好理解, 当 Hystrix Command 请求后端服务失败数量超过一定比例(默认 50%), 断路器会切换到开路状态(Open). 
  这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态一段时间后(默认 5 秒), 自动切换到半开路状态(HALF-OPEN). 
  这时会判断下一次请求的返回情况,如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN). 


轮询策略，随机，轮询，权重等


tcp三次握手

 对象的序列化主要有两种用途：
      1.把对象的字节序列永久地保存到硬盘上，一般存在文件中；
      2.在网络上传送对象的字节序列。(常用)




 cloud和dubbo等框架的区别
		之前的dubbo，链路，治理，等框架都只是解决了微服务中的某一个问题，没有成体系。
		而cloud是解决微服务架构实施的综合性解决框架。相当于一个组装机，不用像之前一样，自由度高的配置零件。
		之前的类似自己组装电脑，cloud相当于品牌机各个原装组件都配置好了。是整套的实现框架。

cloud的简单模块
  负载均衡：ribbon和feign,采用feign的方式更优雅（feign内部也使用了ribbon做负载均衡）,使用起来就像是调用自身工程的方法
  注册中心: Netflix Eureka。包含客户端和服务端。
  熔断保护： hystrix 
  网关： cloud zuul 网关
  链路追踪： cloud sleuth 



ddos攻击防护，csrf攻击，sql注入，

普通用户与系统管理员用户的权限要有严格的区分。普通用户不能有Drop Table等表结构的权限
预编译语言
检查前置


VisualVM可视化工具使用


jvm相关
一个线程一个栈，一个方法一个栈帧，数据运行时确定

java堆中还可以细分为：新生代（MinorGC，包括eden,from,to）和老年代（MajorGC）

在新生代中，由于对象生存期短，每次回收都会有大量对象死去，那么这时就采用复制算法。minorGc的核心动作是 核心动作 复制-->清空-->互换，年龄+1，默认情况下年龄达到15的对象会被移到老年代

老年代里的对象存活率较高，没有额外的空间进行分配担保，所以可以使用标记-整理 或者 标记-清除。
标记出仍然存活的对象（存在引用的），将所有存活的对象向一端移动，以保证内存的连续，老年代的对象比较稳定，所以MajorGC不会频繁执行。
在进行MajorGC前一般都先进行了一次MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足够大的连续空间分配给新创建的较大对象时也会提前触发一次MajorGC进行垃圾回收腾出空间。

由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。

 minor GC 和 Full GC 的触发时机
    - minor GC: 当 eden 区满以后会触发。
    - Full GC：
        1. JVM 的一些特性比如分配担保，大对象直接进入老年代，长期存活的对象进入老年代等等都会不断增加老年代的使用率，当老年代空间不足以支持下一次 Minor GC 时会触发一次 Full GC
          发生minor gc时，虚拟机会检测之前每次晋升到老年代中的平均大小是否大于老年代的剩余空间大小，若大于，则改为直接进行一次full gc
        
        2. 当用户代码调用 System.gc 时，系统系统建议执行 Full GC，但是否进行是由 JVM 来决定的。

  
打印异常进程的堆栈信息 dump线程快照，定位死锁，超时问题
    jmap        查看堆内存使用情况，可生成JVM堆的转储快照，dump文件较大，消耗大量资源
    jstack
        jstack用于生成java虚拟机当前时刻的线程快照。注意是当前时刻
        线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，用于定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。



内存泄漏， 
修改HashSet中对象的参数值，且参数是计算哈希值的字段，
外部类实例对象的方法返回一个内部类的实例对象，内部类长期引用，外部类虽然不用了但被内部类持有，回收不了


系统配置内存
prd_pc 的tomcat的catalina.sh中配置大小，JAVA_OPTS="-server -Xms4608m -Xmx4608m -XX:MaxMetaspaceSize=500m"
prd_netpay 中是，JAVA_OPTS="-server -Xms1600m -Xmx1600m -XX:MaxMetaspaceSize=400m"
prd_open中是，JAVA_OPTS="-server -Xms2048m -Xmx2048m -XX:MaxMetaspaceSize=500m"

类加载，加载的几个阶段：加载，验证，准备，解析，初始化，使用，卸载，前5个就是类的加载过程，2-4属于连接
               

线上处理经验
Java基础知识和分布式经验应该很熟悉，框架层面源码如果能研读可以加分。但是如果只是会用而不了解原理就要减分。

一个是跨系统的hessian的异常处理，一个是dubbo线程池的溢出

动态数据源，继承AbstractRoutingDataSource
在查询的时候aop拦截选定指定数据源，后面执行数据操作的时候匹配相应的数据源，给方法加上自定义的切换注解，然后拦截注解内容，实现动态切换数据源。

重点
过往的工作经验是owner一个独立的业务系统，负责系统的设计开发工作。
明确知道系统架构的情况，理解上下游关系。
理解该系统的业务定位，该系统当前存在的问题和后续的规划发展有自己的见解。
Java基础知识和分布式经验应该很熟悉，框架层面理解原理，适当看源码
重点考察分布式/服务化系统（不是大流量高并发）的设计原理，思路，关注点。
要会理解一些分布式session、全局流水ID号、服务多次重试幂等、同步转异步、服务监控、最终一致性等原理和应用。
2主导一个复杂的系统（多个业务系统完整链路）；或者负责一块五脏俱全的业务。
3 对业务系统的理解会更多从商业价值角度去描述，熟悉这块产品链的模式和玩法，或者工业化成熟度较高的专业实现方案。
4分布式系统设计原则：分库分表分布式事务、性能稳定性的实践。
如果能描述分库分表中间件实现原理（SQLParse、语法树）、单元化/多机房灾备

######临时记录区域，防止冲突合并######

再次整理到，
Spring+Mvc+Mybatis


## 临时整理知识区
### 1. 111
      redis顺序消费，xss攻击，mq事务
      redis主从，复制断电，数据丢失，

        区别
        1.主从复制-备份
            备份或者读写分离。

        2.哨兵-高可用
          解决的问题是：自动化故障恢复

        3.cluster-高并发
          分片/槽

        哨兵模式
          哨兵作用就是主从切换
          一主(master)二从(slave)三sentinel的架构模式,  三个哨兵监控三个服务器
          脑裂问题，网络问题，导致临时2个m，解决配置：m断开s10秒，拒绝写入
          从节点的意义在于故障转移的能力

        集群模式
          (1m+1s)** 3
          数据是分片存储的，每个主节点存储的数据不一样，采用哈希槽的槽位映射到具体的节点，自带的哨兵功能
          解决负载均衡的问题。具体解决方案是分片/虚拟槽slot。

          自带类似哨兵机制，实现主从切换

          集群扩容
            使用工具redis-trib.rb
            主要步骤，1.创建新节点加入集群，2，迁移槽和数据 3.设置从节点


      b树比二叉树好在哪
      索引结构，b+树结构好在哪里，时间复杂度啥的
      tcp几层结构，http和tcp等对比


      linux操作相关，shell脚本相关，
      redis的lua脚本
      技术选型
      redis是主从什么架构，有没有哨兵机制啥的，主从复制断电数据，
      幂等和可靠性
      mq消息积压，消费端异常消费不了怎么办，主要用途，消息消费？ 顺序消费？其他功能
      mq事务使用了两阶段等的协调者的思想
      线程池参数配置意义，三个重点参数，


      redis的lua好处
      redis中引入lua的优势：

      减少网络开销：多个请求通过脚本一次发送，减少网络延迟
      原子操作：将脚本作为一个整体执行，中间不会插入其他命令，无需使用事务
      复用：客户端发送的脚本永久存在redis中，其他客户端可以复用脚本
      可嵌入性：可嵌入JAVA，C#等多种编程语言，支持不同操作系统跨平台交互


      mq消息积压
        本来就是流量削峰用的，慢慢稳定消费
        横向扩容，双m结构，加机器

        双m模式
            多个主节点时，一条消息只会发送到其中一个主节点
            优点：配置简单，单个 Master 宕机或重启维护对应用无影响，性能高。 
            缺点：单台机器宕机期间，这台机器上未被消费的消息在机器恢复之前不可订阅，消息实时性会受到影响。

        Broker分为Master和Slave，一个Master可以对应多个Slave，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave；
        Broker 集群通过 Master 和 Slave 的配合达到高可用性，通过在 Broker 的配置文件中设置参数 brokerId 来区分是 Master 还是 Slave：
        * brokerId 等于 0 表示这个 Broker 是 Master;
        * brokerId 大于 0 表示这个 Broker 是 Slave;
        Master 支持读和写操作，Slave 只支持读操作。

        消费消息时，RocketMQ会轮询该Topic下的所有队列将消息发出去
        一个Topic中的多个MessageQueue会被均匀的分布给一个消费者组中的多台机器进行消费，注意一个MessageQueue只能被一台消费者机器消费，可以同时消费多个master节点上的消息
        两个master节点恰好可以平均分发到两个消费者上，如果此时只有一个消费者，那么这个消费者会消费两个master节点的数据。

        在集群消费模式下，每条消息只需要投递到订阅这个topic的Consumer Group下的一个实例即可。
        消息队列 RocketMQ 版 Broker 会将这些 Queue 再平均分配至属于同一个Group ID的订阅方集群。

        ProducerGroup，ConsumerGroup，代表某一类的生产者和消费者，一般来说同一个服务可以作为Group，同一个Group一般来说发送和消费的消息都是一样的



        topic，broker，queue，tag的关系
            topic是指一类消息的集合,topic分片是把这些消息分布到不同broker的Queue上，便于实现横向扩展。
            一个 Message 必须指定 topic，Topic与Tag 都是业务上用来归类的标识，区分在于 Topic 是一级分类，而 Tag 可以说是二级分类

            *****
                一个group可以订阅多个Topic
                一个Topic下可以有多个MessageQueue，Queue使得消息存储可以分布式集群化
                比如OrderTopic有四个MessageQueue，这4个MessageQueue分布在两台MasterBroker上，每个MasterBroker上有两个MessageQueue。这样消息分布在不同的broker节点上
            *****

            消息发送发到broker存储
              Producer发送消息时，默认会轮询目标Topic下的所有MessageQueue，并采用递增取模的方式往不同的MessageQueue上发送消息，以达到让消息平均落在不同的queue上的目的。
              由于MessageQueue是分布在不同的Broker上的，所以消息也会发送到不同的broker上。
              首先按照BrokerName划分到不同的master上,划分到具体的master后又回分到不同的queue上, 每一个master维护自己的queue(即不同master之间的queue没有联系).
              Producer 的消息以轮询的方式发送至 消息队列(Queue);

            //队列结构
            public class MessageQueue {
              private String topic;
              private String brokerName;
              private int queueId;
            }


        *****
          特别注意点，当存在多个主节点时，一条消息只会发送到其中一个主节点。
          rocketmq对于多个master节点的消息发送，会做负载均衡，使得消息可以平衡的发送到多个master节点上。
          RocketMQ是通过多Master实现了对Producer发送消息的负载均衡，而不是kafka那样通过分区分片存储实现Producer发消息负载均衡
        *****

        异步刷盘(推荐)
          当执行消息写入操作时，当消息写入到内存中时，就返回写成功状态。当内存中的消息量积累到一定量时，统一触发写磁盘动作。
        同步刷盘
          当执行消息写入操作时，同步写入内存和磁盘中后才返回写成功状态

        异步复制
          当执行消息写入操作时，只要 Master写成功即可反馈给客户端成功状态
        同步复制(推荐)
          当执行消息写入操作时， Master和 Slave 均写成功才反馈给客户端成功状态


      生产者端
        如果是生产者端由业务暴增引起的生产过快，而消费者端消费能力不足，这个时候就可以采取生产者端限流或者进行消费者扩容；
        这个时候要注意，如果生产者只是短期暴增或者消息的业务不是很重要可以采用限流，如果是长期暴增真正的业务量上涨就必须要进行消费者扩容。
        一般也不考虑生产者，因为本质上是消费者消费能力不足

        限流，被拒接的请求，直接返回给调用者，也可以进行排队
              1.0和1开关
              2.设置固定值(每秒请求次数QPS)，超过请求次数，拒绝请求。
               
      消费者端
        比如说消费者挂了，然后broker堆积了很多消息，然后可以先把堆积的消息读到别的地方比如mysql或者es然后去后续进行处理，然后把RocketMQ堆积的消息删掉，启动消费者保障消费者正常消费，这里要注意的是删除堆积消息之前，需要停止mq

        *****
          这个时候我们可以先把一部分消息先打到另外一个MQ中或者先落到日志文件中，再拓展消费者进行消费，优先恢复上游业务。比如redis中设置了开关
          总结下来就是，出现堆积后防止业务出现写入异常，需要把消息队列清出一份容量出来，也就是保证消息时序的情况下先将消息快速消费到一些速度更快的存储上，事后再写程序处理。
        *****

        我之前的是，消费者挂了，持久化，后续再后台一条一条去发送消费，本质还是，持久化积压消息，然后补偿发送，还有一个就是注意是发送端问题还是消费端问题
        
        rocketmq的消息模型简单来说，producer投递消息到topic中的各个队列，各消费者组订阅topic,消费者组中的消费者并行消费队列中的消息

        RocketMQ 消息积压了，增 加消费者有用吗？
          https://baijiahao.baidu.com/s?id=1727529346182059031

          如果消费者的数量小于 MessageQueue 的数量，增加消费者可以加快消 息消费速度，减少消 息积压。
          比如一个 Topic 有 4 个 MessageQueue，2 个消费者进行消费，如果增加一个消费者，明细可以加快拉取消息的频率。

          特殊情况是，消费者消息拉取的速度也取决于本地消息的消费速度，如果本地消息消费的慢，就会延迟一段时间后再去拉取。
          其实延迟拉取的本质就是消费者消费慢，导致下次去拉取的时候 ProcessQueue ·
          消费者消费慢，可 是能下面的原因：
          消费者处理的业务逻辑复杂，耗时很长；
          消费者有慢查询，或者数据库负载高导致响应慢；
          缓存等中间件响应慢，比如 Redis 响应慢；
          调用外部服务接口响应慢

          如果消费者的数量大于等于 MessageQueue 的数量，增加消费者是没有用的。
          比如一个 Topic 有 4 个 MessageQueue，并且有 4 个消费者进行消费。

        *****
          解决方案
            可适当增加broker的读写队列数，防止，某一broker单条消息堆积引起队列消息总体延迟的情况
            增加服务实例数量，提高消费能力
            扩容broker实例，多m
            临时积压，可以加开关，先将积压的消息入库或者打到另外一个MQ中或者先落到日志文件中，后续慢慢消费
        *****


      mq事务事务消息
        1.事务消息发送及提交：
        (1) 发送消息（half消息）。
        (2) 服务端响应消息写入结果。
        (3) 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）。
        (4) 根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可见）。
        2.补偿流程：
        (1) 对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查”。
        (2) Producer收到回查消息，检查回查消息对应的本地事务的状态。
        (3) 根据本地事务状态，重新Commit或者Rollback。
        其中，补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。


        这里有个half message变为消费者可以消费的消息 或者 抛弃half message的动作

        长时间没有消费的half message，Broker要去Producer回查结果

          消息队列：目前RocketMQ中支持事务消息，它的工作原理是：
              a. 生产者订单系统先发送一条half消息到Broker，half消息对消费者是不可见的
              b. 再创建订单，根据创建订单成功与否，向Broker发送commit或rollback
              c. 并且生产者订单系统还可以提供Broker回调接口，当Broker发现一段时间half消息没有收到任何操作命令，则会主动调此接口来查询订单是否创建成功
              d. 一旦half消息commit了，消费者库存系统就会来消费，如果消费成功，则消息销毁，分布式事务成功结束
              e. 如果消费失败，则根据重试策略进行重试，最后还失败则进入死信队列，等待进一步处理


      mq顺序消费

        可以指定一个MessageQueueSelector。通过这个对象来将消息发送到自己指定的MessageQueue上。这样可以保证消息局部有序。  
        mq中，相同id发送到同一个队列，一个队列的消息只由一个消费者处理，实现顺序消费


        如果采用先将消息消费到日志文件的方式，怎么保证时序性？
            一般消息队列都有时序问题，我们需要根据业务，对消息进行分区路由，比如根据用户纬度，只保证同一个用户的消息时序就行了，比如我把id为1～10000的用户写在一个文件中，10001～20000的写在一个文件中。后面按这个文件单独消费就能保证消息的时序。

        发送端使用顺序消息，MessageQueueSelector
        消费端用MessageListenerOrderly 来接受消息，无序的是MessageListenerConcurrently接受


        但这个顺序，不是全局顺序，只是分区顺序。要全局顺序只能一个分区。
        消息发送默认是轮询，发送到不同队列分区，所以要想顺序，必须要放在同一个分区中
        而消费端消费的时候，是会分配到多个queue的，多个queue是同时拉取提交消费。


        但是同一条queue里面，RocketMQ的确是能保证FIFO的。那么要做到顺序消息，应该怎么实现呢——把消息确保投递到同一条queue

        按照这个示例，把订单号取了做了一个取模运算再丢到selector中，selector保证同一个模的都会投递到同一条queue。
        即： 相同订单号的--->有相同的模--->有相同的queue。

        而消费端消费的时候，是会分配到多个queue的，多个queue是同时拉取提交消费。
        rocketMQ中提供了基于队列(分区)的顺序消费。


        SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
                    @Override
                    public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
                        Long id = (Long) arg;  //根据订单id选择发送queue
                        long index = id % mqs.size();
                        return mqs.get((int) index);
                    }
                }, orderList.get(i).getOrderId());//订单id


          默认情况下，消费者是循环往topic下所有的messageQueue上写消息的，然后messageQueue会被分配给某个consumer去消费的。
          如果messageQueue有多个，producer生产消息是轮询messageQueue的，这样生产端就无法保证将消息顺序的写入到rocketmq，
          然后消费者，messageQueue只能被一个consumer取消，因为消息是分散在各个messageQueue上的，无法保证消费的先后顺序

          并且很多情况下，并不需要全局有序，只需要有特定联系（如状态流转）的消息实现有序就行，

          如一个订单的状态流转时的通知消息（orderId相同，状态: 生成->支付->发货->收货->....）

          分区有序
          只要保证特定联系的消息（如orderId相同）一定会发送到同一个messageQueue，保证有特定联系的消息按照顺序就行

          //顺序生产
            public static void main(String[] args) throws MQClientException, RemotingException, InterruptedException, MQBrokerException {
                logger.info("producer start ...");
                DefaultMQProducer producer = new DefaultMQProducer("ProducerGroupName1");
                producer.setNamesrvAddr("127.0.0.1:9876");
                producer.start();
            
                Long orderId = 1000L;
                Message message = new Message("TopicTest3", "TAGA", "测试事务消息".getBytes());
                producer.send(message, new MessageQueueSelector() {
                  @Override
                  public MessageQueue select(List<MessageQueue> mqs, Message msg, Object bizId) {
                    //bizId == orderId,可以保证是每个订单进入同一个队列
                    Integer id = (Integer) bizId;
                    int index = id % mqs.size();
                    return mqs.get(index);
                  }
                }, orderId);
            
                producer.shutdown();
              }
              
            
          // 顺序消费
            consumer.registerMessageListener(new MessageListenerOrderly() {
              @Override
              public ConsumeOrderlyStatus consumeMessage(List<MessageExt> msgs, ConsumeOrderlyContext context) {
                for (MessageExt ext : msgs) {
                  String result = new String(ext.getBody());
                  logger.info("消费消息[queueId:{}:{}]:{}", ext.getQueueId(), ext.getQueueOffset(), result);
                }
                return ConsumeOrderlyStatus.SUCCESS;
              }
            }) ;

          MessageListenerConcurrently  和  	MessageListenerOrderly

          并发消费时，启动定时任务：定时清理超时的消息
          顺序消费时，启动定时任务：定时向broker发送锁定messageQueue消息，表明这些messageQueue现在被我消费了



    实际使用生产者的组是，rocketmq.producer.order.citic=citicOrderProducer
    消费者的组是，rocketmq.consumer.order.egj=EgjOrderConsumer
    两个订阅的都是同一个topic，TOPIC_EGJ_ORDER，

    topic表示一类消息，每个主题有若干条消息
    一个consumer只能订阅一个topic   
    一个producer可以生产多种topic
    默认是4个队列
    //Number of queues to create per default topic.
    private volatile int defaultTopicQueueNums = 4;


    一个topic可以多个队列
    topic中的一个queue只能被同一个consumer组中的一个消费者所消费

    Group
    分组，一个组可以订阅多个Topic。
    分为ProducerGroup，ConsumerGroup，代表某一类的生产者和消费者，
    一般来说同一个服务可以作为Group，同一个Group一般来说发送和消费的消息都是一样的

    Message Key
    Key 一般用于消息在业务层面的唯一标识。对发送的消息设置好 Key，以后可以根据这个 Key 来查找消息。

    Tag
    消息标签，二级消息类型，用来进一步区分某个 Topic 下的消息分类。
    Topic 与 Tag 都是业务上用来归类的标识，区分在于 Topic 是一级分类，而 Tag 可以理解为是二级分类。结构更清晰

    //发送案例
      Message msg = new Message(topic, tag ,key, content.getBytes());
			SendResult sendResult = null;
			sendResult = producer.getDefaultMQProducer().send(msg);

			// 当消息发送失败时如何处理
			if (sendResult != null
					&&sendResult.getSendStatus() != SendStatus.SEND_OK) {
				logger.warn("消息发送成功 key:{},content:{}",key,content);
			}else{
				logger.warn("消息发送成功 key:{},content:{}",key,content);
			}


### 1.222
      get post
      http请求nginx过程
      请求sessionid的过程
      springsession的拦截过程
      jenkins提到了shell脚本和ansible部署
      还是最终一致
      多个线程实现时间不一致，三个都好了再执行另一个动作，使用计数器即可
      nginx使用
      git分支相关
      服务拆分
      双语国际化可以弄下

### 2.111

      数据千万，分页，200w后的10页
            *****对limit的优化，不是直接使用limit，而是首先获取到offset的id，然后直接使用limit size来获取数据。*****

            这里使用索引覆盖
            主要思想：通过索引覆盖查询来查出必要的需要扫描的行(比如主键id等排序关键字段)，然后再去扫描实际的数据行
            用子查询/连接+索引快速定位元组的位置,然后再读取元组
            select * from news where cate = 1 and id > (select id from news where cate = 1 order by id desc limit 500000,1 ) order by id desc limit 0,10 

            1.采取的是限制分页(只查看前几千条数据)和增加缓存(记录上次查询的最大id，带到下次查询中筛选)。
            2.用到的是索引覆盖，先查出offset的id，然后limit size

            语句样式: mysql中,可用如下方法: SELECT * FROM 表名称 LIMIT M,N
            适应场景: 适用于数据量较少的情况(元组百/千级)
            原因/缺点: 全表扫描,速度会很慢 且 有的数据库结果集返回不稳定(如某次返回1,2,3,另外的一次返回2,1,3). Limit限制的是从结果集的M位置处取出N条输出,其余抛弃.

            limit语句的查询时间与起始记录的位置成正比

            这两个是等效的
            那么如果我们也要查询所有列，有两种方法，一种是id>=的形式，另一种就是利用join，看下实际情况：
            SELECT * FROM product WHERE ID > =(select id from product limit 866613, 1) limit 20
            查询时间为0.2秒！

            另一种写法
            SELECT * FROM product a JOIN (select id from product limit 866613, 20) b ON a.ID = b.id

      redis事务
        redis事务就是一次性、顺序性、排他性的执行一个队列中的一系列命令
               本质是一组命令的集合，打包执行

               执行步骤
                  MULTI    开始事务。
                           命令入队。        多命令会入队到事务队列， 按先进先出(FIFO)的顺序执行
                  EXEC     执行事务。

               单个 Redis 命令的执行是原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所以Redis事务的执行并不是原子性的。
               事务可以理解为一个打包的批量执行脚本，但批量指令并非原子化的操作，中间某条指令的失败不会导致前面已做指令的回滚，也不会造成后续的指令不做


      redis日排行
        使用redis的SortedSet实现，有序不重复，简称是zset
        Sorted Set数据类型就像是set和hash的混合

        ZADD key score member
        zset 通常包含 3 个 关键字操作：
        key (与我们 redis 通常操作的 key value 中的key 一致)
        score (排序的分数，该分数是有序集合的关键，可以是双精度或者是整数)
        member (指我们传入的 obj，与 key value 中的 value 一致)


        ZCARD key 返回集合数量。
        ZREM [key] [value]  删除key

        ZUNIONSTORE 取集合的并集
        ZUNIONSTORE hotnews:week:1 2 hotnews:1 hotnews:2

        ZUNIONSTORE destination numkeys key [key ...] [WEIGHTS weight [weight ...]] [AGGREGATE SUM|MIN|MAX]
        计算给定的一个或多个有序集的并集，其中给定 key 的数量必须以 numkeys 参数指定，并将该并集(结果集)储存到 destination 。
        默认情况下，结果集中某个成员的 score 值是所有给定集下该成员score值之和。


        使用 WEIGHTS 选项，你可以为 每个 给定有序集 分别 指定一个乘法因子(multiplication factor)，每个给定有序集的所有成员的 score 值在传递给聚合函数(aggregation function)之前都要先乘以该有序集的因子。如果没有指定 WEIGHTS 选项，乘法因子默认设置为 1 。

        AGGREGATE
        使用 AGGREGATE 选项，你可以指定并集的结果集的聚合方式。
        默认使用的参数 SUM ，可以将所有集合中某个成员的 score 值之 和 作为结果集中该成员的 score 值；使用参数 MIN ，可以将所有集合中某个成员的 最小 score 值作为结果集中该成员的 score 值；而参数 MAX 则是将所有集合中某个成员的 最大 score 值作为结果集中该成员的 score 值。



        添加：zadd 2kshoot 100 curry
        加减：zincrby 2kshoot 2 harden
        排序：zrange 2kshoot 0 2 withscores           倒序，zrevrange ，withscores为输出结果带分数


        获取某个member的排名，按score从小到大排名，从0开始，  main_rds.zrank(name,member)
        
        场景如下：视频点播系统，每天观看的人很多。该系统有个榜单功能，展示观看量最多的视频。分为今日榜单、三日榜单、一周排行、月榜单。
        思路：首先是按天统计视频观看次数，然后再统计出今日榜单、三日榜单等。

        日分榜单，
          ZINCRBY rank:20170301 5 1     增加日内积分     这里1是用户id，5是得分

      redis内存策略
      docker日志，也就查看日志了
        docker logs -f -t --tail 100 xye-soa  // 查看容器日志
      线程执行顺序  同上，排序看a,b即可，大同小异

      redis锁过期
        锁延期

      Threadlocal的泄漏问题
        内存泄漏归根结底是由于ThreadLocalMap的生命周期跟Thread一样长。如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。
