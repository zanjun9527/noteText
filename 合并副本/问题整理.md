重核

设计模式，单例模式
分布式事务
秒杀系统
  核心思想：层层过滤，尽量将请求拦截在上游，降低下游的压力，逐渐递减瞬时访问压力(主要是数据库的压力)
  流程， 用户抢购（请求）->是否是异常用户（账号安全检查,ip检查等）->缓存中的库存是否足够（商品库存检查）->扔给mq去慢慢操作->异步消费订单处理，附带超时补偿操作


  有效请求和无效请求
      1.针对一个用户的无效恶意请求，可以增加图片验证码
      2.短信验证，进一步的限制请求，比如限制用户在单位时间的操作次数，降低请求量， 
      3.一人多账号的，最终集中到实名那步，限制到人信息即可
      4.多人多账号的，僵尸账号排除法，平时没交易，只在特殊节日交易
      5.当然还能使IP封禁，尤其是通过同一IP或者网段频繁请求的，但是可能误伤有效请求，需注意


  充分利用缓存与消息队列，提高请求处理速度以及削峰填谷的作用
  针对扣库存的地方，利用redis实现分布式锁(一般是集群，用分布式锁),锁住针对库存的减操作。可以使用redisson已经有对 Reentrantlock的封装操作。


平台提升即可，在公司的主要工作内容，技术只谈技术，杂的和别人谈
尊重和平等




## 数据结构
treeMap的自定义排序（comparator，排list<entry>或者key，key是初始化比较器）

hashmap的不安全性在于多个线程同时resize时候，但是有的执行完 有的正在resize，这样数量就会出现问题。所以要加锁控制
定位的时候，先hash定位数组，在key定位链表位置（链表中元素超过8个时，就将链表转化为红黑树）
扩容，初始容量为 16，负载因子为 0.75 的 HashMap。超过16*0.75=12，就扩容一倍，并重新散列

ConcurrentHashMap主要特点，分段锁Segment，默认16段

ConcurrentHashMap = Segment[] 和 HashEntry[] 组成
一个Segment里包含一个HashEntry数组,本身segment继承ReentrantLock实现锁控制(这里是jdk7，jdk8有变化)

通过两次Hash定位到元素位置，第一次是定位segment，第二次是定位hashEntry。

确定该元素的放在哪个Segment；再确定该元素放置在哪个HashEntry


了解即可
JDK1.8的实现已经摒弃了Segment的概念，而是直接用Node数组+链表+红黑树的数据结构来实现，并发控制使用Synchronized和CAS来操作，整个看起来就像是优化过且线程安全的HashMap。
虽然在JDK1.8中还能看到Segment的数据结构，但是已经简化了属性，只是为了兼容旧版本。


HashSet通过 hashCode 值来确定元素在内存中的位置。一个 hashCode 位置上可以存放多个元素。
哈希值相同 equals 为 false 的元素，就是在同样的哈希值下顺延（可认为哈希值相同的元素放在一个哈希桶中）。也就是哈希一样的存一列。类似map


## 线程相关
线程池介绍，工作机制,优点
  线程池的工作流程和包和策略，主要核心线程参数corePoolSize,maximumPoolSize，队列等

  流程：corePoolSize - 工作队列(workQueue) - maximumPoolSize,必要时创建非核心线程，满了交给饱和策略(无法处理新任务时抛出异常)

  使用线程池的好处:
  线程池可以减少创建和销毁的开销，避免频繁切换线程，任务调度
  控制线程数量,集中管理线程

ExecutorService 接口继承了Executor 接口，是Executor 的子接口
Executors是工具类(创建线程池)，他提供对ThreadPoolExecutor的封装产生ExecutorService的具体实现类


创建三种线程池，
ExecutorService executorService = Executors.newFixedThreadPool(11);
newSingleThreadExecutor()
newFixedThreadPool(int numOfThreads)
newCachedThreadPool()


executorService.submit()方法可以接收Runnable和Callable接口对象,后者有返回Future对象，get()获取

阻塞优化
使用CompletionService按照线程完成顺序获取，原始的是按加入线程池顺序(submit顺序)的阻塞
监听future返回结果阻塞问题，引入Guava Future
使用ListenableFuture Guava帮我们监听检测Future是否完成了，如果完成就自动调用回调函数，不必手工get数据

事务特性 ACID   
原子性、一致性、隔离性和持久性

ThreadLocal对象本质是操作Thread.ThreadLocalMap<ThreadLocal, Object>这个对象

线程中断的概念
只是加中断标记，不立刻执行，按需终止。
interrupt加标记，isInterrupted()判断后决定是否去终止

终止线程常用
1.正常运行结束
2.Interrupt中断
3.异常终止


常见方法 sleep，wait，nofity，yield
wait() 和 notify() 实现的基础是基于对象存在

所有的对象都会有一个wait set，用来存放调用该对象wait方法之后进行block状态的线程。
线程从wait set中唤醒的顺序不一定是FIFO(先入先出模式)。但是线程被唤醒后，必须重新获取锁

interrupt
给线程设置中断状态，只设置状态，不会立刻停止，后续可检查自己的中断状态isInterrupted()，自行判断要做啥

阻塞：等待，sleep，io阻塞，同步阻塞

对象的等待队列WaitQueue中，进入等待状态

java内存模型
线程生命周期
线程实现方式 3种


ThreadLocal，主要用作隐式传参，
Threadlocal操作对象，是获取当前线程的Threadlocalmap对象，线程独享，key是Threadlocal对象，value是待存值，
本质就是操作Thread.ThreadLocalMap<ThreadLocal, Object>这个对象


线程的生命周期：新建（start），就绪，运行，阻塞（synchronized，sleep，wait，可以notify唤醒），死亡




### 锁相关
常见的锁类型，自旋锁，偏向锁，轻量级锁，可重入锁，公平锁，非公平锁，乐观锁，悲观锁

实现分布式锁
内存模型(工作内存，主内存，堆栈内存)
线程访问对象值时，先通过对象引用找到对应在堆内存的变量的值，然后load到本地内存，建立变量副本，最后再回写回去，也就是所说的线程工作内存和主内存之间的操作。

CountDownLatch 也可以实现join功能
a，b，c三个线程执行顺序,   a>(b,c)
CountDownLatch(1)，countDown() 和  await()
Semaphore(0)，acquire() 和 release()

当一个线程进入一个对象的 synchronized 方法A 之后，其它线程是否可进入此对象的 synchronized 方法B，不能
对于同一个对象obj的两个synchronized方法a，b，一个线程占用方法a后，另一个线程不能进入对象的方法b，因为这里是前者线程持有了obj的锁，锁的是整个实例对象

自旋锁使用场景
自选等待时间小于持锁时间，减少线程切换

condition是对wait方法的补充，可以选择唤醒顺序
synchronized 和 lock
公平，可重入，可中断

Lock 和 synchronized 的区别
可中断、公平锁、多个锁，获取锁状态tryLock，手动释放锁，系统自带和api级别
ReentrantLock可能通过Condition来控制各个低粒度的边界

悲观锁和乐观锁
使用场景
select for update
version



分布式锁，常用的是redis的setnx搭配expire(改进版是getset()方法)，或者zookeeper锁，使用了目录节点的唯一性
expire()命令对 lockkey 设置超时时间，为的是避免死锁问题。（这里宕机会出现死锁问题）


## spring,mvc,mybatis相关
    动态代理
      jdk-invocationhandler,ciglib-MethodInterceptor
      Proxy.newProxyInstance(target.getClass().getClassLoader(), i.getClass().getInterfaces(), this);

    常用aop是@Aspect
    所有的service在注入使用时候，都是使用的代理对象，这样可以实现事务控制
    
    当@service标注的bean在容器中检查到有@transaction，则会创建一个代理对象，
    开启事务--->创建sqlsession--->使用jdbc连接执行sql--->最后提交事务
    client-aop动态代理-@transaction-service-@transaction提交或回滚，实质上service是被aop代理了，



    事务
      编程式事务，允许用户在代码中精确定义事务的边界，侵入业务代码，使用 TransactionTemplate,直接事务模板处理，可以返回自定义的result。
      声明式事务，基于AOP，有助于用户将操作与事务规则进行解耦。@transactional

      事务自调用失效
         方法：1.使用注入的service调用， 2.从springcontext中获取bean(是一个代理对象)，调用也行

         必须是走代理才能使用事务
        
      隔离级别(默认可重复读) 和 事务传播行为

    主流初始化，使用@PostConstruct注解初始化,Bean实现InitializingBean 接口
      
    解决springbean循环依赖
        解决方案：
        1.spring的循环依赖问题：在注入@Autowired 下加@Lazy 注解即可(两边都加比较保险)
          Spring的懒加载是在需要用到bean的时候，就是getBean的时候才创建，这样就不会报BeanCurrentlyInCreationException。
        2.将相互依赖的两个Bean中的其中一个Bean采用Setter注入(也就是属性注入)的方式即可。

    springbean生命周期
      主要的是4个关键阶段和多个扩展点(实现Aware接口)
        1.实例化 Instantiation		对应构造方法
        2.属性赋值 Populate		    对应setter方法的注入
            扩展：检查Spring Awareness 这里是一个扩展点  基本都实现了aware接口
        3.初始化 Initialization			beanpostprcessor，初始化前后自定义初始化逻辑。所有Aware接口的注入就是在这前置完成的。
        4.销毁 Destruction


    属性赋值
      @PropertySource("classpath:application.properties")		#添加自定义的属性文件进来,将属性文件加入到容器，后续可以直接用@value注入
      @ConfigurationProperties(prefix = "application.dubbo.demo.server")	#写在类上，省略前缀，匹配后面的名字，但是注意要有set方法


    mvc和spring是父子容器关系

    mvc流程
      request-dispatcherservlet-HandlerExecutionChain-handler-mv给dispatcherservlet-视图解析

    mybatis会为mapper接口生成一个动态代理，去处理相关的实现逻辑

    sqlsession 会话，SqlSession中定义的全是对数据库增删改查的各种方法，mybatis的核心接口对象、
        类似jdbc中的connection对象，代表一个连接资源的启用。1.获取mapper接口，2.发送sql给数据库 3.控制数据库事务
        存在一个业务请求中，操作事务，请求完成，关闭连接，归还给sqlsessionfactory。


    级联查询
    mybatis不支持多对多，可以拆分成两个一对多级联处理。暂时忽略
		1. 关联-association				用于一对一
		2. 集合-collection				用于一对多

    mvc全局异常
      @ControllerAdvice 或者 实现接口handlerExceptionResolver


    PageHelper原理也是使用了threadlocal变量


     ***核心思路***
         mapper的动态代理，最后核心处理方法是sqlsession对象去运行对应的sql。mapper通过关联xml中的namespace，找到对应的执行方法。
         sqlSessioη.getMapper(RoleMapper.class);
         configuration.<T>getMapper(type, this)
         最终代理的是sqlsession的操作。通过namespace将sql和代理对象绑定起来
    ***核心思路***

  创建拦截器两种方法
      1.继承HandlerInterceptorAdapter类，可重写其中一个或多个方法
      2.实现HandlerInterceptor接口，需要同时实现其中三个方法

  sqlsession					
        会话，SqlSession中定义的全是对数据库增删改查的各种方法，mybatis的核心接口对象、
        mybatis中的主要操作对象
        类似jdbc中的connection对象，代表一个连接资源的启用。1.获取mapper接口，2.发送sql给数据库 3.控制数据库事务
        存在一个业务请求中，操作事务，请求完成，关闭连接，归还给sqlsessionfactory。

  			
  演示动态代理mapper的生成
        ProductMapper productMapper = sqlSession.getMapper(ProductMapper.class) ;
				Product product= productMapper.getRole(productid);




## boot相关
    自动配置原理
      自动配置是通过spring-boot-autoconfigure的jar包实现的(配置核心)，其中有很多的配置类，加载默认配置。

      1. @SpringBootApplication启动入口，是boot的入口
      2. boot在springapplication对象实列化时会加载META-INF/spring.factories文件，将该文件中的配置加入到spring的容器（对应是各自功能的AutoConfigurationBean
      3. 根据条件注解@ConditionalOnMissingBean等，配置相关的功能bean(由jar引入)，）各bean根据属性读取自动配置
		
      @conditionalOnClass、@ConditionalOnMissingBean实现自动的条件加载

      简单的说就是1.启动类入口，2.引入jar，读取spring.factories文件，搭配条件注解实现自动加载

      实际上spring.factories的作用就是做上下文初始化，加载配置文件中的bean到Ioc容器，加载配置项等。
      springboot执行时或扫描所有的META-INF/spring.factories的内容，会将classLoader加载类路径下的所有spring.factories的配置内容，loadSpringFactories方法将返回一个key=接口名，value=实现类集合的Map结构。

      *****
        启动自动装配流程
          主要模块spring-boot-autoconfigure 的jar负责
          1.启动类入口
          2.通过SpringFactoriesLoader加载META-INF/spring.factories中的配置，各个jar引入
          3.在结合 @Conditional 对加载到的自动装配配置bean进行过滤，从而实现模块的自动装配
              @conditionalOnClass、@ConditionalOnMissingBean实现自动的条件加载
            （如果自动装配bean能够被ComponentScan扫描到，不配置到META-INF/spring.factories中也是会生效的）
      *****


    web方面的配置
      WebMvcConfigurer接口，主要是配置拦截器，过滤器，servlet，静态资源等一些web配置。


    拦截器，过滤器，Servlet

    过滤器，Servlet，关注的是前者的dofilter(),后者的service()方法，其他就是初始化和销毁方法
    拦截器prehandle、posthandle 和 aftercompletion

    prehandler按顺序执行，posthandler，afterCompletion按拦截器配置的逆向顺序执行


## jvm相关
类加载 双亲委派(向上递归检查，向下递归加载),一个类只能被一个类加载器加载
  双亲委派机制，就是一个类只能被一个类加载器加载，不会重复加载

  采用双亲委派的一个好处是比如加载位于 rt.jar 包中的类 java.lang.Object，不管是哪个加载器加载这个类，最终都是委托给顶层的启动类加载器进行加载，这样就保证了使用不同的类加载器最终得到的都是同样一个Object对象

  向上递归检查，向下递归加载
  原则：1.自底向上检查类是否已经装载  2.自顶向下尝试加载类
  逐层往上(接待就返回，没有就抛给上层，直到有一级接待或者上级返回没有接待且不应由上级接待，那么本层就会加载)

  类加载器一般是三层的classLoader， 启动类加载器 BootstrapclassLoader:   扩展类加载器 ExtClassLoader： 应用程序类加载器 AppClassLoader：



JVM 参数，线上问题
生产线上内存参数配置多少
分代回收，年轻代、老年代
大对象直接进入老年代

内存三大部分，堆,栈,方法区
判断对象存活，根路径可达性

什么情况下触发垃圾回收？
minor GC: 当 eden 区满以后会触发。
Full GC：
          当老年代空间不足以支持下一次 Minor GC 时会触发一次 Full GC
          发生minor gc时，虚拟机会检测之前每次晋升到老年代中的平均大小是否大于老年代的剩余空间大小，若大于，则改为直接进行一次full gc


## 分布式
  cap理论，

  一般是ap
  一致性(Consistency) ：  强一致性,    客户端知道一系列的操作都会同时发生(生效)，数据一致更新，所有数据变动都是同步的。最终一致和强一致性  这里一致性用最终一致即可。
  可用性(Availability) ： 高可用性,   每个操作都必须以可预期的响应结束，这是集群概念
  分区容错性(Partition tolerance) ：分布式容忍性,  即使出现单个组件无法可用,操作依然可以完成，这是模块的概念


  分布式事务常见方案，二三阶段提交，tcc, 补偿型

  一致性可以减点，其他两个重要，主要是ap


## mysql相关

      每个索引在InnoDB里面对应一棵B+树，索引的b+树结构
      id索引对应一个B+树索引结构，主键索引的叶子节点存储了整行的记录，就是数据本身
      普通列class_id也对应一个的索引树，普通索引的叶子节点保存的是其行记录中的id，也就是主键id

      InnoDB数据是存在B+树这一点没错，只不过是存在主键索引构成的B+树中的叶子节点中，普通索引的叶子节点存的是主键id


      联合索引的最左原则

      联合索引，肯定只有一棵B+ 树，联合索引中，最左前缀原则(只针对联合索引)

      建立联合索引，能更大可能实现索引覆盖，因为包括的索引字段变多了

      索引覆盖和回表
      			只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表。
            联合索引更容易实现索引覆盖

      这个叫回表(从普通索引树到主键索引树的二次树查询)，如果查询列是索引本身，一次就ok，不用回表，这里既是索引覆盖到了查询列(索引覆盖)    

      如果辅助索引上已经存在我们需要的数据,那么引擎就不会去主键上去搜索数据了。 ---- 这个就是所谓的"**覆盖索引**"
      其核心就是只从辅助索引要数据。那么, 普通索引(单字段)和联合索引,以及唯一索引都能实现覆盖索引的作用。


    主从架构，(主要作用)数据容灾恢复（主从备份），读写分离暂不做
    主备的，就说是冷热备，
    主从定义：从的存在主要是避免主宕机导致数据丢失。而不是让备机来分担并发压力，所以，主业务建议尽量在主上操作

    降低主从复制延迟的方法：1.写的缓存在客户端侧，2.重要读转发到主服务器上，3.减少延迟	
    主库能处理业务就全放在主库吧（特别是更新后的数据），从库只做灾备，备份，对实时性要求不高的统计报表类工作；
    如果你需要主从的业务时，你可以在中间层加个分布式缓存如redis，缓存组装数据，优先从缓存中读取刚刚写入的数据，


    分库分表后只能是多次查询组装数据，或者是做冗余
    难点扩容，  方法1.将所有的映射关系保存在一个独立的数据库中。好处是不用分片计算
               方法2.还有一张方法是 预算最大的服务器数量,比如是32  先搞两台物理机，2*16个db,之后扩容每次增加一倍，这样通过扩容逐渐减小服务器压力

    sql的优化主要就是针对走不走索引的优化，一般函数，in，null列，%开头，<>等都不走索引


## io相关
字节流继承于inputStream和outputStream
字符流继承于inputStreamReader和outputStreamwriter

二者的转换
使用流进行序列化和反序列化，objectoutputStream 和 objectinputStream
只处理纯文本优先用字符流（用writer和reader操作），其他都用字节流，

nio的优点

nio 主要就是一个线程对应多个socket连接,多路复用的核心是，多个socket复用一个线程

Java NIO 实际上就是多路复用IO，通过一个线程就可以管理多个socket(一个线程不断去轮询多个socket的状态)，只有当socket 真正有读写事件发生时，才调用实际的IO来进行读写操作。

Selector(选择器)是 Java NIO 中能够检测到一到多个 NIO 通道，并能够知道通道是否为读写事件做好准备。这样，一个单独的线程可以管理多个Channel，从而管理多个网络连接。


  ***
      nio	主要就是一个线程对应多个socket连接
      Selector(选择区)用于监听多个通道的事件。因此，单个线程可以监听多个数据通道。

      client socket->socketchannel->selector-handle process thread
  ***

IO
    服务器端的socket编程，最早的Java是所谓的阻塞IO(Blocking IO)， 想处理多个socket的连接的话需要创建多个线程， 一个线程对应一个。数量一多，效率降低
    *** 一个线程控制一个socket来读写，容易阻塞 ***
NIO     
    非阻塞IO(NIO：Non-Blocking IO)， 通过多路复用的方式让一个线程去处理多个Socket。	
    *** 一个线程通过一个selector，控制多个socket的读写 ***
    只需要使用少量的线程就可以搞定多个socket了，线程只需要通过Selector去查一下它所管理的socket集合，哪个Socket的数据准备好了，就去处理哪个Socket。



缓冲区
  Buffer的核心作用是用来缓冲，缓和冲击（对输出设备的冲击，包括磁盘、打印机、显示器）。
  比如你每秒要写100次硬盘，对系统冲击很大，浪费了大量时间在忙着处理开始写和结束写这两件事嘛。用个buffer暂存起来，变成每10秒写一次硬盘，对系统的冲击就很小，写入效率高了，

  缓冲区是内存空间的一部分，这些存储空间用来缓冲输入或输出的数据
  对缓冲区的操作速度更快，且减少了磁盘读写次数



NIO 主要有三大核心部分：Channel(通道)，Buffer(缓冲区), Selector。

IO 是面向流的，NIO 是面向缓冲区的。
IO 的各种流是阻塞的，NIO 是非阻塞模式。


为什么nio是非阻塞的
    一个线程可以哪个socket空闲处理哪个，不想原来的每个线程socket都可能阻塞
    一个面向流，一个面向缓冲区

  IO
    服务器端的socket编程，最早的Java是所谓的阻塞IO(Blocking IO)， 想处理多个socket的连接的话需要创建多个线程， 一个线程对应一个。数量一多，效率降低
    一个线程控制一个socket来读写，容易阻塞 
  NIO     
    通过多路复用的方式让一个线程去处理多个Socket。	一个线程通过一个selector，控制多个socket的读写 
    只需要使用少量的线程就可以搞定多个socket了，线程只需要通过Selector去查一下它所管理的socket集合，哪个Socket的数据准备好了，就去处理哪个Socket。

## 数据库
覆盖索引 和 回表查询，mysql的索引树,B+树，B-树结构
隔离级别
InnoDB特点
行级锁都是基于索引的，   用不到索引是不会使用行级锁的，走表锁

namespace+id 作为Map<String,MappedStatement>的key使用，namespace不能重复

 主从数据库不一致问题解决
    1.忽略这个不一致，
    2.强制读取主库，读写都在主库，添加缓存提高性能
    3.选择性读主库，添加一个缓存用来记录必须读主库的数据，将库表键作为缓存的key，设置失效时间为主从同步时间，缓存中没有该数据主键就直接读主库

## 缓存相关
  Redis的内存废弃策略
  MQ如何保证顺序性

  redis的持久化 和主从备份去区别

  缓存同步
    spring session，全部存放在redis中
    之前是tomcat简单session缓存共享(现在已经不用，忽略)  Tomcat-redis-session-manager
    SpringSession 技术是解决同域名下的多服务器集群session共享问题的,实现了单点的缓存共享
    配置的springSessionRepositoryFilter必须得是在所有filter的前面。用了springsession后，已存储在redis的session中




  查询级别缓存 用springcache
    针对mybatis的一二级缓存，实际使用springcache更好
    范围可以到service级别
    引入springcache，需要自定义缓存管理器，场景：高查询  低改动
	  默认使用rediscache，最终存在Redis中，可跨系统

  redis常用的就是常用string和hash(类似map结构)

  redis持久化方式：
  rdb           
    默认的存储方式，默认写入dump.rdb的二进制文件中，可以配置redis在n秒内如果超过m个key被修改过就自动做快照
 
  aof
    默认是everysec  同步到磁盘

  键值回收  
     redis采用的是定期删除+惰性删除策略  
     补充操作，内存淘汰机制allkeys-lru，当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key
    
     如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用内存淘汰机制。 
     默认是，allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。


    定期删除：每隔100ms就随机抽取一些，有的可能删不掉

  redis的主从，主备 和持久化
    前者侧重读写分离，高可用
    后者侧重重启redis，恢复数据

  主从同步，绝大多数的迁移步骤，先迁移整体，同时开启临时记录区域，同步进行，延迟性可以通过临时缓存解决


这里单点用的是sringsession结合redis使用共享缓存
本质上还是使用了cookie的共享和redis缓存的共享，sessionid本质是获取用户信息数据。


## 事务相关
编程式事务侵入到了业务代码里面，但是提供了更加详细的事务管理；而声明式事务由于基于 AOP


## 消息队列

特点：异步处理，流量削峰

关注的地方有，消息可靠性，幂等性

业务去重 和 索引，唯一键，分布式锁


1.数据库联合唯一键去重， 2.业务状态查询去重，3.redis这种分布式锁，redis-key的去重（唯一流水号）

rocketmq
  采用的是发布-订阅的模式，系统使用的是2master模式，简单实用
  RQ的基本组成包括nameserver、broker、producer、consumer四种节点，前两种构成服务端，后两种在客户端上。
  broker存储消息(消息存储与转发)，namesrv（路由管理,功能类似zookeeper）

  生产者发送msg发送给namesrv（路由管理,功能类似zookeeper），namesrv路由后通过broker存储转发消息到consumer集群，再消费给consumer(配合listener订阅topic)
  开启vpn会使rocketmq的broker的ip地址发生变化
  客户端是先从NameServer寻址的，得到可用Broker的IP和端口信息，然后自己去连接broker。

  producer生产消息，consumer消费消息，broker存储消息(消息存储与转发)，broker可以是集群部署，其中topic位于broker中
  rocketmq的消息模型简单来说，producer投递消息到topic中的各个队列，各消费者组订阅topic,消费者组中的消费者并行消费队列中的消息


   Producer:　生产者生产消息到broker,broker接受消息写入topic，需要ack确认。消费同理
   Topic:表示一类消息的集合，每一个主题包含若干条消息，每条消息只能属于一个主题，是RocketMQ进行消息订阅的基本单位


  集群消费模式，消费一次
  消费者中同一个Group中的实例，在集群模式下，以均摊的方式消费；在广播模式下，每个实例都全部消费。

  ******这里一般是监听某个group下的某个topic******
        defaultMQPushConsumer = new DefaultMQPushConsumer(consumerGroup);
        defaultMQPushConsumer.setNamesrvAddr(namesrvAddr);
        defaultMQPushConsumer.setVipChannelEnabled(false);
        // 订阅指定中信topic下tags不限制
        defaultMQPushConsumer.subscribe(MQConstants.TOPIC_CITIC_ORDER, "*");
        // 设置Consumer第一次启动是从队列头部开始消费还是队列尾部开始消费<br>
        // 如果非第一次启动，那么按照上次消费的位置继续消费
        defaultMQPushConsumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);
        // 设置为集群消费(区别于广播消费)
        defaultMQPushConsumer.setMessageModel(MessageModel.CLUSTERING);
        defaultMQPushConsumer.registerMessageListener(...)


可靠性和幂等性

适合解决分布式事务
 mq处理事务
    处理多个服务之间的一致性：后者失败，前者补偿操作，事务不要太多
      1、创建不可见的订单，执行多个小事务，并且这些是同时监听一个回滚topic的，只要有一失败就发送消息到mq，其他的监听到并进行回滚操作
      2、需要执行另一个查询订单状态的任务，异常的全部取消

    ***mq解决分布式事务的思路*****
        分支事务id-总事务id，每个分支事务自己独立执行，失败就回滚，并发送mq，更新总事务失败，其他服务监听到总事务失败自行回滚
    ***mq解决分布式事务的思路*****

    consumer端，最好的是使用统一的消息处理接口，重点重点重点：监听业务有没有操作记录，有记录回退，没有记录不用处理，即每个server都需要做相应的处理，处理逻辑看情况和操作日志来定


## 杂项

dubbo原理
    dubbo默认的配置	
    使用zookeeper作为注册中心，
    dubbo协议作为传输协议，
    使用netty异步传输作为底层通信框架，
    hessian序列化，
    javassist动态代理

    dubbo的线程模型

    dubbo的线程模型中有两个重要角色 ，ThreadPool（业务线程池）和Dispatcher(调度器，调度io线程处理)
    对于Dubbo集群中的Provider角色，有IO线程池（默认无界）和业务处理线程池（默认200）两个线程池，

    Dispatcher，默认是all，所有消息都发送发线程池
    配置成message，只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在IO线程上执行。

    threadpool 默认 fixed 固定大小线程池，启动时建立线程，不关闭，一直持有。(缺省)
         dubbo默认线程池大小200 和tomcat一样,tomcat 可创建的最大线程数默认是200
         dubbo默认线程池是fixed


  客户端，地址列表本地缓存

  常用模块，
    注册模块，注册中的的订阅和发布，
    dubbo的remoting，底层netty的通信
    dubbo的container模块，默认只会启动dubbo-container-spring的这个container，主要负责jar启动，优雅停机
		
    spi机制 服务提供接口 动态加载机制，一种服务发现机制
    javaspi就是提供这样的一个机制：为某个接口寻找服务实现的机制。工具类：java.util.ServiceLoader
    一般是在META-INF/services目录下


    xml中的dubbo标签,自定义标签解析，和spring的类似
    解析类DubboNamespaceHandler，其中定义了xml中标签的解析类,能看到有哪些配置类
		DubboBeanDefinitionParser类根据xml中的内容，加载了dubbo的详细配置，具体的配置类加载。

    *******
					ZK的本质就是为两端提供服务地址的发布/订阅服务，让消费者及时感知最新的服务列表，consumer真正调用provider是通过某种通信协议直接调用，并不依赖ZK。
					即使zk宕机，不影响两端调用，只是让本地缓存的服务列表有可能过时的。
		*******

    RpcContext.getContext().setAttachment,传参用，本质是一个ThreadLocal的临时状态记录器

zookeeper原理
    文件系统和通知机制
    zookeeper中的数据是目录树结构,本身是一个树型的目录服务，每个目录节点为znode，支持变更推送，适合做注册中心.

    znode的结构
        主要属性	
            zxid：	每次变化都会产生一个唯一的事务zxid（整个zk唯一）。通过zxid，可以确定更新操作的先后顺序。
            version:	节点的每次修改，都将使得版本号增加1
            data:		每个znode默认能够存储1M数据

     ZooKeeper的临时节点不允许拥有子节点
        四种类型的znode：  持久 临时 有序
            -持久化目录节点：客户端与zookeeper断开连接后，该节点依旧存在
            -持久化顺序编号目录节点：断开后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号
            -临时目录节点：断开后，该节点被删除，一旦创建这个 znode 的客户端与服务器失去联系，这个 znode 也将自动删除。
            -临时顺序编号目录节点：断开后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号

      所有的增删改查操作都是针对znode节点进行的

      zookeeper提供了文件系统和通知机制，client端会对某个znode建立一个watcher事件，当znode变化时，cleint会受到zk通知并根据变化做出改变
      一种是创建一个唯一路径，只有一个会成功
      如果路径存在，在下面创建临时顺序编号目录节点，编号最小的获取锁


netty原理

单例模式，懒汉饿汉静态内部类，实际推荐静态内部类模式
单例实现方式：构造私有化 + synchronized	实现单例模式的获取(防止多线程同时获取),并提供static访问实例的方法即可


quartz中的三要素，Scheduler、Trigger、JobDetai&Job。

Quartz 中两种可用的Job存储类型：
      * 1.内存存储(RAMJobStore),简单优先的解决方案
      * 2.持久化存储(jdbcjobstore)


### 基础知识


三种加密算法
    单向加密算法
      只能加密数据，不能解密回原来的明文。
      常会拼接一个salt字符串。密文＝ MDS(MDS(明文) + salt)
      常用：MD5,SHA,HMAC
    
    对称加密算法
      又称为单秘钥加密或密钥加密，指加密和解密使用的是相同的密钥
      加密后的信息可以解密成原值	des(适用数据库密码的加密)
      常用：DES,AES,和PBE
    
    非对称加密算法
      也叫公钥加密，就是指加密和解密使用了不同的密钥，一个公钥，一个私钥，公钥加密数据，私钥解密数据。		
      私钥用来签名，公钥用来验证签名。判断公私钥的正确性，就是ca证书做的事。
      私钥能解开公钥加密的数据，但忽略了一点，私钥加密的数据，同样可以用公钥解密出来（公钥是公开的，那么由服务器-》客户端的就存在安全隐患）
      常用： RSA 和 DH，重点RSA


  
HTTPS证书

filter 拦截器，servlet

本地私有仓库nexus，发布jenkins

内存模型中，线程间的变量值传递，需要通过主内存

单点登录主要就是cookie中的缓存和session中的缓存值,判断cookie中没有登录相关name的cookie value,有还要和session的userinfo信息一致，才具有登录信息
先看cookie，再看是否和session中值一致，登录的话，先server端设置session，然后返回客户端认证后写登录cookie，实现登录


shiro 了解即可
    *****
      shiro三大核心模块：Subject（用户）、SecurityManager(框架核心)、Realm（Shiro与应用安全数据间的“桥梁”，主要用来权限校验和密码校验）
      重点是shirofilter  securitymanager，和realm(AuthorizingRealm)。
    *****


简单点说，Java 中的传递，是值传递，而这个值，实际上是对象的引用。
传递的值在栈中，直接拷贝一份值传递，改变的形参不会对实参造成影响
传递的值在栈中存放的是地址（引用），先根据栈中的地址找到在堆上的值，然后把地址拷贝一份（拷贝的地址是一个值），此时形参和实参指向堆上同一个地址，形参的修改导致了实参的改变。


es分词，使用的默认的standard分词，ik是中文分词，前者只能是分成单个字，后者可以分成词语等

官网推荐默认使用的是RestHighLevelClient，添加使用的是indexrequest,搜索使用的是SearchRequest,
多条件查询使用BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery()，然后.must拼接各种query即可
最终是sourceBuilder.query(boolQueryBuilder)---> request.source(sourceBuilder)---> client.search(searchRequest)
查询结构SearchHits hits = response.getHits();然后迭代器迭代后getSourceAsString获取jsonString

最终是client执行SearchRequest，这里的searchRequest组合了BoolQueryBuilder布尔多条件过滤。

复合过滤器，bool（布尔）过滤器。 
其中QueryBuilders是用来生成不同功能的query.



这里的分词是针对搜索词分词，分词后与字段分词对比

matchQuery：模糊查询，会将搜索词分词，再与目标查询字段进行匹配，若分词中的任意一个词与目标字段匹配上，则可查询到。
termQuery：精确查询，不会对搜索词进行分词处理，而是作为一个整体与目标字段进行匹配，若完全匹配，则可查询到


match
	  match中，这里的分词是针对搜索输入的字符串进行分词
term
    term本身搜索的参数字符串不分词，属性词分词后包含参数串即可


term决定查询词不分词，keyword决定文档中的值不分词
查询条件不分词精确匹配分词数据，命中一个分词即匹配

fieldName.keyword决定是否采用es分词数据源，不带keyword即查询text格式数据（分词），带即查询keyword格式数据（不分词）

搜索整段词，
match query中查询，operator：表示单个字段如何匹配查询条件分词，默认是or，设置成and就是全部满足
你直接想查一整个词  加上.keyword，fieldName.keyword	

analyzed字段无法使用term

和原来的正排索引是，找标题，进去找详细字段，倒排就是先找到详细字段，然后关联到具体的文档。
Elasticsearch 使用一种称为 倒排索引 的结构，它适用于快速的全文搜索。
一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表


bool 查询(常用),复合过滤器，组合查询

QueryBuilders.boolQuery()
                .must(QueryBuilders.termQuery(“key”, “value2”))
                .mustNot(QueryBuilders.termQuery(“key”, “value3”))
                .should(QueryBuilders.termQuery(“key”, “value4”))
                .filter(QueryBuilders.termQuery(“key”, “value5”));

  must		文档必须匹配这些条件才能被包含进来。
  must_not	文档必须不匹配这些条件才能被包含进来。
  should		如果满足这些语句中的任意语句，将增加 _score ，否则，无任何影响。它们主要用于修正每个文档的相关性得分。
      返回的文档可能满足should子句的条件.在一个bool查询中,如果没有must或者filter,有一个或者多个should子句,那么只要满足一个就可以返回.
      minimum_should_match参数定义了至少满足几个子句.
  filter		必须匹配，但它以不评分、过滤模式来进行。这些语句对评分没有贡献，只是根据过滤标准来排除或包含文档。


对es的操作最终都是落实到具体的request上
  增，IndexRequest
  删，DeleteRequest
  改，UpdateRequest
  查，searchRequest，组合了boolQueryBuilder多条件查询





服务化的好处，减压，公用，解耦

对接接口安全性   
    1、使用同一的token校验（获取动态口令，优先时间60秒，一般是account-key，先请求key，计入缓存，然后二次请求过来）
    2、增加ip白名单过滤，
    3、使用https证书
    4、增加sign校验

熔断，降级，限流 

   Hystrix断路器，快速失败
   自动阻断对服务的访问和调用，转而调用备用方法，或者快速失败


   限流的维度，01开关，设置固定值(每秒请求次数QPS)，超过请求次数，拒绝请求
        1.根据服务端自身的接口，方法控制，每个负载不一样。
        2.根据来源做控制，设置不同的限制，根据请求来源不同级别进行不同的流控处理。

      对于请求过多的时刻，可以告知用户系统繁忙，稍后再试，从而保证系统持续可用



      当达到阀值 时，后续的请求被降级，比如进入排队页面，比如跳转 到错误页（活动太火爆，稍后重试等）



  断路器很好理解, 当 Hystrix Command 请求后端服务失败数量超过一定比例(默认 50%), 断路器会切换到开路状态(Open). 
  这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态一段时间后(默认 5 秒), 自动切换到半开路状态(HALF-OPEN). 
  这时会判断下一次请求的返回情况,如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN). 


轮询策略，随机，轮询，权重等


tcp三次握手

 对象的序列化主要有两种用途：
      1.把对象的字节序列永久地保存到硬盘上，一般存在文件中；
      2.在网络上传送对象的字节序列。(常用)




 cloud和dubbo等框架的区别
		之前的dubbo，链路，治理，等框架都只是解决了微服务中的某一个问题，没有成体系。
		而cloud是解决微服务架构实施的综合性解决框架。相当于一个组装机，不用像之前一样，自由度高的配置零件。
		之前的类似自己组装电脑，cloud相当于品牌机各个原装组件都配置好了。是整套的实现框架。

cloud的简单模块
  负载均衡：ribbon和feign,采用feign的方式更优雅（feign内部也使用了ribbon做负载均衡）,使用起来就像是调用自身工程的方法
  注册中心: Netflix Eureka。包含客户端和服务端。
  熔断保护： hystrix 
  网关： cloud zuul 网关
  链路追踪： cloud sleuth 



ddos攻击防护，csrf攻击，sql注入，

VisualVM可视化工具使用


jvm相关
一个线程一个栈，一个方法一个栈帧，数据运行时确定

java堆中还可以细分为：新生代（MinorGC，包括eden,from,to）和老年代（MajorGC）

在新生代中，由于对象生存期短，每次回收都会有大量对象死去，那么这时就采用复制算法。minorGc的核心动作是 核心动作 复制-->清空-->互换，年龄+1，默认情况下年龄达到15的对象会被移到老年代

老年代里的对象存活率较高，没有额外的空间进行分配担保，所以可以使用标记-整理 或者 标记-清除。
标记出仍然存活的对象（存在引用的），将所有存活的对象向一端移动，以保证内存的连续，老年代的对象比较稳定，所以MajorGC不会频繁执行。
在进行MajorGC前一般都先进行了一次MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足够大的连续空间分配给新创建的较大对象时也会提前触发一次MajorGC进行垃圾回收腾出空间。

由Eden区、From Space区向To Space区复制时，对象大小大于To Space可用内存，则把该对象转存到老年代，且老年代的可用内存小于该对象大小。

 minor GC 和 Full GC 的触发时机
    - minor GC: 当 eden 区满以后会触发。
    - Full GC：
        1. JVM 的一些特性比如分配担保，大对象直接进入老年代，长期存活的对象进入老年代等等都会不断增加老年代的使用率，当老年代空间不足以支持下一次 Minor GC 时会触发一次 Full GC
          发生minor gc时，虚拟机会检测之前每次晋升到老年代中的平均大小是否大于老年代的剩余空间大小，若大于，则改为直接进行一次full gc
        
        2. 当用户代码调用 System.gc 时，系统系统建议执行 Full GC，但是否进行是由 JVM 来决定的。

  
打印异常进程的堆栈信息 dump线程快照，定位死锁，超时问题
    jmap        查看堆内存使用情况，可生成JVM堆的转储快照，dump文件较大，消耗大量资源
    jstack
        jstack用于生成java虚拟机当前时刻的线程快照。注意是当前时刻
        线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，用于定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。



内存泄漏， 
修改HashSet中对象的参数值，且参数是计算哈希值的字段，
外部类实例对象的方法返回一个内部类的实例对象，内部类长期引用，外部类虽然不用了但被内部类持有，回收不了


系统配置内存
prd_pc 的tomcat的catalina.sh中配置大小，JAVA_OPTS="-server -Xms4608m -Xmx4608m -XX:MaxMetaspaceSize=500m"
prd_netpay 中是，JAVA_OPTS="-server -Xms1600m -Xmx1600m -XX:MaxMetaspaceSize=400m"
prd_open中是，JAVA_OPTS="-server -Xms2048m -Xmx2048m -XX:MaxMetaspaceSize=500m"

类加载，加载的几个阶段：加载，验证，准备，解析，初始化，使用，卸载，前5个就是类的加载过程，2-4属于连接


               

线上处理经验
Java基础知识和分布式经验应该很熟悉，框架层面源码如果能研读可以加分。但是如果只是会用而不了解原理就要减分。

一个是跨系统的hessian的异常处理，一个是dubbo线程池的溢出

动态数据源，继承AbstractRoutingDataSource
在查询的时候aop拦截选定指定数据源，后面执行数据操作的时候匹配相应的数据源，给方法加上自定义的切换注解，然后拦截注解内容，实现动态切换数据源。



重点
过往的工作经验是owner一个独立的业务系统，负责系统的设计开发工作。
明确知道系统架构的情况，理解上下游关系。
理解该系统的业务定位，该系统当前存在的问题和后续的规划发展有自己的见解。
Java基础知识和分布式经验应该很熟悉，框架层面理解原理，适当看源码
重点考察分布式/服务化系统（不是大流量高并发）的设计原理，思路，关注点。
要会理解一些分布式session、全局流水ID号、服务多次重试幂等、同步转异步、服务监控、最终一致性等原理和应用。
2主导一个复杂的系统（多个业务系统完整链路）；或者负责一块五脏俱全的业务。
3 对业务系统的理解会更多从商业价值角度去描述，熟悉这块产品链的模式和玩法，或者工业化成熟度较高的专业实现方案。
4分布式系统设计原则：分库分表分布式事务、性能稳定性的实践。
如果能描述分库分表中间件实现原理（SQLParse、语法树）、单元化/多机房灾备

######临时记录区域，防止冲突合并######

再次整理到，
Spring+Mvc+Mybatis


## 临时整理知识区
### 1. 111
      redis顺序消费，xss攻击，mq事务
      redis主从，复制断电，数据丢失，
      b树比二叉树好在哪
      索引结构，b+树结构好在哪里，时间复杂度啥的
      tcp几层结构，http和tcp等对比


      linux操作相关，shell脚本相关，
      redis的lua脚本
      技术选型
      redis是主从什么架构，有没有哨兵机制啥的，主从复制断电数据，
      幂等和可靠性
      mq消息积压，消费端异常消费不了怎么办，主要用途，消息消费？ 顺序消费？其他功能
      mq事务使用了两阶段等的协调者的思想
      线程池参数配置意义，三个重点参数，


redis的lua好处
edis中引入lua的优势：

减少网络开销：多个请求通过脚本一次发送，减少网络延迟
原子操作：将脚本作为一个整体执行，中间不会插入其他命令，无需使用事务
复用：客户端发送的脚本永久存在redis中，其他客户端可以复用脚本
可嵌入性：可嵌入JAVA，C#等多种编程语言，支持不同操作系统跨平台交互


mq消息积压
本来就是流量削峰用的，慢慢稳定消费
横向扩容，双m结构，加机器

如果是生产者端由业务暴增引起的生产过快，而消费者端消费能力不足，这个时候就可以采取生产者端限流或者进行消费者扩容；这个时候要注意，如果生产者只是短期暴增或者消息的业务不是很重要可以采用限流，如果是长期暴增真正的业务量上涨就必须要进行消费者扩容。


比如说消费者挂了，然后broker堆积了很多消息，然后可以先把堆积的消息读到别的地方比如mysql或者es然后去后续进行处理，然后把RocketMQ堆积的消息删掉，启动消费者保障消费者正常消费，这里要注意的是删除堆积消息之前，需要停止mq

我之前的是，消费者挂了，持久化，后续再后台一条一条去发送消费


本质还是，持久化积压消息，然后补偿发送，还有一个就是注意是发送端问题还是消费端问题

rocketmq的消息模型简单来说，producer投递消息到topic中的各个队列，各消费者组订阅topic,消费者组中的消费者并行消费队列中的消息


mq事务事务消息
1.事务消息发送及提交：
(1) 发送消息（half消息）。
(2) 服务端响应消息写入结果。
(3) 根据发送结果执行本地事务（如果写入失败，此时half消息对业务不可见，本地逻辑不执行）。
(4) 根据本地事务状态执行Commit或者Rollback（Commit操作生成消息索引，消息对消费者可见）。
2.补偿流程：
(1) 对没有Commit/Rollback的事务消息（pending状态的消息），从服务端发起一次“回查”。
(2) Producer收到回查消息，检查回查消息对应的本地事务的状态。
(3) 根据本地事务状态，重新Commit或者Rollback。
其中，补偿阶段用于解决消息Commit或者Rollback发生超时或者失败的情况。


这里有个half message变为消费者可以消费的消息 或者 抛弃half message的动作

长时间没有消费的half message，Broker要去Producer回查结果

  消息队列：目前RocketMQ中支持事务消息，它的工作原理是：
      a. 生产者订单系统先发送一条half消息到Broker，half消息对消费者是不可见的
      b. 再创建订单，根据创建订单成功与否，向Broker发送commit或rollback
      c. 并且生产者订单系统还可以提供Broker回调接口，当Broker发现一段时间half消息没有收到任何操作命令，则会主动调此接口来查询订单是否创建成功
      d. 一旦half消息commit了，消费者库存系统就会来消费，如果消费成功，则消息销毁，分布式事务成功结束
      e. 如果消费失败，则根据重试策略进行重试，最后还失败则进入死信队列，等待进一步处理






mq顺序消费
  发送端使用顺序消息，MessageQueueSelector
  消费端用MessageListenerOrderly 来接受消息，无序的是MessageListenerConcurrently接受


  但这个顺序，不是全局顺序，只是分区顺序。要全局顺序只能一个分区。
  消息发送默认是轮询，发送到不同队列分区，所以要想顺序，必须要放在同一个分区中
  而消费端消费的时候，是会分配到多个queue的，多个queue是同时拉取提交消费。


  但是同一条queue里面，RocketMQ的确是能保证FIFO的。那么要做到顺序消息，应该怎么实现呢——把消息确保投递到同一条queue

  按照这个示例，把订单号取了做了一个取模运算再丢到selector中，selector保证同一个模的都会投递到同一条queue。
  即： 相同订单号的--->有相同的模--->有相同的queue。

  而消费端消费的时候，是会分配到多个queue的，多个queue是同时拉取提交消费。

  rocketMQ中提供了基于队列(分区)的顺序消费。


  SendResult sendResult = producer.send(msg, new MessageQueueSelector() {
               @Override
               public MessageQueue select(List<MessageQueue> mqs, Message msg, Object arg) {
                   Long id = (Long) arg;  //根据订单id选择发送queue
                   long index = id % mqs.size();
                   return mqs.get((int) index);
               }
           }, orderList.get(i).getOrderId());//订单id