#一级标题
##二级标题
* 无需列表
1. 有序列表
*** 
*** 
*** 


一些设计思路
	思维导图，查看体系知识更清晰
	
	新技术:官方的文档，官网的demo。后面再横向对比，看源码(从依赖性最小的模块看起)。
	不是全面的掌握，每个东西都有关键点，抓住关键点是核心，往原理上问，抓重点记忆
	不仅仅是细节化的落实了，要整体的设计，主要核心点，以前是从点研究，后面要从面入点。请求数量 性能指标，aqs等
	系统化 由面入线重点内容再到点

1. 开发经验
	1 Don’t Repeat Yourself ：这是软件开发的 础原 ，即不要做重复性劳动，也是现在所说的“极客文化”的 代码重复 作重复在软件开发中都是不合理的存在，利用各种手段消除这些重复是软件开发的 个核心工作准

	2 Keep it simple stupid 在做软件设计的工作中，很多时候都不要想得过于复杂，也不要过度设计和过早优 ，用最简单且行之有效的方案 就避免了复杂方案带来的各种额外成本 这样既有利于后续的维护 也有利于进一步的扩展

	3 You Ain’t Gonna Need It ：即 YAGNI 只需要将应用程序必需的功能包含进来，而不要试图添加任何其 你认为可能需要的功能 因为在 个软件中，往往请求都花费在 的功能上

	4 Done is better than perfect ：在面对 个开发任务时，最佳的思路就是先把东西做出来，再去迭代优化 如果 开始就面面俱到 考虑到各种细节，那么很容易钻牛角尖而延误项目进度

	5 Choose the most suitable things 这是在做方案选择 技术选型时候的 个很重要的原则 在面对许多技术方案、开源实现的时候，务必做到不能盲目求新，要选择最合适的而非被吹得天花乱坠的














## Spring相关

    spring 主要分为5个模块：
		1.IOC	依赖注入
			BeanFactory接口是spring框架的核心，实现了容器许多核心的功能
			Context模块构建于核心模块之上，其中applicationcontext是该模块的核心接口，扩展了BeanFactory，添加了bean生命周期控制，jndi获取，资源加载等。
		2.AOP
			区别于aspect框架，不是同一个事物框架
			借助该功能，实现了声明式事务的功能
		3.数据可访问和集成
		4.web及远程操作
			可通过listener或Servlet初始化Spring容器，将其注册到web容器中 
		5.测试框架

1. 扫描和属性读取

//数据源的配置，相应的配置文件读取即可。
```
<context:property-placeholder location="classpath:jdbc.properties"/>
```

//注解的扫描，无需手动配置bean
```
<context:component-scan base-package="com.test.blog"/>
```
2.读取xml配置测试
```
ApplicationContext ac = new ClassPathXmlApplicationContext("applicationContext.xml");
RegisterDAO registerDAO = (RegisterDAO)ac.getBean("RegisterDAO");
如果是两个以上:
ApplicationContext ac = new ClassPathXmlApplicationContext(new String[]{"applicationContext.xml","dao.xml"});
或者用通配符:
ApplicationContext ac = new ClassPathXmlApplicationContext("classpath:/*.xml");
```
2. Spring事务
    只有runtimeexception，才能让spring自动回滚事务@transactional
	目前看service异常回滚了，controller还是能捕获的

    没有配置事务管理的情况，直接就是数据源的自动commit持久化到数据库（），dao照样可以顺利进行数据操作
    
    jdbc2.0中事务最终只能有两个操作：提交和回滚。
	在jdbc3.0（java1.4）后引入了新特性:保存点（savepoint），可以将事务分割多个阶段，方便指定回滚到事务的特定保存点。
	事务只能被提交或者回滚(或回滚到某个保存点后提交)

    spring事务管理spi的抽象层主要包括3个接口，分别是
			platformtransactionmanager:  负责commit或者rollback事务，不同框架提供不同实现类，jpa、datesource等manager
			transactionDefinition: 定义了传播属性，隔离级别等
			transactionStatus: 代表事务的具体运行状态，使得异常回滚事务的方式更具可控性，继承了savepointManager接口

    spring事务和数据库连接：
			当spring事务方法运行时，会产生一个事务上下文，
			该上下文在本事务执行线程中针对同一个数据源绑定了一个唯一的数据连接，所有被该事务上下文传播的方法都共享这个数据连接
			这个数据连接从数据源获取到返回给数据源都在spring的掌控之中。使用安全


    编程式手工回滚(忽略)
    TransactionAspectSupport.currentTransactionStatus().setRollbackOnly()
	从上面可以看出主要检查一下几个属性，是否都有：
		transactionAttributeSource 事物属性源，我们所有的method对应的事物配置都在这里
		transactionManager 我们执行的方法要使用的transactionManager
		beanFactory 从spring中找到配置
		如果这些都有值的话，那么就完成了我们的这个类基本功能的所有属性要求，就可以使用TransactionAspectSupport(手工回滚)。
		这里暂定是需要加上事务注解支持的，不然缺少transactionAttributeSource。

    事务传播行为（propagation behavior）。
        场景：	当事务方法被另一个事务方法调用时，必须指定事务应该如何传播
        嵌套事务一个非常重要的概念就是内层事务依赖于外层事务。外层事务失败时，会回滚内层事务所做的动作。
        而内层事务操作失败并不会引起外层事务的回，两个方法之间有个savepoint的概念，这个就是嵌套事务的关键点。

        1、REQUIRED 		当前方法必须在一个具有事务的上下文中运行，默认支持当前事务，如果被调用端发生异常，那么调用端和被调用端事务都将回滚

		2、NESTED 	嵌套事务	
                    如果封装事务存在，并且外层事务抛出异常回滚，那么内层事务必须回滚，
                    反之，内层事务并不影响外层事务。如果封装事务不存在，则同PROPAGATION_REQUIRED的一样
					如果A的MethodA()存在事务，则B的methodB()抛出异常，B.methodB()回滚，
                    如果A不捕获异常，则A.methodA()和B.methodB()都会回滚，
                    如果A捕获异常，则B.methodB()回滚,A不回滚；
	
		3、REQUIRES_NEW		一个新的事务将启动，而且如果有一个现有的事务在运行的话，则这个方法将在运行期被挂起，直到新的事务提交或者回滚才恢复执行
		




    编程式事务，允许用户在代码中精确定义事务的边界，侵入业务代码，使用 TransactionTemplate,直接事务模板处理，可以返回自定义的result。
	声明式事务，基于AOP，有助于用户将操作与事务规则进行解耦。@transactional

    sping的事务不能回滚
		使用aop代理对象调用service才有事务，内部调用事务无效
		只有代理对象调用才能触发代理方法，目标对象调用无法触发，类似事务本身调用事务无效的场景。
		
		代理类中调用的方法a调用了代理方法b，那么b无效，此时b是目标类调用的
		代理类一次调用方法，只走一次代理，内部的方法是目标对象直接执行的，没有走代理，this.test()，目标对象调用，不走代理方法
		
		当@service标注的bean在容器中检查到有@transaction，则会创建一个代理对象，
		开启事务--->创建sqlsession--->使用jdbc连接执行sql--->最后提交事务
		client-aop动态代理-@transaction-service-@transaction提交或回滚，实质上service是被aop代理了，

        直接走方法调用的事务问题
                https://blog.csdn.net/zknxx/article/details/72585822  
            
            ***包含事务的方法异常后回滚会默认被上级接收到
            ***当前方法自身调用事务方法，事务会失效的，当作内部方法处理，必须重新注入interface执行，获取当前aop的代理，然后通过aop的代理调用，才能生效
            
            内部方法调用事务(忽略)
            <aop:aspectj-autoproxy proxy-target-class="true" expose-proxy="true"/>组合((SelfCallService)AopContext.currentProxy()).selfCallB();
            proxy-target-class为true的是用Cglib动态代理，false的时候启用JDK动态代理




xml中配spring事务
 ```
    1. tx aop
	//事务拦截器的aop配置,tx配置
	 <tx:advice id="txAdvice" transaction-manager="transactionManager">
		 <tx:attributes>
			<tx:method name="*" propagation="REQUIRED" />
		 </tx:attributes>
	 </tx:advice>
	 <aop:config>
		<aop:pointcut id="interceptorPointCuts" expression="execution(* com.bluesky.spring.dao.*.*(..))" />
		<aop:advisor advice-ref="txAdvice" pointcut-ref="interceptorPointCuts" /> 
	 </aop:config>
	
	2. 全注解事务
	<tx:annotation-driven transaction-manager="transactionManager"/>

	3. 事务的拦截器     transactionInterceptor
	<context:annotation-config />
    <context:component-scan base-package="com.oumyye"/>
    <bean id="logInterceptor" class="com.oumyye.aop.LogInterceptor"></bean>
    <aop:config>
        <aop:pointcut expression="execution(public * com.oumyye.service..*.add(..))" id="servicePointcut"/>
        <aop:aspect id="logAspect" ref="logInterceptor">
            <aop:before method="before"  pointcut-ref="servicePointcut" />
        </aop:aspect>
    </aop:config>
 ```




3. aop事务的动态代理实现：
    模拟spring的事务操作
 ```
/**
 * @ClassName: TransactionHandler
 * @Description: 动态代理封装事务
 * @author: 十期-牛迁迁
 * @date: 2015-10-11 下午2:59:15
 */
public class TransactionHandler implements InvocationHandler
{
    private Object targetObject;

    public Object newProxyInstance(Object targetObject)
    {
        this.targetObject = targetObject;
        //使用Proxy类，通过反射得到一个动态的代理对象
        return Proxy.newProxyInstance(targetObject.getClass().getClassLoader(),
                targetObject.getClass().getInterfaces(), this);
    }

     //在invoke方法中做一些其他操作
    @Override
    public Object invoke(Object proxy, Method method, Object[] args)
            throws Throwable
    {
        Connection conn = null;
        Object ret = null;
        try
        {
            // 从ThreadLocal中取得Connection
            conn = ConnectionManager.getConnection();
            if (method.getName().startsWith("add")
                    || method.getName().startsWith("del")
                    || method.getName().startsWith("modify"))
            {
                // 手动控制事务提交
                ConnectionManager.beginTransaction(conn);
            }
            // 调用目标对象的业务逻辑方法
            ret = method.invoke(targetObject, args);
            if (!conn.getAutoCommit())
            {
                // 提交事务
                ConnectionManager.commitTransaction(conn);
            }
        }
        catch (ApplicationException e)
        {
            // 回滚事务
            ConnectionManager.rollbackTransaction(conn);
            throw e;
        }
        catch (Exception e)
        {
            e.printStackTrace();
            if (e instanceof InvocationTargetException)
            {
                InvocationTargetException ete = (InvocationTargetException) e;
                throw ete.getTargetException();
            }
            // 回滚事务
            ConnectionManager.rollbackTransaction(conn);
            throw new ApplicationException("操作失败！");
        }
        finally
        {
            ConnectionManager.closeConnection();
        }
        return ret;
    }
 ```	

4. 	所有的spring bean都是单例的，默认单例 ，也可以指定多例
 ```
    //向spring注册了一个bean。方法名作为bean的id
	@bean	
	public Performer duke(){
		return nre Juggler()
	}

	//引用创建bean
	@bean			
	public Performer duke2(){
		return nre Juggler(duke())					//并不是调用，spring拦截找到该bean
	}
 ```
 5. 加载上下文
  contextloaderlistener是servlet的监听器，用来初始化加载除dispatcherservlet创建的上下文以外，其他的配置文件到spring应用的上下文中，
 ```
	<listener>
		<description>spring监听器</description>
		<listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
	</listener>
	默认加载  /WEB-INF/applicationContext.xml这个配置文件。
	一般我们人工指定，
	<context-param>
		<param-name>contextConfigLocation</param-name>
		<param-value>	
				classpath:config/spring.xml,
				classpath:config/spring-mybatis.xml,
				classpath:config/spring-dubbo.xml,
		</param-value>
	</context-param>

    ContextLoaderListener默认去WEB-INF下加载applicationContext.xml配置。默认的applicationContext.xml和x-servlet.xml文件

 ```
6. spring中的子父容器
	父子容器，子容器可以访问父容器中的bean，反之不行，在容器内bean id唯一，但子容器可以有一个和父容器id相同的bean
	webapplicationcontext可以获得servletcontext引用,整个web上下文将作为属性放置到servletcontext中，这样web应用就可以访问spring应用上下文。
    spring提供了用于启动webApplicationContext的web容器监听器：ContextLoaderListener,通过容器的上下文参数contextConfigLocation获取Spring配置文件的位置

	WebApplicationContext
		ApplicationContext是spring的核心，spring把bean放在这个容器中，在需要的时候，用getBean()方法取出，在web应用中，会用到webApplicationContext，继承自ApplicationContext

	ServletContext
		是Servlet与Servlet容器之间直接通信的接口，Servlet容器(tomcat等)启动创建一个ServletContext对 象，每个web应用有唯一的ServletContext对象，所有Servlet对象共享一个 ServletContext，Servlet对象可以通过它来访问容器中的各种资源
		在web框架中，每个DispatcherServlet有它自己的WebApplicationContext，WebApplicationContext被绑定在ServletContext上，


	通过实现ServletContextListener可以使得在DispatcherServlet 初始化前就可以完成 Spring IoC 容器的初始化，也可以在结束期完成对Spring IoC 容器的销毁 
	SpringMVC交给了类 ContextLoaderListener，大部分都用这个初始化。
		
	Spring MVC 需要初始 Ioc 容器和DispatcherServlet 请求两个上下文,其中 DispatcherServlet 请求上下文是SpringIoC 上下文扩展,这样就能使得 Spring 各个 Bean 能够形成依赖注入。








7. 容器后处理器：实现BeanFactoryPostProcessor接口，在spring容器启动之后会查找实现了BeanFactoryPostProcessor接口的bean，并实例化调用  postProcessBeanFactory()方法。需加入@component。只处理实现相应接口的地方

	bean后处理器：实现BeanPostProcessor接口，在容器创建了bean对象实例之后，调用bean的初始化方法之前后会调用相关方法。需加入@Component。统一处理的地方
    BeanPostProcessor接口的作用是：我们可以通过该接口中方法在bean实例化、配置以及其他初始化方法前后添加一些我们自己的逻辑。动态代理和aop都是通过该接口实现的
	
	BeanPostProcessor是spring的后处理器。工厂后处理器是容器级的，仅在应用上下文初始化时调用一次，完成配置文件的加工处理工作。
	该接口的实现类为“后处理器”，一般不由bean本身实现，当spring容器创建bean的时候，可以合理对bean进行加工处理。也就是代理的思想

8. 	Bean的生命周期
    bean级生命周期的几个常用控制接口，
		beannameaware：是通过set注入当前bean在容器中的bean_ID，
		beanfactoryaware：让bean获得配置文件中对应的配置名称
		InitializingBean	
		DisposableBean

	BeanFactoryPostProcessor和BeanPostProcessor。两个后置处理器的区别
		**********
			BeanFactoryPostProcessor在bean实例化之前执行，
			之后实例化bean（调用构造函数，并调用set方法注入属性值），
			然后在调用两个初始化方法前后，执行了BeanPostProcessor。
			初始化方法的执行顺序是，先执行afterPropertiesSet，再执行init-method。
		**********

		BeanPostProcessor(bean级别的处理)	
			执行时机:	实例化之后,操作的是具体的bean
						spring容器实例化bean之后，在执行bean的初始化方法(InitializingBean,init-method)前后
			
			使用案例:	@Autowired,ApplicationContextAwareProcessor	
			
			BeanPostProcessor的执行顺序是在BeanFactoryPostProcessor之后
			
		BeanFactoryPostProcessor(BeanFactory级别的处理)	,多个按优先级处理
			
			执行时机：	在beanDefinition加载完成，bean实例化之前执行
			操作对象：	BeanDefinition	针对整个Bean的工厂进行处理,不能实例化操作
			使用案例:	PropertyPlaceholderConfigurer
			
		java对象的创建过程往往包括 类初始化 和 类实例化 ，
			初始化：静态的（变量，方法，代码块）会被执行，只在类加载的时候执行一次
			实例化：创建一个类的实例对象。可多次实例化，堆中开内存
			在Java对象初始化过程中，主要涉及三种执行对象初始化的结构，分别是 1.实例变量初始化、2.实例代码块初始化 以及 3.构造函数初始化。
			Java要求在实例化类之前，必须先实例化其超类，以保证所创建实例的完整性			
					
			xml中定义的bean标签，Spring会解析成一个BeanDefinition(存储bean标签的信息，用来生成bean实例)，这个BeanDefinition就是bean标签对应的javabean。







9.  xml中配置spring相关

    1. xml中schema 
		xmlns是默认命名空间，
		xmlns:xsi是标准的命名空间，
		xmlns:aop这种就是自定义的命名空间（1.指定命名空间的名称，2.指定命名空间的Schema文档格式文件的位置）
		其中aop就是命名空间的别名（用以区分文档后面的元素），对应的还有权限定名和schema文件地址。
		命名空间使用全限定名，一般使用一个引用的url地址指定命名空间对应的schema文件。

    2. bean配置
 ```
    如果在<bean>中没有指定bean的id，那么自动将全限定类名作为bean的名称，<bean>中使用的<property>,就是set注入，需要在类中有对应的set方法
        bean注入
        可注入多种对象，list、map、set、实体类、property等
		1.set注入
            java中的属性命名规范：xxx属性对应setXxx()方法，
            变量的前两个字母要么全大写，要么全小写，否则xml中set注入会报错。比如iDCode和iCcard。
		2.使用构造函数，类中必须要存在有参构造，可以显示指定入参顺序，使用index 和type配合使用，复杂属性类用ref引用，不推荐
		3.工厂方法注入  不推荐



    	使用<bean>配置的时候，可通过init-method指定初始化方法，对应的注解使用@postconstruct。

	spring的  applicationcontext启动时，将配置文件中的<bean>生成一个beandefinition对象（<bean>在spring容器中的内部表示），一个个的BeanDefinition形成了bean的注册列表。根据注册表，加载相关的bean，并放在bean缓存池中，供外层的程序调用
 ```
    3. 在两个xml中有包含关系的时候，加载主动包含的那个xml即可

10. 依赖注入
    使用autowired,如果有一个以上的bean，则可以通过@qualifier注解限定bean的名称
	对集合类型的注入，会将符合类型的所有bean都注入到集合中，这个在注入批量插件时有用

    循环依赖问题
		spring对构造函数配置的bean实例化前提是，入参引用需要准备就绪，如果两个bean都采用构造函数注入，会发生循环依赖，改为属性注入即可

11. @configuration 配合@bean 替代xml中配置，本身相当于标注了@component,可以其他类中直接注入
	@ImportResource,可以加载xml,实际案例使用的是dubbo.xml





12. spring扩展自定义标签，spring中自定义组件标签(忽略)
		1.采用xsd描述自定义标签的元素属性
		2.编写bean定义的解析器
		3.注册自定义标签解析器
		4.绑定命名空间解析器

13. spring提供了自动代理机制，让容器自动生成代理，使用beanPostProcessor来实现（自动在容器实例化bean时为匹配的bean生成代理实例）
	在内部调用方法的时候没有走aop代理，需要注入自身的bean才能实现aop代理的功能，事务方法调用的问题

14. 创建数据源的三种方式，
		1.xml配置一个数据元
		2.使用jndi
		3.代码创建数据源，DriverManagerDataSource(没有提供池化连接，适合单元测试用)

15. applicatincontext就叫做spring容器,
	beanfactory会缓存bean实例到ioc容器中，缓存原理是一个hashmap实现的缓存器，key是beanname，value是单例bean
	
	ApplicationContext和BeanFactory初始化不同：
	BeanFactory：初始化容器时，没有实例化bean，第一次访问才实例化目标bean
	ApplicationContext：在初始化应用上下文时就实例化所有的单例bean，时间稍微长点。实际开发中普遍使用前者，后者功能比较少

16. Spring支持如下三种方式创建Bean
		1：调用构造器创建Bean
		2：调用静态工厂方法创建Bean
		3：调用实例工厂方法创建Bean

17. spring中的单例和多例
		singleton（单例）：只有一个共享的实例存在，所有对这个bean的请求都会返回这个唯一的实例。Spring bean 默认是单例模式
		prototype（多例）：对这个bean的每次请求都会创建一个新的bean实例，类似于new。

18. BeanFactroy和ApplicationContext（忽略）
        1. BeanFactroy采用的是延迟加载形式来注入Bean的，而ApplicationContext是在容器启动时，一次性创建了所有的Bean。 
        2. BeanFactory和ApplicationContext都支持BeanPostProcessor、BeanFactoryPostProcessor的使用，但两者之间的区别是：BeanFactory需要手动注册，而ApplicationContext则是自动注册
        3. ApplicationContext使用ClassPathXmlApplicationContext和FileSystemXMLApplicationContext，前者默认从类路径下加载配置文件，后者默认从文件系统中装载配置文件。
        在获取ApplicationContext实例后，就可以像BeanFactory一样调用getBean(beanName)返回Bean了。

19. 初始化
		指定初始化方法
        一：使用@PostConstruct注解；	JDK提供的，不是Spring提供
        二：实现InitializingBean接口，实现afterPropertiesSet方法(不推荐，对代码的侵入性较强)；
        三：通过xml配置文件指定init-method的方式。


	静态static代码块在首次调用这个类时才触发，而不是一开始就加载。且只加载一次

	@Bean 和  CommandLineRunner
		@Order注解并不能改变Bean加载优先级，对多个CommandLineRunner是有效的，加在普通的方法上或者类上没有作用
		CommandLineRunner 和 @bean 加载顺序，启动mq先消费，CommandLineRunner的常量尚未加载就消费，导致初始化client异常。
		用户扩展CommandLineRunner，进行启动项目完毕之后一些业务的预处理。
		InitializingBean，项目启动时，初始化bean的时候都会执行该方法



20. Aop，Aspectj
    	推荐使用aspectj实现aop
		@Around(value = "test.PointCuts.aopDemo()")
		public void around(ProceedingJoinPoint pjp) throws  Throwable{
			System.out.println("[Aspect1] around advise 1");
			pjp.proceed();
			System.out.println("[Aspect1] around advise2");
		}

21. 静态方法中调用spring bean   无法注入static bean
	原因是Spring容器的依赖注入是依赖set方法，而set方法是实例对象的方法，而静态变量属于类，因此注入依赖时无法注入静态成员变量，在调用的时候依赖的Bean才会为null。
		
	定义static变量ApplicationContext，是为了静态共享，利用容器的getBean方法获得依赖对象。

	setApplicationContext方法，初始化的时候该方法就会被调用,从而获取 SpringIoC的上下文(applicationContext)，
	

 ```
	@Component
	public class SpringContextUtil implements ApplicationContextAware{
		private static ApplicationContext context;

		@Override			#这里不加编译器也能识别，但是标准化的都要加
		public void setApplicationContext(ApplicationContext ctx) throws BeansException {context = ctx;}
		
		public static ApplicationContext getApplicationContext(){return context;}

		public static Object getBean(String beanName){return context.getBean(beanName);}
	}
 ```

	Redisclient中 初始化方法    加入spring 容器,初始化后  然后加载到静态属性中
	public static JedisPool jedisPool;
	
	RedisUtil redisUtil = (RedisUtil)SpringContextUtil.getBean("redisUtil");//手工获取
	
	SpringIoC容器是一个管理springbean的容器,IoC容器都需要实现接口BeaFactory ，
	ApplicationContext继承beanfactory接口，大部分springioc是实现applicationcontext接口的实现类。

22. bean条件加载，实例加载
		@Conditional(RedisChooseConfig.class)
		实现Condition接口，获取环境变量，动态加载
		Environment environment = context.getEnvironment();
		String property = environment.getProperty("resRoot");
		

23. 为什么有了@Compent,还需要@Bean呢？?
	如果想将第三方的类变成组件，你又没有没有源代码，也就没办法使用@Component进行自动配置，这种时候使用@Bean就比较合适了。不过同样的也可以通过xml方式来定义。
	Spring的Starter机制，就是通过@Bean注解来定义bean。
	可以搭配@ConditionalOnMissingBean注解?@ConditionalOnMissingClass注解，如果本项目中没有定义该类型的bean则会生效。避免在某个项目中定义或者通过congfig注解来声明大量重复的bean。

	@Component (”user")
	@bean(name="testBean"),如果没有配置name属性，那么将方法名作为bean的名称
	内部时使用AnnotationConfigApplicationContext来构建ioc容器(基于注解,这个一般是测试用)



## Springmvc相关
1. 主要内容：前端控制器 、处理器映射器（注解和非注解）、处理器适配器、视图解析器
2. mvc 模型视图控制器，请求流程 
	request--->c(控制器controller)--->m模型处理（dao，service）--->返回c--->v（view）视图渲染
    springmvc 请求流程 
	request	--->前端控制器(dispatcherservlet接受请求和响应结果相当于转发器)
			--->处理器映射器(handlerMappering 根据url匹配相应的handler)
			--->返回一个执行链(HandlerExecutionChain包含interceptor和handler：handler处理器（平时controller），不同的handler由不同的处理器适配器(handlerAdapter：按特定规则执行handler)调用执行）
			--->返回modelandview到适配器再到前端控制器DispacherServlet
			--->由视图解析器返回view（是个接口，支持不同的view类型）进行视图渲染


3. 配置dispatcherServlet的url-pattern有三种方式：
	1、*.action 
	2、/ 
	3、/* 这种不对，当转发到一个jsp时，仍然会由dispatcherServlet解析jsp,不找到handler

4. dispatcherServlet中的init-param需要指定contextconfiguration和springmvc.xml（配置handleradapter和handlerMappering等 ），
    默认是加载/WEB-INF/servlet名称—servlet.xml

5. 两个常用注解
    <mvc:annotation-driven></mvc:annotation-driven>  开启注解，映射器和适配器。
    @controller     即表示该类是Handler处理器。		
    本质是适配器都实现handlerAdapter接口，有多种handlerAdapter实现，比如：requestMappingHandlerAdapter
    @requestMapping 实现方法和url的映射	
    本质是映射器都实现handlerMappering接口，有多种实现比如requestMappingHandlerMapping
6. 返回的mv是一个map，将其填充到request域中，前端页面可取值
        modelAndView的addObject()相当于request的setAttribute方法，在jsp中取数据

	ajax中
		contentType: 告诉服务器，我要发什么类型的数据
		dataType：告诉服务器，我要想什么类型的数据

	mvc中的ModelMap实际上继承LinkedHashMap<String Object>


7. 使用mvc注解驱动，<context:componet-scan base-package="" / >注解扫描
8. 整合ssm
	通过spring管理持久层的mapper接口，通过spring管理业务层的service，通过spring管理表现层的handler
	1、整合dao层：mybatis和spring整合，mapperscanner扫描
	2、整合service：管理service接口，配置或标签，实现事务控制
	3、整合springmvc：是spring的模，无需整合
9. 简约版配置：
	整合mybatis
	1)、配置mybatis的mybatis.xml中只需要配置分页插件
	2)、spring-mybatis.xml主要将dao整合到spring中，主要是将sqlsessionfactory（包含mybatis.xml和datasource）注入容器中,再将mapper扫描注入容器（实现@autowire注入）

	整合spring
	配置spring的事务管理：
	1）、事务管理器，spring-jdbc
	2）、通知<tx:advice></txadvice>
	3)、<aop:config></aop:config>
	
	整合springmvc
	1）、组件扫描<context:componet-scan base-packge=""></context:componet-scan>扫描controller
	2）、mvc注解驱动，<mvc:annotation-driven></mvc:annotation-driven>
	3)、视图解析器

            
	在web.xml中通过contextLoaderListener监听器，将各个xml整合文件加入spring容器，参数为	
	<context-param>
		<param-name></param-name>	
		<param-value></param-value>
	</context-param>
10. controller的三种返回对象：1、modelandview 2、string（需要形参model） 3、void
11. redirect 和 forward 区别
	redirect 无法共享request 
		return "redirect:queryItem.action" 	#重定向路径，同级类省略类根路径，地址栏改变
		response.sendirect("url")
		
	forward 地址栏不变，共享request 
		return "forward:queryItem.action"
		request.getRequestDipatcher("path").forward(request,response)

12. 参数绑定
        参数绑定:处理器适配器调用springmvc的参数绑定组件（converter）获取形参，执行controller
        简单传入：
            1）、简单类型 @requestparam（value，required，defaultvalue） 不使用则  request传入的名称和controller的形参名需一致
            2）、pojo类型，不使用标签，页面的name属性和形参pojo的属性name一致，使用的话应该是@modelattribute

        高级绑定：
            pojo： 传入pojo中的pojo属性：页面中name="userInfo.name"
            数组：页面中共用相同的name值即可，name="userId"，传到后台就是 Integer[] userIds
            list: userInfo中有个List<pojo> pojoList，页面name="pojoList[index].name"
            map:页面中name="userInfo['name']" -----key-value
13. 校验：(忽略)
        主要是后端的服务端校验-validation校验框架，springmvc的校验框架（引入hibernate-validator-4.3.0final.jar,jboss-loggging-3.1.0.CR2.jar,validation-api-1.0.0.GA.jar）
        validator需要注入适配器（配置校验器bean和返回bean，这里使用的是返回properties，个人认为是加入容器，快速读取，{}读取即可），通过mvc注解驱动注入，validator="beanname"
        在形参校验的bean前加@validated 其后需要跟着BindingResult bindingResult，有一个pojo校验就需要跟一个bindingResult,形参顺序一前一后，在对bindingResult进行判断即可。
        多个controller共用一个校验pojo时，pojo中可以指定校验分组，group属性group={validate1.class},校验分组是一个空接口，形参中指定@validated（validate1.class）即可
14. 异常处理：
        springmvc提供了全局异常处理器进行统一异常处理（唯一），是抛到前端控制器交给统一异常处理器处理  
            预期异常：runtimeException：

        定义异常处理器，需要实现handlerExceptionResolver接口，并需要在springmvc.xml中注入
15. 数据回显：
	    使用@modelattribute回显数据，简单点的使用model回显
16. 上传图片:
        tomcat的server.xml中添加虚拟目录，方便代码和图片在一台电脑上测试用	
        <Context path="/helloapp" docBase="docBase="D:\web\helloapp" reloadable="true"/>
        springmvc的上传功能：
                    1、form的中增加enctype=”multipart/form-data”
                    2、 spring.mvc中需要增加multipartResolver解析器
                    3、controller中使用MultipartFile 接受处理
                    4、图片目录分级可以提高io能力
                    5、采用file.Transto 来保存上传的文件
17. json数据交互:
        @requestbody 可以将json串转为java对象，形参绑定
        @responsebody可以将java对象转为json串输出(完全绕过视图解析，返回一个json信息)
        public @ResponseBody UserInfo getUserInfo(@RequestBody Item item){
            return userInfo;
        }
        请求时key/value对象：在ajax中 data:'name=shouji&price=90';
18. <form action="" method="">默认是get
        method="get"，表单在提交时，填写在表单中的数据会和action="url"中的url编码在一起。
        method="post"，表单在提交时，填写在表单中的数据将在底层发送到action="url"中的url去。
        两者的区别在于，method="get"时，数据传输是可见的；method="post"时，数据传输是不可见的。
19. session.removeAttribute()适用于清空指定的属性   
	    session.invalidate()是清除当前session的所有相关信息

20. 拦截器：
        配置类似全局的拦截器，注入到每个handlermapping中,多个拦截器顺序执行
```
            <mvc:interceptors>
                <mvc:interceptors>
                    <mvc:mapping path='/**'/>------/**表示拦截所有url包括子url，只配/*只拦截根url
                    <bean class="">
                </mvc:interceptors>	
            </mvc:interceptors>
```

        1、prehandler(request,response,object handler)-----进入handler方法之前执行，
            用于身份认证授权，
            未登录，return false 拦截不向下执行，return true 表示放行

        2、posthandler(request,response,object handler ,mv)--进入handler方法之后，返回mv之前执行
            应用场景从mv出发，可在此处理模型和数据

        3、afterCompletion(request,response,object handler ,mv,exeception)---执行handler完成执行
            统一异常和日志处理

        当多个拦截器拦截统一请求时，
        1、拦截器1、2同时放行
        prehandler按顺序执行，posthandler，afterCompletion按拦截器配置的逆向顺序执行
        2、拦截器1放行，2不放行
        拦截器1prehandler放行，拦截器2的prehandler才会执行，拦截器2prehandler不放行，1、2后续都不执行
        3、拦截器1、2都不放行
        执行到拦截器1prehandler return false 结束

21. Springmvc是@RequestMapping网关实现：
        1.扫描所有注册的Bean并遍历这些Bean，依次判断是否是处理器，并检测其HandlerMethod
        2.遍历Handler中的所有方法，找出其中被@RequestMapping注解标记的方法。获取方法method上的@RequestMapping实例
        3.将类层次的RequestMapping和方法级别的RequestMapping结合，存入一个urlmap中key-value:(url,handler) 
        5.当请求到达时，去urlMap中匹配url，以及获取对应mapping实例，然后去handlerMethods中获取匹配HandlerMethod实例
22. 前段传参数到controller，@requestParam不是必须的，默认是绑定到同名查询参数上

23. 重定向和跳转，redirect和forward
	通过重定向到另一个页面我们能够避免表单的重复提交

	http://www.yu.com/xye-open/open-api/pay/test/cache.htm
	response.sendRedirect("withdrawSubmit");
	http://www.yu.com/xye-open/open-api/pay/test/withdrawSubmit
	实际测试，同一个controller，重定向是在最后一个路径后面追加路径
	registry.addViewController("/").setViewName("forward:/index.html");//这里直接是相当于浏览器发送新请求


	RedirectView
	return  new ModelAndView("redirect:/my_requires.htm");

	return "redirect:/user/show?id="+user.getId() ;
	mv.setViewName("redirect:/user/show?id="+user.getId())


	重定向
		内部可以将参数传递给重定向地址
		Spring MVC有个约定， 当返回的字符串带有redirect时候，它就会认为需要的是一个重定向。
		public String addRole(Model model) (){					//ModelMap类似
			model.addAttribute(”id”, role.getid()) ;
			return ”redirect:./do.htm”；
		}

		public ModelAndView addRole2 (ModelAndView mv ){
			mv.addObject (” note ”, note);
			mv.setViewName(”redirect:./do.htm”);
			return mv;
		}

24. 配置多个dispatcherservlet
    DispatcherServlet之间的上下文是分离的，势必会出现多个dataSource的情况，
    由contextConfigLocation统一制定上下问，即可共享
    原先的hessian是自己的dispatcherservlet 加载自己的 beancontext
        
    在Spring MVC中，每个DispatcherServlet拥有其独立的WebApplicationContext，继承了root/global WebApplicationContext中所定义的所有的bean。
    
    WebApplicationContext被包含到ServletContext中；
    使用RequestContextUtils中的方法获得DispatcherServlet特定的WebApplicationContext；
    使用WebApplicationContextUtils中的方法获得root WebApplicationContext for this application；

25. 在springmvc中，DispatcherServlet 根据 HandlerMapping 找到对应的 Handler,将处理权交给 Handler
	（Handler 将具体的处理进行封装），再由具体的 HandlerAdapter 对 Handler 进行具体的调用。

26. 全局异常处理
	使用@ControllerAdvice注解，全局捕获异常类，只要作用在@RequestMapping上，所有的异常都会被捕获
	HandlerExceptionResolver，旧版的是在web.xml中配置错误页面
	处理异常：＠ controllerAdvice 和 ExceptionHandler 	@ControllerAdvice是用来定义控制器通知的，＠ExceptionHandler是指定异常发生的处理方法


27. 静态资源加载
		**********
			一般是建议资源加载(spring.resources.static-locations)和映射(addResourceHandler.addResourceLocations)相统一，一致。就是都写上，不写也行，不写使用boot默认。
			资源加载，重名的相对而言 static优先。都是统一加载到一起作为资源，不会重复
			********映射的优先级高于资源加载********
			静态资源 js等要配置映射，否则会被拦截，这个不一定 两种选择  1映射 2默认资源路径

			http://192.168.6.222:8086/static/js/runtime.6a3e6d1f.js 	走的资源映射
			如果是 http://192.168.6.222:8086/js/runtime.6a3e6d1f.js，   走的boot静态资源加载  

			对于静态映射的文件，无需资源加载
			http://192.168.6.222:8086/templates/index.html 需配置资源映射后直接访问(因为不能直接访问WEB-INF下的文件)，不用指定加载目录，映射的优先级高。
			
		**********

28. 注解相关
		Annatation(注解)是一个接口，程序可以通过反射来获取指定程序中元素的 Annotation对象，然后通过该 Annotation 对象来获取注解中的元数据信息。
		注解中的@Target 常用的类型 指定用在什么上面，根据实际需求定
			TYPE,		 /**用于描述类、接口(包括注解类型) 或enum声明 Class, interface (including annotation type), or enum declaration */
			FIELD,		 /** 用于描述域 Field declaration (includes enum constants) */
			METHOD,		 /**用于描述方法 Method declaration */
			PARAMETER,	 /**用于描述参数 Formal parameter declaration */
			
		一般@Retention(RetentionPolicy.RUNTIME)都是运行期

29. 不从controller传request，RequestContextHolder的使用
	HttpServletRequest request = ((ServletRequestAttributes) RequestContextHolder.getRequestAttributes()).getRequest();
	但是，如果service层的函数是异步的话，是获取不到request的。
	通常RequestContextHolder.getRequestAttributes()无法在子线程等异步情况下使用，

30. 参数接收

	io流的参数接收
		BufferedReader in = new BufferedReader(new InputStreamReader(request.getInputStream()));
		StringBuffer strBuff = new StringBuffer();
		String line;
		while ((line = in.readLine()) != null) {
			strBuff.append(line);
		}
		Utils.log("HTTPS,服务器响应结果是: \n" + strBuff.toString());

31. 防止表单重复提交
		请求表单页面创建一个token存入缓存中，带到页面的hidden token中  提交的时候校验

32. 前后端分离
		前端只利用Json来和后端进行交互，后端不返回页面，只返回Json数据。前后端之间完全通过public API约定
		未分离，先后端取数据后渲染页面。需要等后端返回数据才能处理(页面跳转，值在requrest中)，/分离后，先html后向后台取数据，这个可以自己模拟Jason数据不需要等
	
		前后端分离的情况下，基本使用json交互，没有什么服务端跳转或者客户端跳转之类，也没有mvc视图配置。使用@RestController相对@responseBody更加的方便，
		这和mvc模式不一样，原:通过视图名称找到对应视图，将数据模型渲染展示
		
		rest
		一般还是只是用Get和Post请求，使用接口名字来区分，所以，对于Rest规范，只需要记得传递数据只使用JSON，而不是后端去渲染模板，从而实现前后端的完全分离。
	
		前后端约定接口&数据&参数
		前后端并行开发（无强依赖，可前后端并行开发，如果需求变更，只要接口&参数不变，就不用两边都修改代码，开发效率高）
		
		大多数都是单独请求后台数据，使用json传输数据，而不是一个大而全的HTTP请求把整个页面包括动+静全部返回过来
	
		浏览器发送请求
			1.直接到达html页面（前端控制路由与渲染页面，整个项目开发的权重前移）
			2.html页面负责调用服务端接口产生数据（通过ajax等等，后台返回json格式数据，json数据格式因为简洁高效而取代xml）
			3.填充html，展现动态效果，在页面上进行解析并操作DOM。

33. 参数接收
	1. 实际mvc接收中，直接(String name)也能接收，没有@requestParam(可以自定义别名)也可以。SpringMV 目前也比较智能化，如果传递过来参数名称和 HTTP 的保存，那么无须任何注解也可 获取参数。这样方式允许参数为空。
	2. 使用一个POJO来接收这些参数，显然这个POJO属性和HTTP请求参数名一一对应了。在没有任何注解的情况下SpringMVC也能映射POJO。
			即使没有任何注解 们也能够有效传递参数，但是有时候前端的参数命和后台的不一致，比如前端传参数命名为role_name，这个时候就要进行转换(一般不用转换)
	3. 处理url参数类型，@PathVariable
	4. 传json类型，这里传的data 是一个data对象，其中pageParams属性也是一个对象。传参的data和接收的pojo保持一致即可
			var data = { 
				roleName :’role ’, 
				note :’note ’ , 
				pageParams: { 
					start: 1 , 
					limit: 20 
				}
			}
			//此处需要告知传递参数类型为json,不能缺少
			contentType：” application/json ”，
			//将JSON 转化为字符串传递     	data:{"dataParam":JSON.stringify(data)},   这种就接收的字符串自己转,这种和放url中拼接一样的接收方式，这种类似表单form提交格式
			data: JSON.stringify(data),    //这种是正规点，传递的是一个json串，而不是json对象。传list<T>类型，后端就@RequestBody List<T>接收
			后端直接json接收方式，，1.@RequestBody方式接收会快点，2.也可以传一个字符串，然后后端自己转成对象
	5. 表单提交，serialize()，后端直接类接收也行。
			通过表单序列化也可以将表单数据转换为字符串传递给后台，因为一些隐藏表单需要一定的计算，所以我们也需要在用户点击提交按钮后，通过序列化去提交表单。
			将数据以 roleName=xxx&namee=xxx 传递






## 高并发
    秒杀的记录 
	1、在不考虑缓存的情况下应该是要操作数据库的。最简单直接的实现就是在这个方法上加上synchronized关键字，更优化的是锁住秒杀的代码块； 
	2、将所有的线程用一个队列管理起来，使之变成串行操作，自然不会有并发问题。
    3. 	ConcurrentHashMap 默认情况下采用将数据分为 16 个段进行存储，并且每个段各自拥有自
	己的锁，锁仅用于 put 和 remove 等改变集合对象的操作，基于 voliate 及 hashEntry 链表
	的不变性实现读取的不加锁

    ConcurrentHashMap 锁住的不是全部的hash表，而是以多个segment的形式锁住单独的区域， 相当于把之前的数组分成多个segment，
	segment 可以看成是 HashMap 的一个部分，（ConcurrentHashMap 基于concurrencyLevel 划分出了多个 segment 来对 key-value 进行存储）每次操作都只对当前segment 进行锁定，从而避免每次 put 操作锁住整个 map。


## 过滤器，拦截器，Servlet

	一次请求只会成功匹配到一个servlet，但是filter只要匹配成功，这些filer都会在请求链filterchain上被调用。
	当filterchain上所有的filter对象执行完成后，会执行最终的servlet。
		
	servlet中配置的url-pattern,若请求没有匹配到所有的servlet，那么这个请求就直接返回
	url-pattern解析规则，对于servlet和filter是一样的
		1.精确匹配	如/foo.htm，只会匹配foo.htm这个url
		2.路径匹配	如/foo/*会匹配以foo为前缀的url
		3.后缀匹配	如*.htm会匹配所有以.htm的url
			
	备注： /foo/、/*.htm 和 */foo 都是不对的
	优先精确匹配，其次是最常路径匹配，最后是后缀匹配。


### 过滤器
    在filter中，response.getWriter().print()后,chain.do()到controller后，继续，
	也可以继续response.getWriter().print()，但是不能通过view层直接返回字符串信息，也不能返回页面

	简单的用@webfilter，需要springbean的就需要使用代理filter
	filter的执行顺序，FilterRegistrationBean注册时，filter顺序与@Bean注解实例顺序一致
	
	
	Filter的优先级大于Servlet，而springMVC又是基于Servlet来进行注入bean的，所以这就导致了Filter无法注入bean
	在Spring中，web应用启动的顺序是：listener ->filter -> servlet，先初始化listener，然后再来就filter的初始化，再接着才到我们的 dispathServlet 的初始化，因此，当我们需要在filter里注入一个注解的bean时，就会注入失败，因为filter初始化时，注解的bean还没初始化，不能注入 。
		（1）容器在启动的时候，会先加载filter，然后再加载Spring中的Bean。所以如果是直接在Filter 中进行SpringBean的注入，那么无法成功进行注入，因为要注入的Bean还没有进行初始化，是null。
		（2）DelegatingFilterrProxy是一个Filter。容器在启动的时候会加载这个Filter，对这个类的操作将会委托到 targetBeanName对应的Bean进行处理(Spring容器管理)，因为TargetBean是Spring的一个Bean，所以可以进行SpringBean的注入。
	
	如果不配置DelegatingFilterProxy，则由于filter比bean先加载，也就是容器或者Tomcat会先加载filter指定的类到container中，
	这样filter中注入的spring bean就为null了，
	或者也可以在filter中使用SpringContextUtil读取bean
	
	filter中没有chain.doFilter(httpRequest, httpResponse);//go   没有就不会进controller
	filter 中 response sendRedirect之后要 return;



### 拦截器
	定义了ABC拦截器，且在SpringMVC定义的顺序为A、B、C，preHandle是顺序执行的，postHandle与afterCompletion方法倒序执行的。
	且在SpringMVC定义的顺序为A、B、C。且B拦截器的preHandle方法返回false。则拦截器的执行行为如下：
	A.preHandle
	B.preHandle
	A.afterCompletion
	即B拦截器之前（包括B拦截器）的preHandle被执行及afterCompletion方法被执行（不包括B拦截器）
	
	只要有一个拦截器不放行，postHandle不会执行。
	所以当拦截器非正常执行完成时，会直接跳过所有拦截器的postHandle()函数，然后再逆向的执行preHandle()函数返回为true时的afterCompletion()方法

	boot中和普通的mvc中，执行顺序就是配置添加的顺序
	
	前置方法preHandle->处理器handler->后置方法postHandle->视图解析和渲染视图->完成方法afterCompletion


	拦截器顺序
		preHandle1
		preHandle2
		preHandle3

		postHandle3
		postHandle2 
		postHandlel 
		
		afterCompletion3
		afterCompletion2 
		afterCompletionl

	Spring会先从第一个拦截器开始进入前置方法(前置方法是按配置顺序运行的)，然后运行处理器的代码，最后运行后置方法。注意，后置方法和完成方法则是按照配置逆序运行的，这和责任链模式的运行顺序是 致的，

	注意，当其中的一个preHandle方法返回为 false 后，按配置顺序，后面的 preHandle方法都不会运行了，而控制器和所有的后置方法postHandle也不会再运行。执行过 preHandle 
	方法且该方法返回为true的拦截器的完成方法afterCompletion会按照配置的逆序运行
	比如拦截器2中的preHandle 中返回false，那么
		preHandlel 
		preHandle2 
		afterCompletionl
			





### Servlet
	*************
		路径匹配（以“/”字符开头，并以“/*”结尾），
		扩展名匹配（以“*.”开头），
		精确匹配，三种匹配方法不能进行组合，不要想当然使用通配符或正则规则。
		 
		servlet的执行顺序由匹配顺序决定，1.优先精确路径匹配 2.次之最长路径匹配， 3.最后后缀匹配
		如果前面三条规则都没有找到一个servlet，容器会根据url选择对应的请求资源。如果应用定义了一个default servlet，则容器会将请求丢给default servlet
		 
		比如servletA的url-pattern为/test/*，而servletB的url-pattern为/test/a/*，此时访问http://localhost/test/a时，容器会选择路径最长的servlet来匹配，也就是这里的servletB。 
		 
		sevlet拦截之后就不会进相关的controller了(而且当有一个servlet匹配成功以后，就不会去理会剩下的servlet了)
		自定义的servlet 可以使用路径匹配的，但是自定义dispatcherServlet，无法使用路径匹配，只能使用后缀和全路径，这个暂定
	*************
		servlet的本质其实也是一个java bean，controller是对servlet的封装，底层依旧是servlet。
		Spring MVC是基于servlet的，DispatherServlet，负责处理请求，调用了你的controller
		多DispatcherServlet的情况下，是registration.setName("rest")，默认为“dispatcherServlet”，这个语句很重要，因为name相同的ServletRegistrationBean只有一个会生效，也就是说，后注册的会覆盖掉name相同的ServletRegistrationBean。
		
		spring使用mvc时会产生两个context上下文，一个是ContextLoaderListener产生的，一个是由DispatcherServlet产生的(以spring的上下文为父容器)，它们俩是父子关系。
		父子级别的上下文。context，多个dispatcherservlet   的 context
		ContextLoadListener监听器在tomcat容器初始化的时候监听tomcat的servlet上下文，在这个监听器中，servletContext.setAttribute(WebApplicationContext.ROOT_WEB_APPLICATION_CONTEXT_ATTRIBUTE, this.context);
		
		@webservlet 注册到web容器中作为一个servlet(只适用自定义的servlet，DispatcherServlet是框架提供的servlet,需要ServletRegistrationBean定义)
		
		配置对应的DispatcherServlet，是需要加载对应的context的。
		那么支付项目中的，就是全部交给了mvc，通过.htm拦截。
		也可以继续加载自身的remoting.xml，交给单独的DispatcherServlet(ServletRegistrationBean.addUrlMappings murlappings不支持通配符，需为具体的路径 配置*.htm后缀是可以的 ,普通的没影响)。
			
		在原始的mvc的xml中配置中，dispatcher中的url(/)映射，当request匹配不到其他servlet，就会进入该Servlet，包括静态资源请求。
				
		在 web.xml 中使用 Listener 监听器来加载 Spring 的配置，Spring 会创建一个全局的 WebApplicationContext 上下文，其被称为根上下文，保存在 ServletContext 中，
		可以使用工具类取出上下文 WebApplicationContextUtils.getWebApplicationContext(ServletContext）
		从 WebApplicationContext 中可以获得ServletContext 的引用，整个Web 应用上下文对象将作为属性放置到 ServletContext 中，以便 Web 应用环境可以访问 Spring 应用上下文。getServletContext()

		多个dispatcherServlet，每个 DispatcherServlet都有自己的 WebApplicationContext 上下文 这个上下文是私有的,继承了根上下文中的所有东西

## Mybatis相关
    1.  原生jdbc访问：
        需要加入mysql连接驱动 
        一般顺序，
        1、加载数据库驱动 				    Class.forName("com.mysql.jdbc.Driver")
        2、获取数据库连接				    connection
        3、获取拼装预处理sql			    prepareStament
        4、执行prepareStament得到结果集		resultSet

        问题存在：
        1、数据库连接，使用创建connection，不用立即释放，频繁开启关闭，影响性能 
            解决方案：使用数据库连接池

        2、将sql语句以及设置参数，获取resultSet，硬编码java代码中，维护不方便
            解决方案：sql语句和参数配置在xml文件中，resultSet转为java对象

    2.使用mybatis
        执行顺序：
        配置mybatis配置文件，-->sqlSessionFactory-->sqlsession-->sqlsession内部executor执行器操作数据库-->mappedstatement（底层封装对象）

    3. #{} 和 ${} 的区别
        1. #{}表示一个占位符,体现在sql上是 =？ parameters：
        2. ${}表示拼接sql串，将接收到的参数内容不加任何修饰拼接在sql中，直接拼接在sql中，
	        但是可能引起sql注入 比如：select * from user where name like '%'or 1=1 or'%'
            传入的是简单类型只能使用${value}
    4. *mapper.xml中的resultType表示单条记录映射的java对象类型，表示返回的类型，是单个记录的类型
    5. mybatis和hibernate
        hibernate:是一个标准的orm框架，不需要写sql，自动生成
            应用场景：适应需求变化不多的中小型项目，比如后台管理项目
        mybatis：专注sql本身，需要自己写sql，比较灵活
            应用场景：需求变化较多的项目，互联网项目
    6. dao的开发方法：
        1、原始dao开发方法，需要写dao接口和dao实现类(过时不看)
            思路：	1.daoImpl可以继承sqlsessiondaosupport,注入sessionfactory属性值(由构造函数引入)，在方法体内通过sessionfactory，创建sqlsession
                    2.实现类中使用sqlsession操作，sqlsession在方法体内操作数据库

            总结：1、dao接口实现类存在大量的模板方法，
                2、调用sqlsession方法时，将statement的id硬编码，sqlsession.selectOne("test.findUserById",id)		首参是namespace的方法id,次参是传入参数
                3、调用sqlsession方法时传入变量，由于使用的是泛型，编译阶段即使变量传参类型错误，也发现不了问题

        2、mapper代理方法，只需要mapper接口(dao接口)
            1、namespace映射mapper
            2、xml中的id和mapper中方法名一致
            3、入参传参一致
            
            总结:封装了sqlsession的方法操作
                1、通过sqlsessionfactory得到sqlsession
                2、生成mapper代理对象 	UserMapper userMapper=sqlsession.getMapper(UserMapper.class )
                3、mapper方法执行，可以统一dmo或者map等对象入参(不灵活)，也可以@param多参数入参

        mapper代理开发
            1.使用mapperFactoryBean单一添加mapper代理对象，指定mapperInterface和sqlsessionfactory（因为bean继承了sqlsessiondaosupport），单一模式不常用

            2.项目中使用的是mapperscanner，扫描出mapper接口，自动创建代理对象并且在spring的容器中注入
 ```
            <bean class="....mapperscannerconfigurer">
                <property name="basePackage" value=""> 扫描多个包，使用半角，分割
                <property name="sqlsessionfactoryBeanName" value="sqlsessionfactory">      #不能配置name="sqlsessionfactory" 
            </bean>

            <bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean">  
                <property name="dataSource" ref="dataSource" />  
                <!-- 自动扫描mapping.xml文件 -->  
                <property name="mapperLocations" value="classpath*:dao/*.xml"></property>  
            </bean>  
 ```




7. typeAlias定义别名，mybatis扫描packsge中的po类，别名是类名resultType=“user”	
        通过mapper接口加载，mappers中的<package name="包名">
	    根据mapper的返回类型，sqlsession判断内部执行的是selectOne还是selectList

8. 动态sql：1.<if test="a and b"></if>
        2.<where>可以自动去掉条件中的第一个and
        3.<sql id="acc"></sql>抽取sql片段,		
        引用sql片段，<include refid="acc"></include> 若引用id不存在本mapper中，需前边追加namesapce
        4.<foreach collection="" item="" open="" close="" separator="">
            每次拼接对象
        </foreach>

		<where>和<trim>，<set>都可以达到去除多余 and 和or的效果。
		<if test="">对于字符串类型的判断，需要加上toString()方法
		模糊查询，mysql中常用的是concat方法



9. mybatis提供查询缓存(不实用，了解即可)
		没有springcache灵活，可以上到service级别
        一级缓存:sqlSession级别的缓存(不共享),一次service事务操作，sqlSession就结束清空缓存
            当调用SqlSession的修改、添加、删除、commit()、close()等方法时，就会清空一级缓存
            第一次查询，没有则数据库中查出并添加进一级缓存，中间如果有commit操作(修改、添加、删除)，则会清空全部，保证数据实时更新
            第二次查，缓存中有直接获取，有commit会从数据库重新查后再写入缓存

        二级缓存:mapper级别的缓存
            默认不开启， usecache=false设置禁用二级缓存
            多个sqlsession可以共享一个mapper的二级缓存区域（按照namespace区分,以命名空间为单位创建缓存数据结构）
            sqlsession关闭后才将数据写到二级缓存，commit后都会清空二级缓存，多个sqlsession之间可以跨，因为二级缓存是针对mapper的
            如果只是执行了增删改而没有提交，只会清空一级缓存的数据，不会清空二级缓存的数据。
            二级缓存适合共享的数据，且这种数据不能经常增删改，一改就清空缓存了，没用

            查出的数据首先放在一级缓存中，只有一级缓存被关闭或者提交以后，一级缓存数据才会转移到二级缓存
        
        整合方法：mybatis自带cach的接口，实现即可
            1、引入相关jar，配置mapper中的cache中的type为其实现类<cache type="">
            2、classpath下配置ehcache.xml


10. ehcache:jvm虚拟机中缓存，速度快，效率高；但是缓存共享麻烦，集群分布式应用不方便。依赖程序  单个应用或者对缓存访问要求很高的应用，用ehcache
        redis:通过socket访问到缓存服务，效率比ecache低，比数据库要快很多，处理集群和分布式缓存方便，有成熟的方案。独立的  大型系统，存在缓存共享、分布式部署、缓存内容很大

        缓存数据在各自服务器之间单独存储，相对用的是redis或者ehcache
        做tomcat的缓存共享比较消耗性能
    
11. spring和mybatis整合
        思路：
            1.需要spring通过单例方式管理sqlsession
            2.spring和mybatis整合代理对象，使用sqlsessionfactory创建sqlsession(spring和mybatis自动完成）
            3.持久层的mapper都需要由spring进行管理

        整合过程：
            1.相关spring的jar mybatis的jar  和spring-mybatis整合jar
            2.配置sqlsessionfactory （1.configlocation：mybatis.xml和2.datasource）,存在spring-mybatis的jar中


		mybatis的运行过程两大步，
			1.服务配置文件缓存到Configuration对象，用以创建sqlsessionfactory
			2.sqlsession的执行过程。
							 
		sqlsessionfactorybuilder构建sqlsessionfactory两步。
			1.通过xmlconfigbuilder解析配置的xml文件(或注解)，存入Configuration类对象
			2.configuration创建sqlsessionfactory。

	mybatis中要使用插件，需要实现Interceptor接口。一般不推荐使用插件。

12. 逆向工程：
        几种生成方法，一般是java工程和命令行，详见官方文档

13. 其中使用collection可以完成一对多的映射,查询出对象中的list属性
 ```
        <resultMap type="" id="">
            <id column="" property=""/>
            <result column="" property=""/>
            <association property="" javaType="">
                <id column="" property=""/>
                <result column="" property=""/>	
            </association>
        </resultMap>
```

	数组：<if test="object!=null and object.length>0">
	参数为集合List：<if test="object!=null and object.size()>0">

14. mybatis的dmo中如果有了有参构造函数，还要添加无参构造
	InstantiationException，实例化异常，缺少无参构造，抛出该异常，或者在orm框架中实现对象的映射，缺少无参构造也会异常

15. 每个mybatis应用程序都以一个sqlsessionfactory对象的实例为核心。
		编写好的dao接口，1.通过sqlSessionTemplate.getMapper获取实例(需要在xml中配置好对应的sqlSessionTemplate bean)
						 2.使用mapperscaner 扫描生成接口实例,对mapper创建代理对象
						 
		mybatis-spring中mapperScannerConfigurer,可以将映射接口直接转换为spring容器中的bean，即可注入service使用。
		扫描basepackage所指定的包下所有接口类（包括子包），如果在sql映射文件中定义过，则将他们定义为一个spring bean。
	
16. SqlSessionFactoryBean,主要是把*Mapper*.xml文件与*Mapper*.java加载进来，
	根据namespace加载对应的接口类到MapperRegistry，
	把方法名与*Mapper*.xml里的Select id对应起来等等。
	MapperRegistry相当于是一个缓存，后面创建代理对象是会用到。

    创建一个代理核心MapperProxy，并使用jdk的动态代理创建代理类，将sqlsession封装在invoke方法中
	public static <T> T newMapperProxy(Class<T> mapperInterface, SqlSession sqlSession) {
		ClassLoader classLoader = mapperInterface.getClassLoader();
		Class<?>[] interfaces = new Class[]{mapperInterface};
		MapperProxy proxy = new MapperProxy(sqlSession);
        return (T) Proxy.newProxyInstance(classLoader, interfaces, proxy);
    }

17. MyBatis 拦截器 （实现分页功能） 
	@Intercepts({ @Signature(type = StatementHandler.class, method = "prepare", args = { Connection.class }) })
	具体的原理是在StatementHandler上进行拦截，并进行代理，实现的思路是StatementHandler-> BOUNDSQL-->加工boundsql-->return ivk.proceed();


18. 一.PreparedStatement 是预编译的,对于批量处理可以大大提高效率. 也叫JDBC 存储过程
    二.使用Statement 对象。在对数据库只执行一次性存取的时侯，用Statement 对象进行处理。PreparedStatement对象的开销比 Statement 大，对于一次性操作并不会带来额外的好处。
    三.statement 每次执行 sql 语句，相关数据库都要执行 sql 语句的编译，preparedstatement 是预编译得,preparedstatement 支持批


19. 	mybatis主要完成两件事，
			1.根据jdbc规范建立与数据库的连接 
			2.通过反射打通java对象和数据库参数的交互之间相互转化的关系
			
 ```            
			PreparedStatement是Statement的子接口，它表示一条预编译过的SQL语句，可以添加参数效率高,可以防止SQL注入,.安全性好
			PreparedStatement perstmt?=?con.prepareStatement(sql);  // ？作为参数占位符
			perstmt.setString(1,var1);
			perstmt.setString(2,var2);
			perstmt.executeUpdate()
			
			原始的ibatis的调用实例
				Class.forName("com.mysql.cj.jdbc.Driver");
				Connection connection = DriverManager.getConnection("url", "user", "password");
				PreparedStatement ps = connection.prepareStatement("sql");
				ps.setInt(1, 10);
				ps.execute();
				ResultSet resultSet = ps.getResultSet();
				while(resultSet.next()) {
					String value = resultSet.getString("columName");
				}
 ```	

20. 这个是放在资源路径下的
	mybatis.mapper-locations=classpath:/mybatis-mapper/*Mapper.xml

	#mybatis
	mybatis.mapper-locations=classpath*:com/xiaoyuer/pay/mapping/*.xml
	mybatis.config-location=classpath:config/mybatis-config.xml

21. mybatis的逆向在github的官方文档有相关的xml配置说明。
	mybatis dmo使用自定义构造函数后，需要加一个默认的构造函数，否则会报错

	mybatis默认情况下提供自动映射，只要sql返回的列名能和pojo对应起来即可。

22. 	@MapperScan扫描后无需添加@Mapper、@Repository等注解(忽略)
		这种映射需要自己写，只适合简单的表，复杂的表不适用，不灵活，难维护，不推荐
		

		@Select("select * from bank_resc where id=#{id}")
		@Results({@Result(column = "bank_code",property = "bankCode"),@Result(column = "bank_name",property = "bankName")})
		BankResc selectByIdd(Integer id);	


		@Select("select user_name from user_base_info where id=#{id}")
		String getuserInfobyid(Integer id);
				

23. 	MyBatis的传入参数parameterType类型分两种
		 1.基本数据类型：int,string,long,Date;
		 2.复杂数据类型：类和Map
		如何获取参数中的值:
		 1.基本数据类型：#{参数} 获取参数中的值
		 2.复杂数据类型：#{属性名}  ，map中则是#{key}	


23. insert插入操作中，返回自增主键，xml中配置 useGeneratedKeys="true" keyProperty="id" 

	模式查询： user_name like concat('%',${userName},'%')

	update delete insert 返回的int 都表示影响的行数

24. xml中加减的时候，ua.account_fix = (ua.account_fix + #{param.freezeAmt}) 可以是一个负数

25. dao，idea中的dao中的xml需要单独配置加载(忽略)
 ```
	<resources>
		<resource>
			<directory>src/main/java</directory>
			<includes>
				<include>**/*.java</include>
				<include>**/*.xml</include>
			</includes>
			<filtering>false</filtering>
		</resource>
	</resources>
 ```
		
26. 配置数据库连接的时候只有在xml中&才需要转义成&amp;,在properties中不需要转义
	com.mysql.jdbc.Driver 是 mysql-connector-java 5中的，
	com.mysql.cj.jdbc.Driver 是 mysql-connector-java 6以后的

			
27. mybatis的几个核心组件
		sqlsessionfactorybuilder	构造器，创建sqlsessionfactory
		sqlsessionfactory			工厂接口，用来创建sqlsession，						
				相当于一个数据库连接池，一旦创建长期保存使用，占据数据库的连接资源，一般是单例
				在mybatis-spring中，使用SqlSessionFactoryBean 支持 SqlSessionFactory 的配置
				
		sqlsession					会话，SqlSession中定义的全是对数据库增删改查的各种方法，mybatis的核心接口对象、
				mybatis中的主要操作对象
				类似jdbc中的connection对象，代表一个连接资源的启用。1.获取mapper接口，2.发送sql给数据库 3.控制数据库事务
				存在一个业务请求中，操作事务，请求完成，关闭连接，归还给sqlsessionfactory。
				
		sqlmapper					映射器，由java接口和xml构成，需要给出对应sql和映射规则，发送sql执行，并返回结果
			主要作用就是将查询结果映射到一个pojo中，或者将pojo插入到数据库中。
			mybatis会为mapper接口生成一个动态代理，去处理相关的实现逻辑

28. mapper代理接口的源码实现，mapper动态代理
 ```	
	//基于InvocationHandler配置类，生成了实现接口的实现类
	//mapper的动态代理，核心就接口和sql中的配置，一个方法对应一个mapperMethod
	public class MapperProxy implements InvocationHandler, Serializable {
		private static final long serialVersionUID = -6424540398559729838L;
		private final SqlSession sqlSession;
		private final Class<T> mapperInterface;
		private final Map<Method, MapperMethod> methodCache;
		public MapperProxy(SqlSession sqlSession, Class<T> mapperInterface, Map<Method, MapperMethod> methodCache) {
			this.sqlSession = sqlSession;
			this.mapperInterface = mapperInterface;
			this.methodCache = methodCache;
		}
		//执行方法				
		public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
			try {
				if (Object.class.equals(method.getDeclaringClass())) {
					return method.invoke(this, args);
				}
				if (this.isDefaultMethod(method)) {
					return this.invokeDefaultMethod(proxy, method, args);
				}
			} catch (Throwable var5) {
				throw ExceptionUtil.unwrapThrowable(var5);
			}
			MapperMethod mapperMethod = this.cachedMapperMethod(method);
			return mapperMethod.execute(this.sqlSession, args);
		}
		//创建方法和sql配置的执行映射
		private MapperMethod cachedMapperMethod(Method method) {
			MapperMethod mapperMethod = (MapperMethod)this.methodCache.get(method);
			if (mapperMethod == null) {
				mapperMethod = new MapperMethod(this.mapperInterface, method, this.sqlSession.getConfiguration());
				this.methodCache.put(method, mapperMethod);
			}
			return mapperMethod;
		}
		public T newInstance(SqlSession sqlSession) {
			final MapperProxy<T> mapperProxy = new MapperProxy<T>(sqlSession, mapperInterface, methodCache);
			return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[]{mapperInterface}, mapperProxy);
		}
	}
 ```

 ```
	//自定义mapper代理，实现单一接口的代理，执行自定义逻辑
	Testmapper testceshi = (Testmapper) TestMapperProxy.newInstance("测试接口代理",Testmapper.class);
	如果不使用泛型T,那么外层就需要强转。执行了泛型,外层就不用转
	
	public class TestMapperProxy<T> implements InvocationHandler {
		private String  sqlSession;
		private final Class mapperInterface;
		public TestMapperProxy(String sqlSession, Class mapperInterface) {
			this.sqlSession = sqlSession;
			this.mapperInterface = mapperInterface;
		}
		public static <T> T newInstance(String sqlSession,Class<T> mapperInterface) {
				TestMapperProxy mapperProxy = new TestMapperProxy(sqlSession, mapperInterface);
			return  (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[]{mapperInterface}, mapperProxy);
		}
		@Override
		public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {
			if (Object.class.equals(method.getDeclaringClass())) {
	//          System.out.println("Object方法"+method.getName());
				method.invoke(proxy,method,args);
			}else{
				System.out.println("拿到操作对象:"+mapperInterface.getName());
				//进行自定义操作
				System.out.println("操作了对象参数:"+sqlSession);
			}
			return null;
		}
	}		
 ```
	mapper的动态代理，最后核心处理方法是sqlsession对象去运行对应的sql。mapper通过关联xml中的namespace，找到对应的执行方法。
	sqlSessioη.getMapper(RoleMapper.class);
	configuration.<T>getMapper(type, this)
	最终代理的是sqlsession的操作。通过namespace将sql和代理对象绑定起来




29. typeAliases 别名， 用来简化全限定名称，一般也不用。
	typeHandler 类型转换器，用来转换javaType 和 jdbcType
	
	映射器定义命名空间(namespace)的方法，对应一个接口的全路径，就是mapper接口。映射器能有效消除jdbc的底层代码

30. 两种自动映射
		自动映射，如果编写sql的列名和对象pojo的属性名一致，就会形成自动映射。默认开启
		驼峰映射，严格要求user_name 对应userName属性。不太灵活。不推荐 默认为false
		实际开发中，一般使用的是resultmap，建立结果集映射。
		
	多值传参
		多值传参也可以传map，但是可读性差，难维护，不推荐
		多值传参也可以使用javabean，当只有一个参数对象，可以指定类型后，直接写属性。多个参数，不行
		一般用的是@param单值传输，多于5个就不推荐用了
		sql中，#{userName}也可以不用给出parameterType类型，mybatis会自动识别

		
	<resultMap id = "cargo" type="cargo">
		<id property="cargoId" column="cargo_id"/>
		<result property="cargoTypeId" column="cargo_type_id"/>
	</resultMap>
		
	子元素id代表resultMap的主键，而result代表其属性。
	在自定义的resultMap中第一列通常是主键id。
	id和result都是映射单列值到一个属性或字段的简单数据类型。
	唯一不同的是，id是作为唯一标识的，当和其他对象实例对比的时候，这个id很有用，尤其是应用到缓存和内嵌的结果映射。级联
		
31. 分页相关
		1.逻辑分页   逻辑内存中，   查询所有数据 List, list.subList 截取你需要数据
			查出所有的数据，使用程序进行分页。它是针对ResultSet结果集执行的内存分页。
			占用内存大、数据更新不能及时反馈、不用频繁查询数据库
			
			mybatis自带的分页RowBounds(忽略)
				RowBounds： 逻辑分页，数据量大的时候压力较大。一般不用
				数据库返回的不是分页结果，而是全部数据，然后再由程序员通过代码获取分页数据。
				rowbounds是一次性取出数据放入内存再分割数据，一次获取所有符合条件的数据，然后在内存中对大数据进行操作
				常用的操作是一次性从数据库中查询出全部数据并存储到List集合中，因为List集合有序，再根据索引获取指定范围的数
				
				一次性将数据读取到内存，占用较大的内存空间(数据过大可能引起内存溢出)。数据发生了改变，数据库逇最新状态无法实时反映到操作中，适合数据量较小、数据稳定的场合
				总结：Mybatis的逻辑分页比较简单，简单来说就是取出所有满足条件的数据，然后舍弃掉前面offset条数据，然后再取剩下的数据的limit条
					
				在 mybatis 中，使用 RowBounds 进行分页，不需要在 sql 语句中写 limit。
				但是由于它是在 sql 查询出所有结果的基础上截取数据的，所以在数据量大的sql中并不适用，它更适合在返回数据结果较少的查询中使用
				最核心的是在 mapper 接口层，传参时传入RowBounds(int offset, int limit)对象，即可完成分页
				mapper 接口层代码如下
				List<Book> selectBookByName(Map<String, Object> map, RowBounds rowBounds);

		2.物理分页,直接通过SQL进行在数据库中直接分页,得到的数据就是我们想要分页之后的数据,就是物理分页;其实是依赖物理数据库实体。limit直接数据库查出需要的数据
			每次查询数据库，使用limit，需要计算总数、页数、当前页。
			占用内存小、数据更新及时反馈、频繁查询数据库
			
			mybatis插件或者直接书写sql进行分页;
				PageHelper： 物理分页， 通过拦截器加 limit 语句进行分页
				物理分页依赖的是某一物理实体，这个物理实体就是数据库，比如MySQL数据库提供了limit关键字，程序员只需要编写带有limit关键字的SQL语句，数据库返回的就是分页结果。
				每次都要访问数据库，对数据库造成的负担大
				每次只读取一部分数据，占用的内存空间较小
				每次需要数据时都访问数据库，能够获取数据库的最新状态，实时性强
				数据库量大、更新频繁的场合
			
				(1).通过自己的封装SQL根据beginNum(开始条数)和endNum(需要的条数)来进行分页  一般不用，不需要造轮子
						有点类似老系统的插件，自己封装查询limit 参数,需要手动进行封装总数以及分页信息,数据返回页面;
						自己创建分页插件，老系统，不推荐这样造轮子。

					分页插件的思路，拦截StatementHandler对象的prepare()方法，在预编译sql之前修改sql，得到结果的返回数量被限制。
					@Intercepts({ @Signature(type = StatementHandler.class, method = "prepare", args = { Connection.class }) })
					public class PagePlugin implements Interceptor {
					
					其中，＠Intercepts 说明它是个拦截器。＠Signature 是注册拦截器签名的地方，只有签名满足条件才能拦截type是四大对象中一个，这里是 StatementHandler。
					method 代表要拦截四大对象的某种接口方法，而args表示该方法参数，要根据拦截对象的方法参数进行设置
					mappedStatement.getId().matches(".*ListPage.*")


						
				(2).PageHelper分页插件(推荐)
						将pageNum和pageSize封装为page对象，保存在ThreadLocal中，实现线程间数据隔离。
						Pagehelper实现了Mybatis的Interceptor接口，调用拦截StatementHandler（Sql语法的构建处理）方法，按照物理库的不同重构SQL实现分页。
						
						插件拦截的对象：
						Executor：拦截执行器的方法（log记录）
						StatementHandler：sql语法构建处理
						ParameterHandler：拦截参数的处理
						ResultSetHandler：拦截结果集的处理
						
						PageHelper首先将前端传递的参数保存到page这个对象中，接着将page的副本存放入ThreadLoacl中，这样可以保证分页的时候，参数互不影响，接着利用了mybatis提供的拦截器，取得ThreadLocal的值，重新拼装分页SQL，完成分页。
				
32. 级联查询，关联

		结果集映射，集合，级联，关联，关联查询
		 
		MyBatis的级联分为3种。级联过多会降低查询性能   直接join查询出来关联
		mybatis不支持多对多，可以拆分成两个一对多级联处理。暂时忽略
		1. 关联-association				用于一对一
		2. 集合-collection				用于一对多
		
		比如同时有User.java和Card.java两个类
		public class User{
			private Card card_one;
			private List<Card> card_many;
		}
		在映射card_one属性时用association标签, 映射card_many时用collection标签.

		一般用left join

		RIGHT JOIN(忽略) 
			关键字会从右表 (Orders) 那里返回所有的行，即使在左表 (Persons) 中没有匹配的行。先查出右表值，再关联左表。

		column 是查询出来的结果集中的列名	
		<association property="reqUserInfo" column="req_User_Id" javaType="com.xiaoyuer.core.dmo.UserInfo">    一般这里column没有必要写
			<id property="id" column="req_User_Id"></id>
			<result property="nickName" column="rNick_Name" />
		</association>	
			
33. mybatis中一条sql和它相关的配置信息由3个部分组成
		MappedStatement			用来获取某条sql的所有配置信息
		Sqlsource				获取BoundSql对象
		BoundSql				建立sql和参数的地方，插件功能中常修改这个地方
		
	mybatis的四大对象
		1.Executor				执行sql的全过程，包括组装参数、组装结果返回集和执行sql过程
		*2.StatementHandler		是执行SQL的过程，我们可以重写执行SQL的过程它是插件最常用的拦截对象
		3.ParameterHandler		主要拦截执行SQL参数组装，我们可以重写组装参数规则
		4.ResultSetHandler		用于拦截执行结果的组装，我们可以重写组装结果的规则	
		
	一条查询SQL的执行过程 ：
		1.预编译sql。Executor调用StatementHandler的prepare()方法预编译SQL，同时设置些基本运行的参数。
		2.设置参数。用parameterize()方法启用ParameterHandler设置参数，
		3.执行sql。完成预编译，执行sql 。
		如果是查询MyBatis会使用ResultSetHandler 封装结果返回给调用者。


## 泛型相关
1. Java泛型中的标记符含义： 
	 只是为了提高可读性，没有特定意义
	 E - Element (在集合中使用，因为集合中存放的是元素)
	 T - Type（Java 类）
	 K - Key（键）
	 V - Value（值）
	 N - Number（数值类型）

2. 泛型推断：从JDK7 开始，Java允许在构造器后不需要带完整的泛型信息，只要<>即可推断出对应的类型。
　　比如：List<String> list = new ArrayList<>();

3.  <? extends T>表示该通配符所代表的类型是 T 类型的子类。
	<? super T>表示该通配符所代表的类型是 T 类型的父类。
	Class<T>代表这个类型所对应的类， Class<?>表示类型不确定的类

4. 	T 和 <T>的区别
	主要是看是否受Class<T>的影响
	必须要有泛型说明,1.要么自定义<T> T，2.要么跟着Class<E>走。
		
	<T> T表示返回值是一个泛型，传递啥，就返回啥类型的数据，
	而单独的T,代表一个类型,就是表示限制你传递的参数类型(用于共同操作一个类对象，单独T已经在类上限制了)

 ```
	public static <T> T get(String key, Class<T> clazz) {}
	private <T> T getListFisrt(List<T> data) {}			T是代表任意一种类型，<T>是一种形式，可以接受任意类型List参数。这个是不限定类型。
	private T getListFisrt(List<T> data) {}				初始化的时候已经限定了T的类型，所以getListFirst方法只能接受List<T>类型的参数。这个是限定类型。是编译就要指定的特定的类型
 ```

	****
		<T> T 	
			表示不限制类型			不受static影响，因为不需要编译期完成指定
			不需要 类上泛型标注，可以使用static修饰


		T		
			表示编译时候就要限制类型，限制特定类型，编译就指定，使用这个，受static影响，因为编译期需要完成，和static同时期，但是static修饰后又使用T,冲突
			需要类上使用泛型标注，

	****




	实例的demo
 ```
	public class Request<E> {
				/**
					* tClass 		方法入参
					* <T>  		声明此方法拥有一个类型T,也声明此方法是一个泛型方法
					* T    		指明该方法返回值为类型T
					* Class<T>  	指明泛型T的具体类型
					*/
				public <T> T getObject(Class<T> tClass) throws IllegalAccessException, InstantiationException {
					T t = tClass.newInstance();
					return t;
				}
				
			
				//第一个<T> 表示当前方法的值传入类型可以和类初始化的泛型类型不同
				//也是就是该方法的泛型类可以自定义，不需要跟类初始化的泛型类相同
				// 参数T  第一个表示是泛型，第二个表示是返回是T类型的数据，第三个表示限制参数类型为T
				private <T> T getListFirst(List<T> data) {
					if (data == null || data.size() == 0) {return null;}
					return data.get(0);
				}
				
				//这个只能传E类型的数据
				//这里不能写成T了，要么自定义<T> T，要么跟着类的<E>走
				private E getListFirst2(List<E> data) {
					if (data == null || data.size() == 0) {return null;}
					return data.get(0);
				}
				
				public static void main(String[] args) {
					List<Integer> data = new ArrayList<>();
					List<String> data2 = new ArrayList<>();
					//入参由List<T>的T 决定，因为返回值为<T> T ,所以入参不受 Request<T> 影响
					Integer a = new Request<String>().getListFirst(data);

					//编译出错，入参由Request<T> T的决定，受Request<T>影响
					//new Request<String>().getListFirst2(data);

					//没什么区别
					String aa = new Request<String>().getListFirst(data2);
					String bb = new Request<String>().getListFirst2(data2);
				}
			}

 
 ```



## 缓存相关
1. tomcat简单额session缓存共享(现在已经不用，忽略)
	1.Tomcat-redis-session-manager
	2.配置tomcat配置文件context.xml
	3.3、添加Tomcat-redis-session-manager的jar包到tomcat/lib目录下，需要的jar包如下：
			commons-pool2-2.2.jar
　　　　	jedis-2.5.2.jar
　　　　	tomcat-redis-session-manage-tomcat7.jar

2. 常见的session管理方案，
		1、session的同步复制，但是集群数量过多的时候不适用
		2、session集中管理，建立session存储，可以是数据库也可以是分布式存储
		3、通过cookie传递


3. 缓存共享，session共享
	1、最原始的是：直接通过tomcat自带的复制功能，即访问其中一台tomcat服务器就会在其他配置好的tomcat服务器上各复制一份session，存在一定的延迟，同时若并发量一大的话也会有网络风暴的风险
	2、使用tomcat-redis-session-manager,使用redis同步各tomcat之间的缓存（依赖tomcat，需要修改context.xml文件），但是目前只支持到jdk1.7
	3、更新使用spring session，存储在第三方存储容器redis的spring session，是配置在项目和代码中的
	

4. spring session相关：使用springboot项目很简单
		spring session在spring框架中的实现原理，
		其实就是在请求request上通过DelegatingFilterProxy代理过滤器封装了一层，将原来存储在容器缓存的session变成存储在redis的session，
		所以在web.xml中的此springSessionRepositoryFilter必须得是在所有filter的前面。
		用了spring session后，web.xml中设置session过期时间是无效。因为已存储在redis的session。
		
		jedisPoolConfig、connectionFactory、过期时间，springSessionRepositoryFilter,组装redisTemplate
		
 ```
			对于后端的请求创建了无效的session，可以在filter的FilterChain.doFilter之后删除session
			arg2.doFilter(request, response);
			if(request.getRequestURL().toString().contains("systemGateWay.htm")){
				request.getSession().invalidate();
			}
 ```


5. SpringSession相关
    1. springsession和boot的版本
        Redis的支持，替换掉底层Jedis的依赖，取而代之换成了Lettuce(生菜)
        spring2.0 整合spring session  先检查boot自带的相关依赖，然后移除spring-session的旧版本jar的依赖：
        spring5（springboot2.x）只支持spring-session-core了。
        最高版本的spring-session:1.3.5已经不再更新，而且支持到spring-session-data-redis:1.8。
        官方文档上写了，spring-session-data-redis2.x后只能搭配spring-session-core2.x
    
    2. 使用redis替换应用容器（tomcat的session容器）
		原先的tomcat管理内存，Cookie 中记录的 Key 值是 JSESSIONID，而替换成 RedisHttpSession 之后变成了 SESSION。
		
	    spring session 中 每次request请求都会刷新Session，重置原先的过期时间
    
    3. 设置cookie相关
 ```
        @Bean
        public HttpSessionIdResolver httpSessionIdResolver() {
            CookieHttpSessionIdResolver cookieHttpSessionIdResolver = new CookieHttpSessionIdResolver();
            DefaultCookieSerializer cookieSerializer = new DefaultCookieSerializer();

            //cookieSerializer 可以配置cookie相关，包括setCookieName("JSESSIONID") 还原sessionid的name.
    //	    cookieSerializer.setCookieName(redisProperty.getCookieName());//cookies名称 默认是session

            //跨站sessionid会有问题，写的时候进行base64编码，读的时候进行base64解码
            //这个要关闭，否则sessionid会在浏览器编码显示，导致跨手机 和pc的sessionid变化
            cookieSerializer.setUseBase64Encoding(false);
            cookieSerializer.setDomainName(domainName);
            cookieSerializer.setCookiePath("/");
            cookieHttpSessionIdResolver.setCookieSerializer(cookieSerializer);
            return cookieHttpSessionIdResolver;
        }
 ```
    4. 配置
        1.配置redis连接工厂(factory:poolconfig)
        2.RedisHttpSessionConfiguration
        3.springSessionRepositoryFilter
            spring:session 是默认的 Redis HttpSession 前缀(redis中，常用 ‘:’ 分割),
            Spring Session 之所以能够替换默认的 tomcat httpSession  因为配置了springSessionRepositoryFilter
    
            -- redis中目录结构
                3(A).spring:session::sessions:77112-sdd12-....					对应的是 hash 数据结构			默认35分钟
                2(B).spring:session:expiretions:123123123						set 结构(存储系列1类型键)		默认30分钟			存放着这一分钟(当前时间+过期时间)应当过期的 session 的 key。
                1(C).spring:session:sessions:expires:77112-sdd12-....			对应一个空值,String				默认30分钟			手动改redis无效，有自己的预先缓存机制吧。
    
    
                A.存储Session的详细信息，包括Session的过期时间间隔、最近的访问时间、attributes等等。这个k的过期时间为Session的最大过期时间 + 5分钟。如果默认的最大过期时间为30分钟，则这个k的过期时间为35分钟
                B.存储这个Session的id，是一个Set类型的Redis数据结构。这个k中的最后的1439245080000值是一个时间戳，根据这个Session过期时刻滚动至下一分钟而计算得出。
                C.表示Session在Redis中的过期，这个k-v不存储任何有用数据，只是表示Session过期而设置。这个k在Redis中的过期时间即为Session的过期时间间隔
    
                每一个 session 都会有三个相关的 key	，
                第三个 key 最为重要，它是一个 HASH 数据结构，将内存中的 session 信息序列化到了 redis 中,形如sessionAttr:browser=chrome
                另外两个过期时间，因为redis 清除过期 key 的行为是一个异步行为且是一个低优先级的行为，
                用文档中的原话来说便是，可能会导致 session 不被清除。
                于是引入了专门的 expiresKey，来专门负责 session 的清除，包括我们自己在使用 redis 时也需要关注这一点
    
                C 类型键存在的意义便是解耦 session 的存储和 session 的过期，并且使得 server 获取到过期通知后可以访问到 session 真实的值。
                对于用户来说，C 类型键过期后，意味着登录失效，而对于服务端而言，真正的过期其实是 A 类型键过期，这中间会有 5 分钟的误差。
            
            
            
            request.getSession().invalidate(),会将c类型的立刻删除，然后B类型的还会多保留5分钟在服务器上。
            在调用request.getSession().invalidate()会销毁当前的session，后续再调用request.getSession()会重新创建一个session
            
            *****对于多余的无用sessioin，一般在filter中的chain.dofilter之后清除当前无用的session*****
            request.getSession().invalidate();  会删除当前的session， 对应springsession中是spring:session:sessions:expires:77112-sdd12-....  这种类型的过期，但是主sessionid还在服务端存放一定时间
            request.getSession().invalidate()   可以测试ok  会保留5分钟的时间后自动删除
            

            boot使用的就是本身的SessionRepositoryFilter，自动配置了spring-session，一般不建议改动默认配置

    5. 我们只需要告诉spring开启redis方式的session存储即可，这里有两种方式可以实现
		方式1、在配置文件中添加一行配置     spring.session.store-type=redis     //第一种方式：修改application.properties，添加
		方式2、在程序启动类上添加注解        @EnableRedisHttpSession            //第二种方式：启用注解


		boot中是自动高配置的
     ```
		@Configuration
		@ConditionalOnBean(SessionRepositoryFilter.class)
		@EnableConfigurationProperties(SessionProperties.class)
		class SessionRepositoryFilterConfiguration {
			@Bean
			public FilterRegistrationBean<SessionRepositoryFilter<?>> sessionRepositoryFilterRegistration(
					SessionProperties sessionProperties, SessionRepositoryFilter<?> filter) {
				FilterRegistrationBean<SessionRepositoryFilter<?>> registration = new FilterRegistrationBean<>(filter);
				registration.setDispatcherTypes(getDispatcherTypes(sessionProperties));
				registration.setOrder(sessionProperties.getServlet().getFilterOrder());
				return registration;
			}
     ```
    6. redis过期
        后台提供了定时任务去“删除”过期的 key，来补偿 redis 到期未删除的 key。
			方案再描述下：取得当前时间的时间戳作为 key，去redis中定位到 spring:session:expirations:{当前时间戳}这个 set 里面存放的便是所有过期的 key 了。
			
			spring-session中有个定时任务，每个整分钟都会查询相应的spring:session:expirations:整分钟的时间戳中的过期SessionId，然后再访问一次这个SessionId，
			即spring:session:sessions:expires:SessionId，以便能够让Redis及时的产生key过期事件——即Session过期事件。
		
			
			redis的key过期具有一定延迟性：
			1.redis 在键实际过期之后不一定会被删除，可能会继续存留，但具体存留的时间我没有做过研究，可能是 1~2 分钟，可能会更久。
			2.具有过期时间的 key 有两种方式来保证过期，一是这个键在过期的时候被访问了，二是后台运行一个定时任务自己删除过期的 key。划重点： 这启发我们在 key 到期后只需要访问一下 key 就可以确保 redis 删除该过期键
			3.如果没有指令持续关注 key，并且 redis 中存在许多与 TTL 关联的 key，则 key 真正被删除的时间将会有显著的延迟！显著的延迟！显著的延迟！
			  
			每次 session 的续签，需要将旧桶中的数据移除，放到新桶中。验证这一点很容易。
			this.redis.hasKey(key)可以触发将 redis过期键删除

7. maxInactiveIntervalInSeconds(session中的数据的过期时间(不是session在redis中的过期时间))   

8. Session的一致性问题，在昨天的课堂中讲解了四种方法，
			(1)基于IP机制的负载均衡，各自维护自己的session.
			(2)服务器session复制，可以通过Tomact配置集群的方式配置同步session。
			(3)Session 统一缓存，这个就是spring seesion解决方案。
			(4)客户端缓存，也就是token机制关于APP token验证的疑问?。

9. Springcache相关
    引入springcache，需要自定义缓存管理器，场景：高查询  低改动
	默认使用rediscache，最终存在Redis中，可跨系统

	@EnableCaching 表示SpringIoC容器启动了缓存机制
	一般查询用＠Cacheable；插入和修改，使用＠CachePut；删除操作，使用＠CacheEvict。

	常规配置: 失效时间，序列化方式(redis服务端易读)，目录的层级(默认是::)

	查询原理：
		每次调用需要缓存功能的方法时，Spring会检查检查指定参数的指定的目标方法是否已经被调用过(依据是value+key,相同会覆盖，一般key中追加参数信息)；
		如果有就直接从缓存中获取方法调用后的结果，如果没有就调用方法 并缓存结果后返回给用户。下次调用直接从缓存中获取。
		先执行@Cacheable----->再执行service层的方法，基于注解()，实际就是个拦截器(就是使用注解省去了判断的过程。原先是判断没有缓存，就从数据库查询，这里讲判断隐藏到了注解去实现)

	Spring Cache对Cache进行抽象，提供了@Cacheable、@CachePut、@CacheEvict等注解。
		@Cacheable
			根据方法对其返回结果进行缓存，下次请求时，如果缓存存在，则直接读取缓存数据返回；如果缓存不存在，则执行方法，并把返回的结果存入缓存中。一般用在查询方法上。
		@CachePut
			使用该注解标志的方法，每次都会执行，并将结果存入指定的缓存中。其他方法可以直接从响应的缓存中读取缓存数据，而不需要再去查询数据库。一般用在新增方法上。
			需要返回待缓存的对象，存入cache
		@CacheEvict
			使用该注解标志的方法，会清空指定的缓存。一般用在更新或者删除方法上
			无需返回对象

	Springcache 和redis的区别
		1.Spring cache是代码级的缓存，一般是使用一个ConcurrentMap，也就是说实际上还是是使用JVM的内存来缓存对象的，这势必会造成大量的内存消耗。但好处是显然的：使用方便。
		2.Redis 作为一个缓存服务器，是内存级的缓存。它是使用单纯的内存来进行缓存。
		3.集群环境下，每台服务器的spring cache是不同步的，这样会出问题的，spring cache只适合单机环境。
		4.Redis是设置单独的缓存服务器，所有集群服务器统一访问redis，不会出现缓存不同步的情况。


	通常情况下，直接使用SpEL表达式来指定Key比自定义KeyGenerator更简单。
		key = "'USER:'+#id"
		空参数使用默认的key就是calendar::SimpleKey []，多次调用会覆盖同名key
		可以使用单独的字符串作为key="'zhaoyun'"

		注解使用在mapper上，需要使用p绑定：	@Cacheable(value=ConstantsRedis.CACHE_PAY,key="'withdraw:config:'+#p0+'-'+#p1")
		在service上：	@Cacheable(value="cache",key="'letterBank-'+#firstLetter")  
		若不希望返回值为null时进行缓存，则使用unless="#result == null",排除掉返回值为null的结果	
		若不希望参数为空的时候进行缓存，则需要使用condition = "#i==null",这时函数还没执行，排除掉参数为空的情况
		key="‘wangyun’+#userinfo.id"
	

	配置
		这个做springcache用的，查询结果缓存使用
 ```
		@Bean
		public CacheManager redisCacheManager(RedisConnectionFactory redisConnectionFactory) {
			//1.设置key 和value的序列化方式
			RedisSerializer<String> redisSerializer = new StringRedisSerializer();
			Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class);
			
			ObjectMapper om = new ObjectMapper();
			om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY);
			om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL);
			jackson2JsonRedisSerializer.setObjectMapper(om);

	//		定义缓存前缀,默认是两个冒号
			CacheKeyPrefix keyPrefix = new CacheKeyPrefix() {
						@Override
						public String compute(String cacheName) {return cacheName + ":";}
					};
					
			//2.链式调用(返回new的config对象)设置config
			RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig()
					.entryTtl(Duration.ofMinutes(30))
					.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(redisSerializer))
					.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(jackson2JsonRedisSerializer))
					.disableCachingNullValues().computePrefixWith(keyPrefix);
			return RedisCacheManager.builder(redisConnectionFactory).cacheDefaults(config).build();
		}
 ```
 
10. boot中的redis
			在引入Redis中一般排除redis的异步客户端lettuce(一般在spring-boot-starter-data-redis 2.x版本默认，用的比较少)，使用jedis。
			
			spring提供了一个redisconnectionfactory接口，生成redisconnection(对应jedis驱动，其实现类jedisconnection)接口对象
			使用redistemplate，实际使用中最多的还是stringredistemplate
			
			序列化方式	
			1.stringredisserializer  
			2.jdkserializationredisserializer(redistemplate默认序列化器)   
			3.jacksonJsonRedisSerializer 已经过时，不推荐使用
			
			redis事务(忽略)
				通常的命令组合是watch...multi...exec, 
				watch是监控redis的一些键，
				multi命令是开始事务，
				exe命令意义在于执行事务(队列命令执行前会判断被watch监控的redis键数据是否变化过(赋值相同也算变过)，没变才会执行事务)
				redistemplate.execute((RedisOperations operationns) ->{
					operationns.watch("key1");//监控key1
					operationns.multi();//开启事务，在exec命令执行前，全部命令都只是进入队列,期间的set后随即get value也是null，
					... 	//一些列操作 
					return operationns.exec();//执行exec命令，将先判别keyl是否在监控后被修改过，如果是则不执行事务，否则就执行事务
				})
			
			使用redis流水线技术可以批量执行redis的命令(忽略)
			redis中也可以做发布订阅模式，只能算是简化版的mq
			
		旧项目中是代码形式是封装的jedis启动类，
			jedisPool = new JedisPool(JedisPoolConfig, ip, port)， 
			Jedis jedis = jedisPool.getResource(); //用jedis操作对象

11. 缓存的选择  ehcache   redis  memcached
		memcached:	服务器端是c编写的，客户端多语言实现，相对下面，效率低
		Ehcache:	纯java编写的,相对上面效率高，
		综合比较，两者会选ehcache。redis另算
		
		ehcache就是一个框架，提供了一些缓存方案而已，底层基于jvm内部缓存开发的，大白话就是，基于jvm提前加了一些功能方便你开发，没啥太大区别。

		ehcache直接在jvm虚拟机中缓存，速度快，效率高；但是缓存共享麻烦，集群分布式应用不方便。
		redis是通过socket访问到缓存服务，效率比ecache低，比数据库要快很多，处理集群和分布式缓存方便，有成熟的方案。 

		如果是单个应用或者对缓存访问要求很高的应用，用ehcache。 
		如果是大型系统，存在缓存共享、分布式部署、缓存内容很大的，建议用redis。
		补充下：ehcache也有缓存共享方案，不过是通过RMI或者Jgroup多播方式进行广播缓存通知更新，缓存共享复杂，维护不方便；简单的共享可以，但是涉及到缓存恢复，大数据缓存，则不合适。


12. Redis相关
		Redis是单线程的，是线程安全的。

		redis是操作是原子性的，可存储 字符串，列表，集合多种数据类型

		redis的数据结构，数据类型
		hget pay:bankcard_acct 1366          pay:bankcard_acct       key-1366 value-5
		type key	查询redis的key类型

		redis持久化 
			方案：相对来说使用aof的sec足够了，先重点，细节用到再说，默认是rdb模式
				rdb:在指定的时间间隔内将内存中的数据集快照写入磁盘
					数据集快照dump到dump.rdb中，可以修改dump的频率。快照文件总是完整可用的
					频率比如:300秒内，如果超过10个key被修改，则发起快照保存 ；
					
					fork一个子进程来进行持久化，不影响主进程的io操作
					快照备份，是备份当前瞬间 Redis 在内存中的数据记录。备份慢一点，恢复快
					
					生成rdb文件的命令
					save	阻塞服务器进程，知道rdb创建完成为止，阻塞期间，不接受任何命令
					bgsave	用子线程创建rdb文件，服务器进程继续处理命令请求
					
					多个save命令(用save选项设置的保存条件)，是或关系，满足条件就会执行bgsave命令
					
				aof:每次写指令操作，进入aof记录文件。追加命令进文件保存
					追加文件，备份快，恢复慢，备份文件可能大
					其作用就是当 Redis 执行写命令后，在一定的条件下将执行过的写命令依次保存在 Redis中， 将来就可以依次执行那些保存的命令恢复 Redis 的数据了
			
				三种策略：每次修改，每秒同步(常用)，从不同步
				数据恢复时按照丛前到后的顺序再将指令执行一遍
			
				其中包含重写机制，一条 incr*100，最后可以合成一条incr100
			
				redis提供了string,hash(hset),list,set(类似队列操作) 这几种数据类型可供存取
				
				redis
				最简单的 String ，可以作为 Memcached 替代品，用作缓存系统
				使用 SetNx 可以实现简单的分布式锁
				使用 list Pop Push 功能可以作为阻塞队列／非阻塞队列
				使用 SUBSCRIBE PUBLISH 可以实现发布／订阅模型对数据进行实时分析，如可以累加统计等
				使用 Set 做去重的计数统计
				使用 SortedSet 可以做排行榜等排序场景
				以上场景基本上涵盖了 Redis 支持的各种存储结构
				? Key 可以是任意类型，但最终都会存储为 byte ［］
				? String 简单的（key,value ）存储结构，支持数据的自增、支持 BitSet 结构
				? Hash 哈希表数据结构，支持对 field 的自增等操作章数据存储 189
				? list 列表，支持按照索引、索引范围获取元素以及 Pop Push 等堆桔操作
				? Set 集合，去重的列
				? SortedSet 有序集合
					
				如果想要保证数据的安全性，建议同时开启 AOF RDB ，此时由于 RDB 有可能丢失文件 Redis 重启 优先使用 AOF 进行数据恢复

				需要注意 ，如果通过 kill -9 或者 Ctrl+C 关闭 Redis ，那么 RDB AOF 都不会被触发，这样会造成数据丢失，建议使用 redis-cli shutdown 或者 kill 优雅关闭 Redis

13. ehcache(单体) 和redis(分布式)
	ehcache直接在jvm虚拟机中缓存，速度快，效率高；但是缓存共享麻烦，集群分布式应用不方便。是可以做集群缓存共享的，但是做服务话不适用，这个是跟着java内存走的
	redis是通过socket访问到缓存服务，效率比ecache低，比数据库要快很多，处理集群和分布式缓存方便，有成熟的方案。

	如果是单个应用或者对缓存访问要求很高的应用，用ehcache。
	如果是大型系统，存在缓存共享、分布式部署、缓存内容很大的，建议用redis。
				
14. getsession时候，不存在会直接创建新的，所以如果getattribute取不到前设置的session，很可能已经过期，重新创建一个新的session了

15. js中的多个ajax异步请求的执行时并行，不会等待操作。执行的快与慢，要看响应的数据量的大小及后台逻辑的复杂程度。
	cookie.setMaxAge();pc中设置的是-1。默认值是-1，表示关闭浏览器，cookie就会消失。如果是正数，表示从现在开始，即将过期的seconds。
	
	Cookie newCookie=new Cookie("SESSION",null); 
	newCookie.setMaxAge(0);    
	ids页面刷新sessionid，当前request带进的session，response时候删除对应session，那么这过程中的设值无效
		
	就是不同的domain域对应不同的cookie，比如http 和https,重定向和浏览器直接敲，会把相应的sessionid带到后台，这样是共用一个sessionid
	但是http后台请求每次都会产生一个新的sessionid

## 设计模式
1. 单例模式		
		*****确保一个类只有一个实例，并且提供一个全局访问点。*****分别对应构造私有和静态访问
		确保只有一个实例会被创建
		线程池，日志对象只能有一个实例。
		单例实现：构造私有化，并提供static访问实例的方法即可
		
		典型代码：
		这里可能会有线程问题，使用双重检查加锁，性能还可以
		public class Singleton{
			private static Singleton uniqueInstance;//利用一个静态变量记录该类的唯一实例
			private Singleton(){};
			public static Singleton getInstance(){
				if(uniqueInstance==null){
					uniqueInstance=new Singleton();
				}
				return uniqueInstance;
			}
		
		这里使用静态变量有两层意思：1.静态方法类中变量必须是静态变量。2.单例就是共享一个实例，符合静态共享
		private static Singleton uniqueInstance=new new Singleton();  这个就是线程安全的
		
		}
			
		java中实现单例模式需要：1私有构造，2静态方法 和 3静态变量
2. 	工厂模式
        用来封装对象的创建，让子类决定该创建的对象时什么。
        定义了一个创建对象的接口，由子类决定要实例化的接口是哪一个。工厂方法让类把实例化推迟到子类。
        将对象创建的方法封装起来
3. 


## 动态代理
    动态代理：
        jdk，	基于接口实现，创建实现类完成目标对象的代理，生成方便，性能稍差
		cglib	基于类的继承，创建子类，是对目标类扩展的子类  字节码是实现，可读性差点
			
			
			
			
			
			
		CGLib代理，不受接口的限制，底层采用ASM字节码生成框架，效率高比使用Java反射效率要高。注意CGLib不能对声明为final的方法进行代理，因为CGLib原理是动态生成被代理类的子类。
		其中需要使用 //Enhancer类是CGLib中的一个字节码增强器，它可以方便的对你想要处理的类进行扩展
		jdk使用的invocationhandler接口
		cglib使用的是MethodInterceptor接口





    
**>>>核心思想<<<**
		基于jdk的接口的动态代理，其实接口和实现类都可以被代理，因为private Object target;  这里被代理类是obj，接口本身也是属于obj的
		本质上是invoke中拿到method后的处理方式：
			1.实现类处理方式是，用反射，用实例调用对应的方法，所以被代理实例要实现同一接口，这样能对应上
			2.接口的处理方式是，拿到对应的方法后，可以进行些其他的操作，比如，根据接口找到映射的xml中的sql再执行，


		这两种处理方式实际场景就是
			1.创建一个实现类的代理类，做增强处理
			2.创建一个接口的代理类，可以做rpc，也可以是mapper调用
**>>>核心思想<<<**

    ciglib
        关键点 1.定位连接点   2，增强中编写切面代码 说白了就是定位切入点，将逻辑织入
		不能对目标类中的final或者private方法进行代理。
        cglib采用底层的字节码技术，创建一个类的子类，在子类中采用方法拦截的技术，拦截所有父类方法的调用，并顺势植入横切逻辑
		通过切面将切点和advice增强组装起来，aop就是负责实施切面的框架，将切面定义的逻辑织入切面指定的连接点
		
 ```
		ciglib代码实例
		public class UserServiceCglib implements MethodInterceptor {
			private Object target;
			public Object getInstance(Object target) {
				this.target = target;
				Enhancer enhancer = new Enhancer();
				enhancer.setSuperclass(this.target.getClass());
				enhancer.setCallback(this);// 设置回调方法
				return enhancer.create();// 创建代理对象
			}
			/**
				* 实现MethodInterceptor接口中重写的方法，回调方法
				*/
			@Override
			public Object intercept(Object object, Method method, Object[] args, MethodProxy proxy) throws Throwable {
				System.out.println("事务开始。。。");
				Object result = proxy.invokeSuper(object, args);
				System.out.println("事务结束。。。");
				return result;
			}
		}
 ```
		两种方法相似，通过geProxy方法生成代理对象，执行代理的逻辑类（需要实现一个接口，一个是invocationhandler,一个是MethodInterceptor），决口定义的方法就是代理对象的逻辑方法。可以控制真实对象的方法
		
		拦截器设计思路，用封装设计好的拦截器来实现动态代理的功能。拦截器底层还是动态代理。设计拦截器，让开发者直接使用，隐藏底层动态代理的实现。简化开发
		
		interceptor实现原理，就是getProxy方法的参数中(target,interceptorClass)传连个参数,然后invoke中根据情况实现逻辑。
		这里被代理的类还是target，只不过增加的interceptorClass的一层判断，根据判断结果执行target的相关方法
				
		多个拦截器的处理链即各proxy依次作为下个拦截器代理的target，链式调用。
				





		
    只有public修饰的接口才能实现jdk动态代理，但是public static也不行
	由于final static private 修饰方法不能被继承，所以不能ciglib动态代理


2. jdk代理基于接口实现，创建代理类实现invocationhandler接口，实质上是对被代理类的增强
    1、统一的接口 
    2、被代理类 
    3、代理核心（需要注入目标类） 然后使用proxy调用，

3. jdk的动态代理需要绑定代理对象和真是对象的关系，可以封装在代理的操作类中，就是说再invocationhandler中直接加上代理创建方法
	cglib创建代理，只需要一个非抽象的类就能实现动态代理，主要代理操作类是实现MethodInterceptor接口，通过加强这Enhancer实现代理
	*Enhancer是cglib中使用频率很高的一个类，它是一个字节码增强器，可以用来为无接口的类创建代理。它的功能与java自带的Proxy类挺相似的。它会根据某个给定的类创建子类，并且所有非final的方法都带有回调钩子。




## Rpc相关
    使用工厂模式，将工厂类加入容器，初始化就会返回的代理类添加到容器中，创建接口的代理类，
	将http的请求封装在代理方法中，使用代理类，这样实现了类似本地化的远程调用，
	前提是知道了访问的地址，路径默认是方法名，则这样，调用接口，直接就能找到bean，是实现远程调用

    序列化问题
        jdk序列化写入不仅是完整的类名，也包含整个类的定义，包含所有被引用的类。性能和效率低，java专用的，不能跨语言
        
        序列化是输出，用out流，反序列化是输入用input流，用到的就是 ByteArrayOutputStream()，ObjectOutputStrea/ByteArrayInputStream,ObjectInputStream;	
    
        protostuff序列化，减小序列化后的数组大小(忽略)
        需要引入的jar有protostuff-collectionschema，protostuff-core，protostuff-runtime，protostuff-api

        hessian将对象序列化与语言无关的二进制协议，跨语言，适合传输较小的对象，服务化结构中大量的服务调用是大规模、高并发的短小请求，比较适用

        序列化机制的核心作用就是对象状态的保存与重建。字节序列和Java对象之间的转换
	    为什么要用序列化？进程通信实现文本图片音频等传输外（二进制序列形式），java对象传输必须序列化

    服务化好处
        服务化的过程就是拆分的过程，各个服务之间是独立的，相互解耦的。
        分开独立维护，上线影响范围小，不需要全团队沟通
        模块公用，降低系统负载
	

    每个服务都有多个实例在运行，每个实例可以运行在容器化(tomcat)平台内，打到平滑伸缩的效果(根据性能需求独立水平伸缩,大白话就是加机器)
	每个服务都有自己的数据存储，实际上每个服务都应该有自己独享的数据库、缓存、消息队列等资源

    互联网中拆分：
		水平拆分：从单节点扩展为多个节点，具有一致功能，组成一个服务池，所有节点共同处理大规模请求，简单讲就是做集群
		垂直拆分：就是按照功能进行拆分，专业人干专业事情，产品迭代快，敏捷开发

    tips: 永远不要在本地事务中调用远程服务，在这种场景下如果远程服务出现了问题你，则会拖长事务，导致应用服务器占用太多的数据库连接，让服务器负载迅速攀升，严重情况下，会压垮数据库


    几个一致性问题：
		1.下单和扣库存，两个服务之间最终的一致性
		2.同步调用超时，a调用b，a系统是可以得到超时反馈的，但是b不知道，处理情况类似之间的hessian处理，增加缓存补偿，设置超时时间
		3.异步回调超时，补偿做job重新发即可


       在微服务中，保证最终一致性的模式：
		1.查询模式
			提供查询接口，用来输出服务操作执行状态。
			使用查询模式了解被调用服务的处理情况，决定下一步做什么。例如：补偿未完成操作还是回滚已完成操作。
			为了能够实现查询，每个服务操作都需要有唯一的流水号标识，也可使用此次服务操作对应的资源 ID 来标识，例如：请求流水号、订单号等
			
		2.补偿模式
		为了让系统最终达到一致状态而做的努力叫做补偿。
		对于服务化系统中同步调用的操作，若业务操作发起方还没有收到业务操作执行方的 明确返回或者调用超时，可使用查询模式去查，再做相应的操作(类似之前的redis标记)
			
			补偿操作根据发起形式分为以下几种:
			自动恢复：程序根据发生不一致的环境，通过继续进行未完成的操作，或者回滚己经完成的操作，来自动达到 致状态。
			通知运营：如果程序无法自动恢复，并且设计时考虑到了不一致的场景，则可以提供运营功能，通过运营手工进行补偿。
			技术运营：如果很不巧，系统无法自动回复，又没有运营功能，那么必须通过技术手段来解决，技术手段包括进行数据库变更或者代码变更，这是最糟的 种场景，也是我们在生 中尽 避免的场景
			
		3.异步确保模式
		 通过异步的方式进行处理，处理后把结果通过通知系统通知给使用方 。这个方案的最大好处是能够对高并发流量进行消峰.案例是job
		 
		4.定期校对模式
			关键是有全局唯一的id
			通过补偿操作来达到最终一致性，但是如何来发现需要补偿的操作呢？
			可以在事后异步地批量校对操作的状态，如果发现不一致的操作，则进行补偿。
		
		5.可靠消息模式 （发送可靠和消费可靠）
			使用消息队列处理可异步处理的操作，发送前存入数据库，未发送成功的定时补发
			幂等处理，因为保证消息可靠发送需要有重试机制，消息就一定会重复，那么我们需要对重复的问题进行处理。
			
			保证幂等性的常用方法：
				1).使用数据库表唯一键滤重，拒绝重复的请求
				2).使用分布式表对请求滤重
				3).使用状态流转的方向性滤重，通常使用数据库的行级锁实现
			
		6. 缓存一致性模式
		    使用缓存来保证一致性的最佳实践。
			尽量使用分布式缓存(redis)，而不要使用本地缓存(session 和cookies)。
			写缓存时数据一定要完整，
            如果缓存数据的一部分有效 另一部分无效，则宁可在需要时回源数据库，也不要把部分数据放入缓存中。
			读的顺序是先读缓存，后读数据库，写的顺序要先写数据库，后写缓存。 

    微服务的交互模式：
		1.同步调用模式 				服务1调用服务2，等待返回处理结果
		2.接口异步调用模式			服务1调用服务2，即刻返回受理结果，受理成功，服务2异步处理，处理成功后再通知服务1
		3.消息队列异步处理模式		多应用于非核心链路上负载较高的处理环节中，井且服务的上游不关心下游的处理结果，下游也不需要向上游返回处理结果
		
		两状态同步接口：成功，失败
			使用方---服务1--服务2
			场景1，同步超时发生在使用方调用此同步接口的过程中，这时候是可以异步查询，重试请求的
			场景2，超时发生在内部服务1调用2过程中，使用快速失败原理，同时调用服务2的冲正处理，若成功则回退处理
			原因可能是内部的涉及上下游，超时两端都可能有问题，快速失败比较好
		
		三状态同步接口：成功，失败，处理中
			这里就是尽可能做补偿，两状态就是严格的成功失败
			主要涉及的就是查询接口，重试机制，幂等处理。必要时快速失败

    分布式调用链跟踪系统		
	在分布式系统中迅速定位问题时，够跟踪每个请求的调用链，树形结构进行展示调用信息
	TraceID，ParentSpanID，SpanID

1. 	服务化的调用端：
			1、获得可用服务地址列表
			2、确定目标的机器,即发现服务，采用的是完整的类名+版本号作为key去注册的服务列表中查找相应的服务
			3、建立连接，序列化，请求，接收结果，解析结果
			
		服务端：定位服务，一般基于名称和版本号定位，处理返回
		
		
		在服务化框架中的三个基础的属性，
				interfacename：通过接口生成代理对象，供本地调用
				version：区分的版本号，留个印象即可，可能是分机器调用吧
				group：分组调用，
		
		客户端调用服务端并不是每次都从服务注册中心查找地址，而是把地址缓存在客户端本地，
		当有变化时主动从服务中心发起通知，告诉客户端可用服务提供者的列表变化
2. 常用的异步远程通信方式：
			oneway，是一个单向的同时，
			callback，是一种被动的方式，callback的执行不是在原请求中，一般需要创建新线程来执行回调
			future，是一种主动控制超时、获取结果的方式，并且执行仍在原请求线程中

3. 注册中心的两个基本职能：
			1、聚合地址信息，形成服务地址信息列表
			2、生命周期感知，更新服务地址信息，通过长连接的心跳机制，实现上下线的感知
    
4. 手写一个rpc框架的实现：
    核心就是动态代理一个单独的接口，socket实现参数的传输的接收，同步阻塞等待获取
	可以对一个实现类实现动态代理，也可以只对一个单独的接口实现动态代理，
    这里rpc框架以及mapper使用的就是这种单独接口代理的方法

	rpc的demo中，创建sock连接的时候是阻塞的，在一次连接中，client写一个参数，server接收一个参数，直到接收完成返回
	其中使用new ObjectOutputStream(socket.getOutputStream()) write传参数和new ObjectInputStream(socket.getInputStream()) read 读信息，加入功能所以需要需要封装下
	实现一个注册的map,
    //final修饰的List同Map，都是可以改变内部的值，而不允许指向新的地址。
    private static final HashMap<String, Object> implRegistry = new HashMap<>();
    
5. 对比RPC和http的区别
	1.RPC要求服务提供方和服务调用方都需要使用相同的技术，要么都hessian，要么都dubbo，而http无需关注语言的实现，只需要遵循rest规范
	2.RPC主要是基于TCP/IP协议的，而HTTP服务主要是基于HTTP协议的，HTTP协议是在传输层协议TCP之上的，所以效率来看的话，RPC当然是要更胜一筹啦
	4.rpc框架，有服务治理，自带负载均衡(http需借助nginx)，传输效率rpc要高，使用接口开发
	TCP 是传输层协议，HTTP 是应用层协议，而传输层较应用层更加底层，在数据传输方面，越底层越快，因此，在一般情况下，TCP 一定比 HTTP 快

6.  几种常用的序列化方式，java,hessian,thrift，kryo,protobuf
	需要长连接获取高性能，选基于tcp的thrift和dubbo
	需要跨网段，跨防火墙，选基于http协议的hessian
	
	接口访问控制，接口安全，接口控制
		sign验签，基于时间戳防止重放攻击，
		限流 熔断
		RPC 主要指内部服务之间的调用
		ip限制
		
	微服务熔断器
	Hystrix 断路器机制
		会强迫其以后的多个调用快速失败，不再访问远程服务器，从而防止应用程序不断地尝试执行可能会失败的操作
		
		Hystrix Command 请求后端服务失败数量超过一定比例(默认 50%), 断路器会切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务。
		一旦后端服务不可用, 断路器会直接切断请求链, 避免发送大量无效请求影响系统吞吐量, 并且断路器有自我检测并恢复的能力
		
		控制同一个ip和设备id的请求频率，记录在redis中的，使用incr 和 expire实现

		返回给ajax的信息，关键信息，手机号等要*加密处理,敏感数据 userinfo一定要严格返回

7. 熔断，降级，限流
	降级多是大量请求且不能扩容进行的功能限制，可能针对某功能，也可能根据不同使用者。

8. hessian相关

	在boot 的配置中client 和server的配置文件尽量要分开，放一起会冲突
	
	之前netpay的hessian接口代理是remoting/aaa    发送到netpay匹配剩下的aaa即可。这是之前的servlet匹配的方式，boot后改良了

	//消费端
	@Bean
    public HessianProxyFactoryBean tradeManagerExtService(){
		HessianProxyFactoryBean factoryBean = new HessianProxyFactoryBean();
        factoryBean.setServiceUrl(payCoreUrl+"/remoting/tradeManagerExpService.htm");
        factoryBean.setServiceInterface(ITradeManagerService.class);
        factoryBean.setReadTimeout(30000);
        return factoryBean;
    }
	
	//服务端
	@Bean("/remoting/tradeManagerExpService.htm")
	public HessianServiceExporter exportTradeManagerHessian() {
		HessianServiceExporter exporter = new HessianServiceExporter();
		exporter.setService(tradeManagerService);
		exporter.setServiceInterface(ITradeManagerService.class);
		return exporter;
	}	

### dubbo相关
	   传输协议：TCP
    	   传输方式：NIO异步传输。非阻塞型的io，      
    	   序列化：Hessian二进制序列化
		   
	zookeeper挂机，提供者和消费者联系
	可以的，启动dubbo时，消费者会从zk拉取注册的生产者的地址接口等数据，缓存	在本地。每次调用时，按照本地存储的地址进行调用

1. <dubbo:protocol name="dubbo" port="20880"/> 使用dubbo协议在20880端口暴露服务
    提供者注册在zookeeper的地址是，192.168.6.85:20880，这样就是通过20880端口对外提供dubbo服务

2. 消费者启动获得提供者地址，并缓存本地后，consumer调用provider是直接invoke调用的，可以不依赖zookkeper
3. dubbo的三种运行方式：
        1、使用servlet容器运行(原先使用，现不推荐)
            缺点：浪费资源，内存、端口和管理
        2、自建main方法运行(忽略)
        3、dubbo框架提供的main方法运行 
            com.alibaba.dubbo.container.Main启动类

4. dubbo接口的设计原则
        1、接口的粒度大点，通常是包含完成业务作为一个接口，减少系统之间的交互，dubbo暂未提供分布式事务支持。
        2、不建议使用过于抽象的通用接口，如map query（map），不便于后期的维护
        3、接口都应定义版本号，为后续的不兼容升级提供可能（暂不理解）
        4、必要的接口参数校验
        5、provider上尽量多配置consumer端属性，优先server端，比如超时时间，重试次数，并发数量
5. dubbo的启动检查：
        1、<dubbo:consumer check="false">  关闭所有服务的启动时检查
        2、<dubbo:register check="false">	关闭注册中心启动时检查
        3、	dubbo.reference.check=false，强制改变所有reference的check值，就算配置中有声明，也会被覆盖。
            dubbo.consumer.check=false，是设置check的缺省值，如果配置中有显式的声明，如：<dubbo:reference check="true"/>，不会受影响。
            dubbo.registry.check=false，前面两个都是指订阅成功，但提供者列表是否为空是否报错，如果注册订阅失败时，也允许启动，需使用此选项，将在后台定时重试
6. dubbo直连
        消费端，在dubbo配置reference时候，指定接口url="dubbo：//localhost：20818" 绕过zookeeper直连提供者（开发测试用）
7. dubbo的负载均衡：
		4种策略
			1、随机
			2、轮询
			3、权重,按照活跃数少的优先调用，最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。
			4、hash一致：一致性hash，默认对第一个参数hash，相同参数请求发送统一提供者

8. 只有服务端才需要暴露相应的dubbo端口，客户端只要填写zookeeper地址即可，统一在注册中心找服务

9. jar 启动时候可以用java -jar app.jar --spring.profiles.active=dev  来指定运行的环境，目前采用的是pom中指定profile加载的属性文件

10. dubbo注解配置(暂不用)
        EnableDubboConfiguration 是使用dubbo注解的，spring的扫描注解正常配置,不影响
		http://jm.taobao.org/2018/06/13/Provider配置/    			dubbo配置
		http://dubbo.apache.org/zh-cn/blog/dubbo-annotation.html	官方文档
        
        添加扫描，@DubboComponentScan("com.xiaoyuer")
        注册服务
            spring.dubbo.application.name=controller-consumer
            spring.dubbo.registry.address=zookeeper://172.17.0.2:2181
            spring.dubbo.scan=com.gaoxi						扫描dubbo的注解，使用注解
            
            import com.alibaba.dubbo.config.annotation.Service;
            @Service(version = "1.0.0")
            @org.springframework.stereotype.Service

        发现服务
            @Reference(version = "1.0.0")
            spring.dubbo.application.name=controller-consumer # 本服务的名称
            spring.dubbo.registry.address=zookeeper://IP:2182 # zookeeper所在服务器的IP和端口号
            spring.dubbo.scan=com.gaoxi # 引用服务的路径

        代码配置(一般不用)
			@Configuration
			public class Dubboconfig
			    @Bean
                public RegistryConfig registryConfig() {
                    RegistryConfig registryConfig = new RegistryConfig();
                    registryConfig.setAddress(dubboProperties.getAddress());
                    registryConfig.setClient(dubboProperties.getClient());
                    return registryConfig;
                }
			<dependency>
				<groupId>org.apache.dubbo</groupId>
				<artifactId>dubbo-spring-boot-starter</artifactId>
				<version>2.7.3</version>
			</dependency>

11. dubbo的启动方式
	1、使用Servlet容器（Tomcat、Jetty等）运行
	缺点：增加复杂性（端口、管理） 浪费资源（内存）
	服务容器是一个standalone的启动程序，因为后台服务不需要 Tomcat 或 JBoss 等 Web 容器的功能，如果硬要用 Web 容器去加载服务提供方，增加复杂性，也浪费资源。

	2、自建main方法类来运行（Spring容器）  		
	缺点： Dobbo本身提供的高级特性(优雅停机等)没用上 自已编写启动类可能会有缺陷
	**********
	注意别和boot的main启动搞混了，这种一般就是ClassPathXmlApplicationContext 加载一个context，然后wait实现服务提供,一般测试用
	**********

	3、使用Dubbo框架提供的Main方法类来运行（Spring容器)
	优点：框架本身提供（com.alibaba.dubbo.container.Main） 可实现优雅关机（ShutdownHook）
	配置配在 java 命令的 -D 参数或者 dubbo.properties 中。其他的在dubbo.xml中配置即可，这两个可以结合下配置，目前项目中是xml主要配置
	服务容器只是一个简单的 Main 方法，并加载一个简单的 Spring 容器，用于暴露服务。
	dubbo.spring.config=classpath*:*.xml   这个相当于通过属性文件去导入了，目前项目是直接引入xml到容器中
	运用：生产上dubbo server可以用这种方式部署。
	搭配boot的时候：new SpringApplicationBuilder(XyeServiceCoreApplication.class).web(false).run(args);要以非web方式进行

	//boot 2.3.2
	public static void main(String[] args) {
		new SpringApplicationBuilder(XyeServiceCoreApplication.class).web(WebApplicationType.NONE).run(args);
		Main.main(args);
	}

    boot中继承dubbo
		dubbo-spring-boot-starter 使用这个才能在applicationi.properties中自动配置dubbo属性，否则只引入dubbo的maven，就需要添加dubbo.proerties配置


12. dubbo配置变化
	1.全XML的方式配置
	2.注册地址和协议等通过XML的方式配置,服务和消费可通过注解配置
	3.支持spring-boot-starter的方式，于是就有了dubbo-spring-boot-starter，通过Properties配置

	根据 DUBBO 官方文档，配置DUBBO有 4 种方式，分别是：
		1. XML 配置文件方式			推荐
		2. properties 配置文件方式	dubbo.properties
		3. annotation 配置方式		注解的方式 (忽略)
			<dubbo:annotation package="com.chanshuyi..." /> #扫描注解包路径，多个包逗号分隔，不填package，默认扫描当前applicationcontext中所有类
			@Reference(version="1.0.0")等
		4. API 配置方式			RegistryConfig、ServiceConfig等暂不介绍，(忽略)
		结合boot后，可以直接在application.properties中配置了

	DUBBO 在读取配置时，默认读取resources下的dubbo.properties 文件，但是会优先读取XML文件中的配置(两个都有，优先这个，忽略 properties 里的配置)

	一般用properties配置公共信息，比如可能一个应用要调用多个注册中心的服务，这时候它们的application.name、dubbo.protocol.name等都是相同的。其他情况，还是建议用 XML 配置方式。

13. dubbo线程模型
	dubbo的线程模型中有两个重要角色 ，ThreadPool（业务线程池）和Dispatcher(调度器，调度io线程处理)

	Dispatcher是dubbo中的调度器，用来决定操作是在IO中执行还是业务线程池执行
	对于Dubbo集群中的Provider角色，有IO线程池（默认无界）和业务处理线程池（默认200）两个线程池，所以当业务的并发比较高，或者某些业务处理变慢，
	业务线程池就很容易被“打满”，抛出“RejectedExecutionException: Thread pool is EXHAUSTED! ”异常。当然，前提是我们每给Provider的线程池配置等待Queue。

	Dispatcher，默认是all，所有消息都发送发线程池
	配置成message，只有请求响应消息派发到线程池，其它连接断开事件，心跳等消息，直接在IO线程上执行。

	threadpool 默认 fixed 固定大小线程池，启动时建立线程，不关闭，一直持有。(缺省)
		dubbo默认线程池大小200 和tomcat一样
		dubbo默认线程池是fixed
		
	协议的消息派发方式，用于指定线程 模型，比如：dubbo协议的all, direct, message, execution, connection等


14. Dubbo启动时qos-server can not bind localhost:22222
	问题原因：
	consumer启动时qos-server也是使用的默认的22222端口，但是这时候端口已经被provider给占用了，所以才会报错的。
	我们将simple-consumer.xml改成如下即可解决这个问题了。
	一般服务器上的单机运行，端口不会冲突。

15. dubbo同时消费者和提供者
	dubbo的服务者和消费者同时配置时，引入了dubbo-spring-boot-starter 2.7.7 会报application问题，单独引入 dubbo 2.7.7 就没问题

16. 




## 反射相关
    java反射：动态获取类中的信息
		class.getMethods()//获取所有的共有方法
		class.getDeclareMethods()//只获取本类中的方法，包括私有
		method.invoke(pbj,param)

    newInstance构造对象的时候，对象类必须要有一个无参构造
		
    Class.forName("com.test.mytest.ClassForName"); 后续可以再接着newinstance()创建一个实例
    ClassLoader.getSystemClassLoader().loadClass("com.test.mytest.ClassForName");
    
    Class.forName加载类是将类进了初始化，而ClassLoader的loadClass并没有对类进行初始化，只是把类加载到了虚拟机中。
    ClassLoader通过一个类的全限定名来获取描述此类的二进制字节流”，获取到二进制流后放到JVM中。class文件本来就是二进制文件,是字节码文件


    可以动态的执行方法和操作属性
            Method method=clazz.getdeclaredmethod("add",int.class,int.class);
            method.invike(this,1,1);
            
            Field field=clazz.getdeclaredField("name");
            field.set(this,"Test");


	Field field=clazz.getDeclareField("name");
	field.set(this,"Test")；
	如果属于类的静态属性，那么set和get方法的第一个参数就可直接设置为null；因为静态不需要实例，跟着类走的。
	
	方法，Method[] method=clazz.getDeclaredMethods();
	属性，Field[] field=clazz.getDeclaredFields();
	构造函数，Constructor[] constructor=clazz.getDeclaredConstructors();
	Class 对象的 newInstance()方法来创建该 Class 对象对应类的实例，但是这种方法要求该 Class 对象对应的类有默认的空构造器






## IO相关

Java IO 是一种装饰者模式，

1. io流 输入(读),输出(写)（相对内存而言  主要是内存和外围设备（打印机，硬盘等））
        流操作分为两种：字节流和字符流（字节流+编码表）
        电脑存储的原理：二进制--码表--信息
        硬盘的数据基本体现是文件

        字节流的抽象基类：操作对象是字节数组,无需编解码，无需缓冲刷新，但需要关闭
2. 获取系统的换行符 system.getProperty("line.separator")

3. reader：
        filereader流对象  可以读取单个字符和数组
        int ch = fr.read()  返回对应的asc码  最后一位再读取 返回-1 (作为流的结束标记)
        char[] a= new char[3]    默认 1024 千字节为单位 abcde#
        int length =  fr.read(a) 将读取指定长度的字符存储到数组中 重复读取会覆盖 返回读取的字符个数
        fw.writer（a，0，length ） a作为两个流之间的中转

       writer： 
        filewriter- 默认新建，存在覆盖   new filewriter("a.txt",true)有续写功能
        filewriter.write("数据写入"); 数据存储到临时存储缓冲区中， 
        filewriter.flush.刷新流的缓冲区，将数据直接写到目的地中
        filewriter.close 内部先flush，流对象最后一定要close
 
4. 操作流的一些规律：
        1、明确源和目的
            源：inputstream		reader
            目的：outputstream	writer
        2.明确数据是否是纯文本数据
            源：是reader	否 inputstream
            目的：是writer	否outputstream
        3、明确具体的设备
            源:
                硬盘：file
                键盘：system.in
                内存：数组
                网络：socket
            目的：
                硬盘：
                控制台：system.out
                内存：
                网络：
        4、是否需要其他的额外功能
            1、是否需要缓冲区： 加上buffer
            2、转换

5. 转换流的使用：
        字节流转换成字符流  	使用指定的charset读取字节并解码为字符
        inputStreamReader isr=new inputstreamreader(inputStream),然后可以作为缓冲流的处理对象
        字节流读取中文字2个字符，会读取两次，一次一个，字符流读一次，

        字符流转换成字节流	使用指定的charset将写入流中的字符编码成字节
        outputStreamWriter  子类filterWriter

        输入源（inputStream）-转换流成字符流-使用缓冲区读取-将读取到的写入到输出地（outPutStream的缓冲区）


        new bufferedreader（new inputstreamreader(system.in，码表)）
        new bufferedwriter（new outputstreamwriter(system.out，码表)）字符流
        
        转换流接收的目前都是字节流，如fileInputStream和fileOutputStream
        outputstreamwriter/inputstreamreader 可以指定编码写/读
        filterwriter/filereader是其子类，使用默认本机的编码
    
        转换流的使用场景：
            1、源或目的对应的设备是字节流，但操作的是文本数据
            2、操作文本涉及到指定编码，必须使用转换流

        字符流的缓冲区：提高读写的效率，一定要有缓冲对象
        bufferedRead：可以读取行readline（） 没有返回null
                先将源中数据读取到缓冲区，再从缓冲区中一个一个读取数据或整行读取
            
        bufferedWriter 特有newline（）
            BufferWriter bw = new BufferWriter（fw） 封装数组提高数组操作数据的效率
            bw.writer("aa");
            bw.flush();
            bw.close(); fw 同时关闭

        bytearrayinputsteam 和bytearrayoutputsteam

6. 序列化相关
        两个进程远程通信时，彼此可以发送各种类型的数据。数据都会以二进制序列的形式在网络上传送。所以需要序列化和反序列化。
        oos = new objectoutputstream(new fileoutputstream("a.txt")).writerObject(obj)  obj需实现序列化
        (person) oos.readerObject() 反序列化

        serializable
        存在唯一的序列化id，没有显示id，默认存在的
        流对象是可以直接读取对象的，ios.readObject(),序列化接受
        序列化过程中，有些属性不想传输，但是也不能static 可以使用tranient关键字	，static无法序列化传输
        网络模块是通过二进制流的方式进行传输的。
		通过序列化方式将内存对象转为二进制数据(二进制序列化后的数据传输效率高,适合系统之间传输),对象序列化需要实现Serializable接口

    序列化
		文本协议，直观、描述性强，容易理解，便于调试，缺点就是冗余数据较多，不适宜传输二进制文件（比如：图片等），解析复杂（需要进行字符串比较）；
		二进制协议，没有冗余字段，传输高效，方便解析（固定长度，并且可以直接比较字节），缺点就是定义的比较死，哪个位置有哪些东西，是什么意义是定义死的，场景单一。
		
		主流的、常用的序列化框架
		相对来说，二进制存储占用体积小。
			1.json序列化，适用与web与控制层的转换。,可视化强,文本化协议
			2.hessian序列化,HTTP协议的，二进制序列化，跨平台，内部会使用HessianSkeleton(HessianOutput和HessianInput)，将传输对象序列化，不需要手工序列化。
			3.java内置序列化，不支持跨平台，性能低，ObjectOutputStream和ObjectInputStream
			4.XStream，使用json居多，数据传输，xml序列化推荐，XStream,可视化强,文本化协议
			5.Thrift用的也不多。

		序列化的注意点
			1.父类实现serializable，所有子类都可以被序列化
			2.子类实现Serializable接口，父类没有，?中的属性不能序列化(不报错，数据会丢失)，但是子类中属性能正确序列化
			3.序列化的属性是对象，这个对象也必须实现序列化接口
			4.序列化过程中对应的序列化id不要变



7. 文件功能  apachecommonsIo的fileUtils操作工具类，写到本地服务器或者上云

8. 编码相关
	两端交互的时候，发送端指定编码，接收方使用固定编码接收即可	
   	response.setCharacterEncoding("UTF-8");//发送方固定统一编码utf8  然后接收方 的流处理使用统一编码解码即可

	UrlBase64字符编码相关
 ```
		String aa="我是革命一块砖";
        byte[] utf8s = UrlBase64.encode(aa.getBytes(Charset.defaultCharset()));
        String s = new String(utf8s, Charset.defaultCharset());
        byte[] decode = UrlBase64.decode(s.getBytes(Charset.defaultCharset()));
        String s1 = new String(decode, Charset.defaultCharset());
        System.out.println(s1);//最终s1是"我是革命一块砖"
 ```

		计算机中存储信息的最小单元是一个字节，即8bit们表示的字符范围是0~255个
		ascII,gbk,utf8等可以被看做字典，规定了转化的规则。通常不使用操作系统默认的编码，否则跨环境会出现乱码。

		string类的字符字节转换
			String str="海绵宝宝";
			byte[] bytes = str.getBytes("UTF-8");
			String strr = new String(bytes, "UTF-8");
		访问数据库中的编码，在url中指定即可


9. 接收参数
	Map<String, String[]> parameterMap = request.getParameterMap();
	也可 Enumeration<?> paramNames = request.getParameterNames()  遍历名称获取

10. 传输带有特殊字符的编码过就可以传后端
		[{"amount":"200","orderId":"1"},{"amount":"300","orderId":"2"}]
		%5B%7B%22amount%22%3A%22200%22%2C%22orderId%22%3A%221%22%7D%2C%7B%22amount%22%3A%22300%22%2C%22orderId%22%3A%222%22%7D%5D

11. 上传文件，
		单文件上传 MultipartFile
			1.既然是文件上传，form 中enctype="multipart/form-data"  method="post"
			2.commons-fileupload和commons-io这两个文件上传的依赖包
			3.配置commonsMultipartResolver
			<form action="/talents/importTalents"  method="post" enctype="multipart/form-data">
			选择文件 <input type="file" name="excel">
				<input type="text" name="eUserId" value="123">
				<input type="text" name="groupId" value="1">
				<button type="submit">提交</button>
			</form>

	SpringMVC 文件上传是通过MultipartResolver (Multipart解析器）处理的。
	对于 MultipartResolver 而言它只是个接口，它有两个实现类CommonsMultipartResolver 和 StandardServletMultipartResolver。前者依赖第三方包，一般用后者，可以xml配置，也可以java配置。
	controller中可以选择request间接接收，也可以选择MultipartFile直接接收
	MultipartFile是Spring MVC提供的类，而Part是ServletAPI 提供的类。
	表单中要设置为enctype=”multipart/forrn-data”


12. netty入门学习(忽略)
		Netty封装了JDK的NIO(nio，主要使用selector多路复用器来实现)
		netty是封装java socket nio的。 类似的功能是 apache的mina。
		建立在客户端和服务端之间的,服务端建立相应的规则，然后运行起来，等待客户端访问或者发送”消息“
		
		一个socket对应一个channel？
		服务端
			服务端用ServerBootstrap(netty服务端应用开发的入口)，有两个NioEventLoopGroup；
			有两种通道需要处理， 一种是ServerSocketChannel：用于处理用户连接的accept操作， 另一种是SocketChannel，表示对应客户端连接。
			分别用来用来接收进来的连接和用来处理已经被接收的连接，一旦‘boss’接收到连接，就会把连接信息注册到‘worker’上。
			
			.childHandler(),设置子通道的处理器，也就是SocketChannel的处理器，内部是实际业务开发的”主战场”，具体的业务实现。
			
			Channel都有且仅有一个ChannelPipeline与之对应，Channel包含了ChannelPipeline，ChannelPipeline内部包含了N个handler，每一个handler都是由一个线程去执行；
			channel.pipeline().addLast添加处理的handler
			
			b.option(),.childOption()分别配置ServerSocketChannel的选项 和 子通道也就是SocketChannel选项 
			
			ChannelFuture f = b.bind(port).sync();//绑定端口并启动去接收进来的连接
			f.channel().closeFuture().sync();//这里会一直等待，直到socket被关闭
			
		客户端
			client用Bootstrap，只有一个NioEventLoopGroup。只有一种channel，也就是SocketChannel
			
		网络传输的载体是byte，所有框架都是这个规定，JAVA的NIO提供了ByteBuffer，用来完成这项任务， Netty也提供了叫做ByteBuf
		通过合理的切分微服务变价可结局大缤纷分布式的事务问题
		
		IO多路复用技术通过把多个 IO 的阻塞复用到同一个 select 的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。与传统的多线程/多进程模型比，I/O 多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源。
		由于 Netty 采用了异步通信模式，一个 IO 线程可以并发处理 N 个客户端连接和读写操作，这从根本上解决了传统同步阻塞 IO 一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升

13. java.io操作类主要有4种(前两种属于数据格式，后两种属于传输方式)
			1.基于字节操作的I/O接口：inputSteam 和outputStream
		    2.基于字符操作的I/O接口：writer 和 Reader
			3.基于磁盘操作的I/O接口：file
			4.基于网络操作的I/O接口：socket
			
			
		磁盘和网络传输，最小的存储单元都是字节，不是字符。
		数据持久化或者网络传输都是以字节进行的。
			InputStreamReader是字节到字符的转化桥梁
			OutputStreamWriter完成字符到字节的编码过程
			
			reader类是java的I/O中读字符的父类，inputStream类是读字节的父类
			writer类对应是写字符的父类，outputStream类是写字节的父类
						
		网络优化的几个点
			1.减少网络交互的次数。能用缓存用缓存，能批量处理就批量处理
			2.减少网络传输数据量的大小。文件的话压缩后再传输
			3.尽量减少编码。尽量提前字符转字节。
			
		IO 是面向流的，NIO 是面向缓冲区的
			Selector 类是 NIO 的核心类，Selector 能够检测多个注册的通道上是否有事件发生，如果有事件发生，便获取事件然后针对每个事件进行相应的响应处理。
			在 Java NIO 中，是通过 selector.select()去查询每个通道是否有到达事件，如果没有事件，则一直阻塞在那里。
			Java NIO 实际上就是多路复用 IO。在多路复用 IO模型中，会有一个线程不断去轮询多个 socket 的状态，只有当 socket 真正有读写事件时，才真正调用实际的 IO 读写操作
			
			多路复用 IO 模式，通过一个线程就可以管理多个 socket，只有当socket 真正有读写事件发生才会占用资源来进行实际的读写操作。
			多路复用 IO 为何比非阻塞 IO 模型的效率高是因为在非阻塞 IO 中，不断地询问 socket 状态时通过用户线程去进行的，而在多路复用 IO 中，轮询每个 socket 状态是内核在进行的，这个效率要比用户线程要高的多。		
		
	网络传输，网络协议
		TCP/IP 由四个层次组成：网络接口层、网络层、传输层、应用层
		三次握手，四次断开
			TCP 建立连接要进行三次握手，而断开连接要进行四次。这是由于 TCP 的半关闭造成的。因为 TCP 连接是全双工的(即数据可在两个方向上同时传递)所以进行关闭时每个方向上都要单独进行关闭。这个单方向的关闭就叫半关闭。当一方完成它的数据发送任务，就发送一个 FIN 来向另一方通告将要终止这个方向的连接。
			
		HTTPS
		HTTPS是以安全为目标的HTTP通道，是HTTP的安全版。即HTTP下加入SSL层，HTTPS的安全基础是SSL。其所用的端口号是 443。 
		简单过程是，建立通信后，服务端发送证书给客户端，客户端用公钥加密传输，服务端私钥解密。
		建立连接获取证书
		1） SSL 客户端通过 TCP 和服务器建立连接之后（443 端口），并且在一般的 tcp 连接协商（握手）过程中请求证书。即客户端发出一个消息给服务器，这个消息里面包含了自己可实现的算法列表和其它一些需要的消息，SSL 的服务器端会回应一个数据包，这里面确定了这次通信所需要的算法，然后服务器向客户端返回证书。（证书里面包含了服务器信息：域名。申请证书的公司，公共秘钥）。
		证书验证
		2） Client 在收到服务器返回的证书后，判断签发这个证书的公共签发机构，并使用这个机构的公共秘钥确认签名是否有效，客户端还会确保证书中列出的域名就是它正在连接的域名。数据加密和传输
		3） 如果确认证书有效，那么生成对称秘钥并使用服务器的公共秘钥进行加密。然后发送给服务器，服务器使用它的私钥对它进行解密，这样两台计算机可以开始进行对称加密进行通信。
	




## linux相关
1. 常用命令
	more 可以分页查看文本，不常用
    cp 文件 文件路径   复制文件
	cp -r 文件夹 路径  复制文件夹内容到指定路径下,递归复制
	cp						cp -r  递归复制，是相当于windows中的复制+粘贴，而mv相当于windows中的剪切+粘贴，也就是移动文件

    mkdir 目录名    创建一个目录, -p 递归创建(即使上级目录不存在，会按目录层级自动创建目录)
    rm -rf * 强制递归删除
    chmod +x *.sh 为sh文件增加可执行权限；
	chmod +x 文件  给出文件的可执行权限,支持通配
    vim 
        /，查询，
        N或n，是向前向后搜索字符串  
        ESC，q退出；q!强制退出；:wq 保存并退出  
    tar zxvf zhcon.tar.gz
		z代表gzip的压缩包；x代表解压；v代表显示过程信息；f代表后面接的是文件
    yum install 包名（支持*） ：手动选择y or n  全自动就 -y
    ps -ef | grep java 显示所用运行中java进程的状态
    kill -9 java pid 停止特定java进程

	curl 					页面请求返回	
	cat 					是一个文本文件查看和连接工具。查看一个文件的内容,cat后面直接接文件名。


	grep  aa xye.log		字符串查找	找出xye.log中的aa内容
	find  -name xye.log  	文件查找 find  -name "*.log"				查询速度慢
	which   				查看系统命令是否存在，以及执行的到底是哪一个位置的命令。
	whereis 				只能用于可执行文件的搜索，只能搜索二进制文件，说明文件，源代码文件。比which范围广

	:set nu					vi命令下显示行号	


 2. ./当前目录 ../上级目录 /根路径

	curl "http://www.baidu.com"  如果这里的URL指向的是一个文件或者一幅图都可以直接下载到本地  get
	curl -d "username=user1&password=123" "www.test.com/login"	post
		
	curl模拟的访问请求一般直接在控制台显示，适用结果内容比较少
	而wget则把结果保存为一个文件。适用结果比较多
	wget是个专职的下载利器，简单，专一，极致；而curl可以下载，但是长项不在于下载，而在于模拟提交web数据，POST/GET请求，调试网页等。

 3. inxus 中的文件路径一般是/ windows中一般是\\   
 4. vi和vim	   				
 	都是Linux中的编辑器，不同的是vim比较高级，可以视为vi的升级版本。vi使用于文本编辑，但是vim更适用于coding。			
	在vi编辑器中，按u只能撤消上次命令，而在vim里可以无限制的撤消。

 5. linux中的系统发布，优雅停机
		应用启动后，小校验从而完成服务器上的应用发布。(一般通过检测脚本或者页面。有返回结果即可。)
		优雅停机，在负载均衡上做文章，关闭应用前，把应用从负载均衡中心上移去，然后再优雅关闭应用（结束当前所有请求后关闭），然后进行新应用的启动及检查，检查通过后再把应用加到负载均衡上，并对外提供应用。
		灰度发布，指针对新应用，在用户体验上完全感知不到的更新，可能持续时间长，重要的状态需要记录。

 6. linux权限，文件权限，用户权限
			chmod [-cfvR] [--help] [--version] mode file
			mode : 权限设定字串，格式如下 : [ugoa...][[+-=][rwxX]...][,...]
			--help : 显示辅助说明 
			--version : 显示版本
			-c : 若该档案权限确实已经更改，才显示其更改动作 
			-f : 若该档案权限无法被更改也不要显示错误讯息 
			-v : 显示权限变更的详细资料 
			-R : 对目前目录下的所有档案与子目录进行相同的权限变更(即以递回的方式逐个变更) 
	
		Linux的文件基本上分为三个属性：可读（r），可写（w），可执行（x）。
		类型后面紧接着的3*3个字符分3组，各指示此文件的读、写、执行权限，对于owner、group、others而言

		| d | rwx | r-x | r-x |
		|文件类型 | 所有者权限|用户组权限 |其他用户权限|

		drwxr-xr-x   2 root root 48 2013-11-27 16:34 test/
		第一个栏位，表示文件的属性，
		第二个栏位，表示文件个数。
		第三个栏位，表示该文件或目录的拥有者
		第四个栏位，表示所属的组（group），每一个使用者都可以拥有一个以上的组，不过大部分的使用者应该都只属于一个组
		第五栏位，表示文件大小
		第六个栏位，表示最后一次修改时间
		第七个栏位，表示文件名

		（以-rwxr-xr-x为例）：　　  
		rwx(Owner)r-x(Group)r-x(Other)　
		这个例子表示的权限是：使用者自己可读，可写，可执行；同一组的用户可读，不可写，可执行；其它用户可读，不可写，可执行。
		另外，有一些程序属性的执行部分不是X,而是S,这表示执行这个程序的使用者，临时可以有和拥有者一样权力的身份来执行该程序。

		egj是yunwei创建，egjjjj是开发创建，在kaifa用户下查看权限，yunwei和kaifa都是同一个组的
		哪个用户创建就属于哪个owner
		drwxrwxr-x.   3 prd_yunwei prd_yunwei  4096 May 12 10:48 egj		yunwei建目录，所有者属于运维，同组有写操作
		drwxr-xr-x.   2 kaifa      prd_yunwei  4096 May 12 10:59 egjjjj		kaifa建目录，所有者属于kaifa，yunwei用户不能写操作(因为同组没有写操作)

		创建权限
		who 
		u 表示“用户（user）”，即文件或目录的所有者。
		g 表示“同组（group）用户”，即与文件属主有相同组ID的所有用户。
		o 表示“其他（others）用户”。
		a 表示“所有（all）用户”。它是系统默认值。

		+ 添加某个权限。
		– 取消某个权限。
		= 赋予给定权限并取消其他所有权限（如果有的话）。

		chmod ［who］ ［+ | – | =］ ［mode］ 文件名     有对应的数字简化版
		例如：chmod g+r，o+r example使同组和其他用户对文件example 有读权限
		******在配置文件写权限的时候，必须要拥有上层目录的读权限******
		
		groups 查看当前用户所属组
		chmod +rwx file	给file的所有用户增加读写执行权限     	不写用户就默认所有
		
		setfacl命令可以用来细分linux下的文件权限。(忽略)
			chmod命令可以把文件权限分为u,g,o三个组，而setfacl可以对每一个文件或目录设置更精确的文件权限。 比较常用的用法如下：
			setfacl –m u:apache:rwx  file 设置apache用户对file文件的rwx权限 
			setfacl –m g:market:rwx  file  设置market用户组对file文件的rwx权限 
			setfacl –x g:market file   删除market组对file文件的所有权限 
			getfacl  file  查看file文件的权限
						
			setfacl -R -m  g:kaifa:r-x /usr/local/logs   // 赋权给 kaifa 查看日志   -R 递归目录    g: 用户组  u:用户    // 注意给文件w权限时须要给上级文件夹w权限，否则文件有w权限也无法写删
			getfacl  /usr/local/logs     // 查看目录权限 
	
7. linux网络配置
		默认使用nat连接，主机ping不同虚拟机是因为，v8虚拟网卡没有开启，
		虚拟机需要开放防火墙中的端口，才能对外提供访问，centos7需要yum install iptables-services后才能重启防火墙
			vi /etc/sysconfig/iptables
			systemctl restart iptables
			
		如果发现虚拟机的网卡没有ip地址，/etc/sysconfig/network-scripts/ifcfg-eth0(确认ONBOOT=yes),其中eth0是设备名，实际可能不一样
		ONBOOT是指明在系统启动时是否激活网卡，只有在激活状态的网卡才能去连接网络，进行网络通讯	
			
			
8. linux和windows文件传输
		1.使用winscp工具
		2.安装xftp后自动集成到xshell的插件中
		3.	rz和sz
			sz  下载(命令格式：  sz filename   下载文件filename || sz file1 file2   下载多个文件 || sz dir/*　　　下载dir目录下所有文件)	　
			rz 上传	(命令格式： 	rz)
			注意：
			1.如果机器上没有安装过 lrzsz 安装包，则无法使用rz和sz命令。
			　可使用yum命令安装：yum install -y lrzsz  或者下载源码进行安装。下载地址：https://ohse.de/uwe/software/lrzsz.html	
9. 安装虚拟机
		CentOS 7提供了三种ISO镜像文件：
			DVD ISO 标准安装版，桌面版
			Everything ISO 标准安装版的补充，增加了大量的应用软件
			Minimal ISO 精简版，自带的应用软件最少，生产环境推荐使用			#额 精简版啥都没有，好多需要自己装，只有最小安装(基本功能)
			
		centos7			
		安装虚拟机 https://www.bilibili.com/read/cv7593000
		安装jdk，1.手动安装（下载.tar.gz） 2.yum安装(下载rpm包)
		
		service命令的功能基本都被systemct取代。直接使用systemctl命令即可
		systemctl命令是系统服务管理器指令，它实际上将 service 和 chkconfig 这两个命令组合到一起。
		systemctl是RHEL 7 的服务管理工具中主要的工具，它融合之前service和chkconfig的功能于一体。可以使用它永久性或只在当前会话中启用/禁用服务。
		
		解决CentOS安装VM Tools出现在客户机中装载CD驱动器启动终端，使用tar解压缩安装程序，然后执行vmware-insall.pl安装VMware Tools的问题
			1.进入文件界面，找到左侧“设备”下面的名为“VM Tools“ 的驱动器，进入该CD驱动器中，找到文件名末尾为.tar.gz的文件。
			2.将末尾为.tar.gz的文件拷贝到其他任意的文件夹，我直接拷贝到了桌面上，然后将该文件解压，解压方法有两种，随便选下面中的一种：
			3.直接右键点击该文件，选择“提取到此处”选项。
			4.进入命令行界面，使用tar 指令解压，解压后文件名为vmware-tools-distrib。
			5.进入命令行界面，cd到vmware-tools-distrib或者直接在文件夹处打开终端；然后输入指令： sudo ./vmware-install.pl；
			6.之后输入密码就可以下载VMware Tools了。下载中会出现很多询问的问题，只需要不断按回车以选择默认值即可。
			7.安装完成后的界面如下图所示，出现了红圈中的enjoy字样，就说明安装成功   Enjoy, --the VMware team
		
		
			centos7 安装jdk
				/usr/java 下不能直接复制，要从其他文件中copy过去
				1.删除自带的openjdk
					rpm -qa|grep java			查出列表
					rpm -e --nodeps xxx			依次卸载所有跟openjdk相关的包
					
				2.安装jdk即可，随便是手动解压还是rpm安装
					vi /etc/profile  最下方添加环境变量，保存退出。
					有时需要让 profile 起作用，需要执行 source /etc/profile命令生效
					
					export JAVA_HOME=/usr/java/jdk1.8.0_291-amd64
					export JAVA_BIN=/usr/java/jdk1.8.0_291-amd64/bin
					export PATH=$PATH:$JAVA_HOME/bin
					export CLASSPATH=:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
					export JAVA_HOME JAVA_BIN PATH CLASSPATH
					
				3.java -version 检查版本

			服务使用方法
				gpm 是linux中的光标复制功能
			启动gpm服务：
			service gpm start

			运行systemctl enable gpm.servicere 添加到后台服务。
			
			systemctl start [服务文件名]
			systemctl restart [服务文件名]
			systemctl stop [服务文件名]
			systemctl status [服务文件名]
			
			设置开机启动
			systemctl enable [服务文件名]
			systemctl disable [服务文件名]			
			
			
			systemctl命令兼容了service，替代service和chkconfig两个命令。
			**centos7后都是用systemctl命令**
			systemctl start docker.service
			systemctl stop docker.service
			服务名不带后缀默认就是.service单元，其他的单元比如.mount .sockets .device .target都必须指定类型

10. yum与rpm，建议使用yum安装rpm包
	Yum是rpm的前端程序，主要目的是设计用来自动解决rpm的依赖关系，
	rpm 只能安装已经下载到本地机器上的rpm 包. yum能在线下载并安装rpm包,能更新系统,且还能自动处理包与包之间的依赖问题,这个是rpm 工具所不具备的		
	yum与rpm的区别：rpm适用于所有环境，而yum要搭建本地yum源才可以使用！yum是上层管理工具，自动解决依赖性，而rpm是底层管理工具。yum 基于 rpm，增加了自动解决依赖关系的方案	
	yum [options] [command] [package …]
	[options] 选项包括-h（帮助），-y（当安装过程提示选择全部为"yes"），-q（不显示安装的过程）
	
11. shell脚本
		Bash 也是大多数Linux系统默认的Shell。
		在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 #!/bin/sh，它同样也可以改为 #!/bin/bash。
		#!/bin/bash					这里#! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序。
		echo 命令用于向窗口输出文本，还有个类似的功能printf。

		运行 Shell 脚本有两种方法：
			1、作为可执行程序，常用方法
				chmod +x ./test.sh  #使脚本具有执行权限
				./test.sh  #执行脚本

			2、作为解释器参数
				/bin/sh test.sh
				这种方式运行的脚本，不需要在第一行指定解释器信息，写了也没用。
			
			执行当前目录下的sh脚本，一定要写成 ./test.sh，而不是 test.sh，运行其它二进制的程序也一样，
			直接写 test.sh，linux 系统会去 PATH 里寻找有没有叫 test.sh 的，而只有 /bin, /sbin, /usr/bin，/usr/sbin 等在 PATH 里，你的当前目录通常不在 PATH 里，所以写成 test.sh 是会找不到命令的，要用 ./test.sh 告诉系统说，就在当前目录找。
			
			以 # 开头的行就是注释，会被解释器忽略。
			
		shell变量
			your_name="runoob.com"		变量赋值，字符串可用单引号，也可用双引号，也可以不用引号。()
										单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；
										单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用
										双引号里可以有变量,双引号里可以出现转义字符
			echo ${your_name}         	#输出展示变量   可省略{}，但是建议加上
			readonly myUrl				设置为只读
			unset variable_name 		删除变量，删除后不能再用，只读不能删
			echo ${#variable_name} 		输出长度
			数组名=(值1 值2 ... 值n)	数组
			
		shell运算
			val=`expr 2 + 2`
			echo "两数之和为 : $val"
			表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2，这与我们熟悉的大多数编程语言不一样。
			完整的表达式要被 ` ` 包含，注意这个字符不是常用的单引号，在 Esc 键下边。
			
			val=`expr $a + $b`
			echo "a + b : $val"
			
			代码中的 [] 执行基本的算数运算，如：
			result=$[a+b] # 注意等号两边不能有空格
			echo "result 为： $result"
				
			echo -n 不换行输出	
			
			nohup(no hang up,不挂起)，用于在系统后台不挂断地运行命令，退出终端不会影响程序的运行。
				nohup 命令，在默认情况下(非重定向时)，会输出一个名叫 nohup.out 的文件到当前目录下，如果当前目录的 nohup.out文件不可写，输出重定向到 $HOME/nohup.out 文件中。
				语法格式： nohup Command [ Arg … ] [　& ]
				
				在后台执行 root 目录下的 runoob.sh 脚本，并重定向输入到 runoob.log 文件
					nohup /root/runoob.sh > runoob.log 2>&1 &
					
					如果是 > /dev/null 2>&1 &   
						> 代表重定向到哪里
						/dev/null 代表空设备文件，也就是不输出任何信息到终端，说白了就是不显示任何信息
						& 表示等同于的意思，2>&1，表示2的输出重定向等同于1
						标准错误输出重定向等同于标准输出，输出到同一文件中

					2>&1 解释：
					将标准错误 2 重定向到标准输出 &1 ，标准输出 &1 再被重定向输入到 runoob.log 文件中。
					0 – stdin(standard input，标准输入)
					1 – stdout(standard output，标准输出)，">/dev/null"等同于"1>/dev/null",默认是1
					2 – stderr(standard error，标准错误输出)
					
					JAR_HOME_DIR=/usr/local/java_project/webapps/
					APP_NAME=e-manager-pay.jar
					nohup java -Xms512m -Xmx512m -XX:PermSize=256M -XX:MaxPermSize=256M -jar $JAR_HOME_DIR$APP_NAME > /dev/null 2>&1 &
					这里实际grep的名字实际显示出来就是e-manager-pay.jar
					
			关系运算符
				-eq	等于则为真
				-ne	不等于则为真
				-gt	大于则为真
				-ge	大于等于则为真
				-lt	小于则为真
				-le	小于等于则为真
				
			文件运算符
				-b file	检测文件是否是块设备文件，如果是，则返回 true。	[ -b $file ] 返回 false。
				-c file	检测文件是否是字符设备文件，如果是，则返回 true。	[ -c $file ] 返回 false。
				-d file	检测文件是否是目录，如果是，则返回 true。	[ -d $file ] 返回 false。
				-f file	检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。	[ -f $file ] 返回 true。
				-g file	检测文件是否设置了 SGID 位，如果是，则返回 true。	[ -g $file ] 返回 false。
				-k file	检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。	[ -k $file ] 返回 false。
				-p file	检测文件是否是有名管道，如果是，则返回 true。	[ -p $file ] 返回 false。
				-u file	检测文件是否设置了 SUID 位，如果是，则返回 true。	[ -u $file ] 返回 false。
				-r file	检测文件是否可读，如果是，则返回 true。	[ -r $file ] 返回 true。
				-w file	检测文件是否可写，如果是，则返回 true。	[ -w $file ] 返回 true。
				-x file	检测文件是否可执行，如果是，则返回 true。	[ -x $file ] 返回 true。
				-s file	检测文件是否为空（文件大小是否大于0），不为空返回 true。	[ -s $file ] 返回 true。
				-e file	检测文件（包括目录）是否存在，如果是，则返回 true。	[ -e $file ] 返回 true。
				其他检查符：
				
			整数变量表达式
				if [ int1 -eq int2 ]    如果int1等于int2   
				if [ int1 -ne int2 ]    如果不等于    
				if [ int1 -ge int2 ]       如果>=
				if [ int1 -gt int2 ]       如果>
				if [ int1 -le int2 ]       如果<=
				if [ int1 -lt int2 ]       如果<	
			 
			字符串变量表达式
				If  [ $a = $b ]                 如果string1等于string2字符串允许使用赋值号做等号
				if  [ $string1 !=  $string2 ]   如果string1不等于string2       
				if  [ -n $string  ]             如果string 非空(非0），返回0(true)  
				if  [ -z $string  ]             如果string 为空
				if  [ $sting ]                  如果string 非空，返回0 (和-n类似)    
				
			变量符号
				$0	当前脚本的文件名
				$n	传递给脚本或函数的参数。n 是一个数字，表示第几个参数。例如，第一个参数是$1，第二个参数是$2。

				$#	传递给脚本或函数的参数个数。
				$*	传递给脚本或函数的所有参数。
				$@	传递给脚本或函数的所有参数。
				　　$* 和 $@ 的区别
				　　	相同点：都是引用所有参数，不被双引号" “包含时，都以”$1" “$2"…"$n” 的形式输出所有参数，
						被双引号" “包含时，”$*" 会将所有的参数作为一个整体；"@" 会将各个参数分开，以换行形式输出所有参数。
						比如，假设在脚本运行时写了三个参数 1、2、3，，则"*"等价于"1 2 3"(传递了一个参数)，而 "@" 等价于 "1" "2" "3"(传递了三个参数)
				$?	上个命令的退出状态，或函数的返回值。
				$$	当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID

			-- if else
				if condition1
				then
					command1
				elif condition2 
				then 
					command2
				else
					commandN
				fi
			-- for循环
				for var in item1 item2 ... itemN; do command1; command2… done;
			-- whlie	
				while condition
				do
					command
				done
				
			-- case
			case ... esac
			case $aNum in
				1)  echo '你选择了 1'
				;;
				*)  echo '你没有输入 1 到 4 之间的数字'
				;;
			esac

			#使用 . 号来引用test1.sh 文件
			. ./test1.sh

			# 或者使用以下包含文件代码
			# source ./test1.sh

			echo "菜鸟教程官网地址：$url"	
				
		当前目录执行，不加找不到(不在执行程序默认的搜索路径之列)
		./a.sh会用你脚本中第一行的那个#!XXX的shell来执行语句,而sh a.sh则是用sh来执行语句
		sh或是执行脚本，或是切换到sh这个bash里，默认的shell是bash	
		执行脚本的时候是用sh + 脚本名的方式来执行，其实，大部分的时候，简单脚本只要权限设置正确，可以直接执行，不需要sh命令的
				
		以sh执行，那么，不必设定执行权限，也不用写shell文件中的第一行（指定bash路径）。因为方法三 是将hello.sh作为参数传给sh(bash)命令来执行的。这时不是hello.sh自己来执行，而是被人家调用执行。		
				
		sh带参数执行
			/usr/local/java_project/bin/java_project.sh stop        #多个参数空格分隔
			
		1、/bin/sh是/bin/bash的软连接，在一般的linux系统当中，使用sh调用执行脚本相当于打开了bash的POSIX标准模式，也就是说 /bin/sh 相当于 /bin/bash --posix
		2、/bin/sh执行过程中，若出现命令执行失败，则会停止执行；/bin/bash执行过程中，若命令执行失败，仍然会继续执行
		
		#!/bin/sh是#!/bin/bash的缩减版
				
		awk是一个强大的文本分析工具，简单来说awk就是把文件逐行读入，（空格，制表符）为默认分隔符将每行切片，切开的部分再进行各种分析处理		
				
		pid =`ps -ef| grep tomcat | grep -v grep | awk '{print $2}'`			#这里命令中的反引号的作用就是先执行命令然后把结果返回作为参数
		grep -v  			这里是查找，排除的意思
		awk '{print $2}'	就是截取第二个字段输出
		
		linux 
			命令中的 |
				利用Linux所提供的管道符“|”将两个命令隔开，管道符左边命令的输出就会作为管道符右边命令的输入。依次向后传递。
			命令> 和 >>
					> 表示stdout标准输出信息重定向输出，覆盖写。
						echo 'World' > test.txt
					>> 表示内容追加写。
						echo 'World' >> test.txt
			命令&& 
				command1 && command2, 即指令1执行成功, 才会执行指令2, 常用来连贯执行
				cd dockertest/ && vi Dockerfile 
			命令|| 
				command1 || command2 指令1执行失败, 才会执行指令2, 
				例如 cat filename || echo “fail”
				
		实际自己测试的shell脚本
			简单的kill进程，然后重启
				#!/bin/bash
				tomcatpid=`ps -ef| grep tomcat | grep -v grep | awk '{print $2}'`
				echo "now pid is ${tomcatpid},trying to stop"
				kill -9 ${tomcatpid}
				echo "trying to reload"
				sh /home/zhanjun/test/tomcats/apache-tomcat-01/bin/startup.sh
				tailf -f /home/zhanjun/test/tomcats/apache-tomcat-01/logs/catalina.out



## Redis
1. redis集群分布式节点一般一主一备，当任意master挂了没有备份或半数以上的master挂了则集群不可用
2. redis的两种持久化方案：
    * snapshotting 快照  
        默认的存储方式，默认写入dump.rdb的二进制文件中，可以配置redis在n秒内如果超过m个key被修改过就自动做快照
    * append-only file(aof)  
        使用aof时候redis会将每一次的函数都追加到文件中，当redis重启时会重新执行文件中的保存的写命令在内存中

3. TTL KEY_NAME Redis TTL 命令以秒为单位返回 key 的剩余过期时间。
4. redis是单线程，不会设计多个线程并发的问题


## 单点登录方案
    1. 单点登录的主要实现方案：
        1、服务接口的开发
        2、在分布式环境中使用redis实现session共享（缓存唯一token和对应的用户信息）
        3、使用cookie在多个系统中共享。（存放token信息）
        4、拦截器的使用方法（访问校验cookie中的token是否存在或过期）

## 	nginx相关

1. nginx配置以下三种方式：1.ip	2.端口	3)域名 	
	一个域名只能绑定一个ip，一个ip可以被多个域名绑定。通常ip地址是和dns服务器（根据域名换ip地址）绑定一起的，
	
2. 网址解析步骤
	www.baidu.com-->dns服务器---->取得对应的ip地址---->访问百度的服务器,默认的是80端口
	在host文件中，如果配置了ip对应的域名，就会跳过dns解析，进行访问
	
3. nginx请求步骤
	客户端均衡--->nginx--->tomcat 请求经过nginx转发，由tomcat处理，叫反向代理，
	多台tomcat就叫做负载均衡（仅对httpserver如tomcat有效）

4. nginx配置负载均衡：http节点下，添加upstream节点。
    ```
		upstream linuxidc { 
     		 server 10.0.6.108:7080; 			#一个server就是一个虚拟主机
      		 server 10.0.0.85:8980; 
		}
  		2.  将server节点下的location节点中的proxy_pass配置为：http:// + upstream名			称，即“http://linuxidc”.默认的分配策略是轮询
    ```
	高可用：解决高可用的方案就是：添加冗余（备用一主一备）一般用keepalived(集群管理中实现高可用，防止单点故障),不断检查主nginx是否正常，异常就启用备用nginx，主正常，在切换回去。

    一般大公司是可以输入ip地址访问的，但是一些小公司可能运行在同一ip的不同虚拟机上，还是要域名访问才能精确定位

5. nginx配置
	******************************
	https://m.yu.com   和  https://192.168.6.222:8083  存的cookie是不一样的，
	https://m.yu.com/  nginx 转发后是8443 ，然后登录中的两个域名不一样    RedirectFilter 中 loginUrl
	pre 和 sit  手机有没有路径转发,有集群和转发
	域名转发ip相关
	nginx
	proxy_set_header Host $proxy_host;
	配置。当Host设置为$http_host时，则不改变请求头的值，所以当要转发到bbb.example.com的时候，请求头还是aaa.example.com的Host信息；
	当Host设置为$proxy_host时，则会重新设置请求头为bbb.example.com的Host信息。
	
	设置 http 请求 header 传给后端服务器节点，如：可实现让代理后端的服务器节点获取访问客户端的真实ip
	
	******************************		
	windows下nginx用nginx.exe -s stop关
	转发的两台tomcat需要session共享才能相互访问，不然登录会丢失session
	
	普通的负载均衡软件，如 LVS，其实现的功能只是对请求数据包的转发、传递，从负载均衡下的节点服务器来看，接收到的请求还是来自访问负载均衡器的客户端的真实用户；
	而反向代理就不一样了，反向代理服务器在接收访问用户请求后，会代理用户 重新发起请求代理下的节点服务器，最后把数据返回给客户端用户。在节点服务器看来，访问的节点服务器的客户端用户就是反向代理服务器，而非真实的网站访问用户
	ngx_http_upstream_module是负载均衡模块，可以实现网站的负载均衡功能即节点的健康检查，upstream 模块允许 Nginx 定义一组或多组节点服务器组，使用时可通过 proxy_pass 代理方式把网站的请求发送到事先定义好的对应 Upstream 组 的名字上。
	proxy_pass 指令属于ngx_http_proxy_module模块，此模块可以将请求转发到另一台服务器，在实际的反向代理工作中，会通过 location 功能匹配指定的URI，然后把接收到服务匹配URI的请求通过proyx_pass抛给定义好的 upstream 节点池。
	
	
	nginx中存放静态资源，实现静态资源分离
	localhost:80/image/ 时会访问本机的/usr/local/myImage/image/ 
	location /image/ {
				root   /usr/local/myImage/;
				autoindex on;
			}
	server {
		   listen 88;
		   server_name localhost;
		   root     /home/ubuntu/static/;
	}

	#localhost:80/image/1.jpg
	#也可以移除掉root 和 autoindex 配置，直接在html目录下的image目录下新建一张图片1.jpg。
	http://localhost:8087/image/zxnew.png  实际访问成功

	server {
			listen       8087;
			server_name  localhost;
			location / {
				root   html;											
				index  index.html index.htm;
			}
			location /image/ {
				root   C:/Users/xiaoyuer/Desktop/图片/;
				autoindex on;
			}
		}

6. 当用户访问网站时候，第一个交互的组件是dns，将域名解析成ip
7. 域名解析ip(180.97.15.66)->接收66,防火墙打出到250->转到192.168.8.250(keepalived配置的虚拟ip)内部服务器,指定跳到31->31nginx-机器，转发到相应的服务器。

8. 支付都是使用的443端口(可以nginx中转到支付的80，但是原请求都是s端口)


## maven相关
1. 这里的 fork 设置为 true，实际上是会在 maven 编译的时候新创建一个虚拟机执行。这个新创建 JVM 就是这里的 fork。
    它速度会稍慢一些，但是隔离性非常好。消耗更多的资源，更加耗性能
    maven 本身是运行在 jvm 之上的，编译项目的 jdk 可以和运行 maven 的 jdk 不同。

    困扰好几天的dubbo的install问题，终于在StackOverflow 上找到了答案，<fork>false</fork> 很关键。很关键
```
    <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-compiler-plugin</artifactId>
        <configuration>
            <fork>false</fork>
            <source>${java_source_version}</source>
            <target>${java_target_version}</target>
            <encoding>${file_encoding}</encoding>
        </configuration>
    </plugin>
```			
			
默认情况下 ，fork 是 false，Maven 使用 运行自己的 jdk （maven 是需要依赖 jdk 存在的） 来进行 compiler ，	
如果不想使用这个默认的 jvm，就可以通过 fork 来实现				
			
这个错是因为maven所用的jdk版本号过低，项目中的某些类需要更高的JDK版本。
通过配置pom.xml，添加如下配置（注意，fork一定要为true）可以设置maven使用的jdk	

2.``` <dependencyManagement>```	
    父pom工程中集中定义jar或者maven插件的版本信息
    只是对版本进行管理，不会实际引入jar  
    优先以子工程中的dependency声明version为准，子没有配置，默认继承父pom中的dependencyManagement定义的version
			
```
<dependency>  
            <groupId>org.myorg.myapp</groupId>  
            <artifactId>app-util</artifactId>  
            <version>${project.version}</version>  
        </dependency>  
```
    其中${project.version} 是一个属性引用，指向了POM的project/version的值，也就是这个POM对应的version。
    由于app-dao的version继承于app-parent，因此它的值就是1.0-SNAPSHOT

3. repository 一般有中央仓库，公共仓库，私有仓库以及本地仓库

4. 
 ```
    <parent>
	<relativePath>作用
	<!-- 父项目的pom.xml文件的相对路径。相对路径允许你选择一个不同的路径。默认值是../pom.xml。
		Maven首先在构建当前项目的地方寻找父项目的pom，其次在文件系统的这个位置（relativePath位置），然后在本地仓库，最后在远程仓库寻找父项目的pom。 -->
	<relativePath />
 ```

5. runtime 是运行的意思。指的是直接在运行时所需要的包，而非在编译时等时候需要的包。

6. spring-data-redis在xye-project-util中是1.8.3版本，支付中已经排除了引用，但还是方法找不到，
			这里的原因是1.8.3版本是void delete() 编译好了,最终使用的是2.05版本是Boolean delete(),两个不是同一个方法，所以找不到方法
			这样就是 编译是找自身的jar  运行才会找最终的依赖jar。尽量版本统一
			方法定义了  会就近寻找jar依赖   


7. nexus 搭建
	nexus仓库类型  
		Group：这是一个仓库聚合的概念，访问顺序取决于配置顺序
		Hosted:私有仓库，专门用来存储我们自己生成的jar文件  
		   Snapshots：本地项目的快照仓库  
		   Releases： 本地项目发布的正式版本  

		Proxy:公网上发布的jar 例如：spring
		  Central：中央仓库

		1.下载版本，cd目录下 nexus.exe/run  执行 访问
		2.创建相应的maven-proxy库，相应的group库。maven的setting.xml中配置对应的私服即可。
		当项目去私服下载的时候，私服没有会自动远程更新到私服下，然后拉取(实测正确)
			
		配置远程库时nexus的aliyun_proxy，总结就是nexus会远程更新
		1.本地mirror配置了central的代理库  aliyun，私服是远程aliyun代理，那么被本地的拦截了,nexus不会更新jar
		2.本地没有配置mirror，nexus下会更新jar
		3.本地配置mirror关于远程私服aliyun，所有请求都会到私服上，nexus会更新
		
		jar存放路径
		它的默认路径在\nexus-3.2.1-01-win64\sonatype-work\nexus3\blobs\default\content下面
		
		https://blog.csdn.net/m0_38001814/article/details/89494078   nexus 介绍
		
		发布机远程没有的会优先使用本地的jar
		
		子项目在maven库中依赖缺少父pom，上传一个父的pom.xml到nexus中即可。选择pom上传
		nexus中的可以把别的库中的jar文件夹直接复制过去，然后需要发布下或者退出nexus后台重新进入，然后就刷新了

		nexus proxy仓库可用的远程地址，https://repo1.maven.org/maven2/
		
		****
			Nexus私服的Release仓库不允许上传SNAPSHOT版本，会报错，而SNAPSHOT仓库压根就不提供Web界面上传功能。
			手工上传特定的快照jar,SNAPSHOT,到nexus库中
			光copyjar到nexus没用，还需要相关的xml中配置了相关的version等信息
			其中repositoryId是maven的setting.xml中配置的server节点的serverId(server中的配置的是nexus admin的登录账号和密码,获得上传的用户权限)
			mvn deploy:deploy-file -DgroupId=com.xiaoyuer.op -DartifactId=xye-open-dmo -Dversion=1.1.5-SNAPSHOT -Dpackaging=jar -Dfile=D:\k8sjar\xye-open-dmo-1.1.5-SNAPSHOT.jar -Durl=http://192.168.6.251:8087/nexus/content/repositories/K8sJar/ -DrepositoryId=my-nexus-snapshot
		****
		
		调k8s遇到的jar问题
			dubbo 2.8.4原因是没哟同时上传jar，这种关联的jar尽量不要手工上传，update官方的标准jar
			调试k8s的容器，其中dubbo 2.8.4x 手工上传后总是有问题，原先的mavenjar alibaba文件夹可以。替换251也不行，这种很可能是不能单独一个jar 还有其他相关的jar需要关联的。
			所以后来改添加snapshot进发布库，这是可行的，然后251nexus后台目录中删除jar和复制jar到k8sjar,不能立刻nexus页面显示，需要发布一次后才能更新
			
			netpay中的hessian接口也是，使用的是xye-open-dmo的手工上传的copy 的jar，导致报错，应该使用最新的jar，因为自己copy过来的肯定没有install后的实时全面，手工上传容易出错。
			因为可能open-dmo是从打包好的lib下直接拖过来的，但是install本身会传递一个依赖关系。到了lib下，jar已经update完了，不一定存在这种依赖关系。所以copy，不一定存在这种依赖关系。

		maven deploy，上传，部署
			-e 	打印完成的错误日志
			-U 	强制检查快照版本更新，没有就默认是天为检查
				-- 老版本
				<distributionManagement>
					<repository>
						<id>my-nexus-releases</id>	//maven得setting.xml中配置的server验证信息
						<url>http://192.168.6.251:8087/nexus/content/repositories/releases/</url>
					</repository>
					<snapshotRepository>
						<id>my-nexus-snapshot</id>
						<url>http://192.168.6.251:8087/nexus/content/repositories/snapshots/</url>
					</snapshotRepository>
				</distributionManagement>
				-- 分环境版本
				 <profiles>
					 <profile>
						<id>pre</id>
						<distributionManagement>
							<snapshotRepository>
								<id>my-nexus-snapshot</id>
								<url>http://192.168.6.251:8087/nexus/content/repositories/pre/</url>
							</snapshotRepository>
						</distributionManagement>
					</profile>
				</profiles>
	
			maven deploy 错误
				1、部署的仓库类型错误
					nexus的repository分三种类型：Hosted、 Proxy和Virtual，另外还有一个repository group(仓库组)用于对多个仓库进行组合，部署的时候只能部署到Hosted类型的仓库中。
				2、部署的仓库部署策略为禁止部署
					releases仓库的部署策略默认为禁止部署，如果要部署到这个仓库中需要修改部署策略为Allow Redeploy
				3、仓库发布版本与部署的项目发布版本不相符
					项目的发布版本如果为<version>1.0-SNAPSHOT</version>，则不能部署到发布版本为Release的仓库中

8. 多环境相关

	<directory>src/main/resources/${pay_env}</directory>
	目录中的会覆盖resource下的同名文件


## 数据结构相关

    数组和集合，长度和元素类型，集合只能是引用类型
        Collection下有List（ArrayList，LinkedList，Vector）和Set（HashSet，TreeSet）

        -| Collection 单例集合的根接口
        --| List  有序，可重复。 
        -----| ArrayList  底层是维护了一个Object数组实现的。 特点： 查询速度快，增删慢。
        -----| LinkedList 底层是使用了链表数据结构实现的， 特点： 查询速度慢，增删快。
        -----| Vector(了解即可)  底层也是维护了一个Object的数组实现的，实现与ArrayList是一样的，但是Vector是线程安全的，操作效率低。

        -| Set  无序，不可重复。
        --| HashSet  底层是使用了哈希表来支持的，特点： 存取速度快. 
        --| TreeSet   如果元素具备自然顺序 的特性，那么就按照元素自然顺序的特性进行排序存储。也可以比较器排序



1. set中的存值
	当原对象.equals（新对象）等于true时，两者的hashcode却是不一样的，将会存储了两个值一样的对象，
	导致混淆，因此，就也需要重写hashcode()
2. HashMap 和 HashTable的区别

    1.HashMap对象的key、value值均可为null。而HahTable对象的key、value值均不可为null
    2.HashTable 的方法前面都有 synchronized 来同步，是线程安全的；HashMap 未经同步，是非线程安全的。

    ConcurrentHashMap 和 Hashtable 主要区别就是
	围绕着锁的粒度以及如何锁,可以简单理解成把一个大的 HashTable 分解成多个，形成了锁分离。
	如图:而 Hashtable 的实现方式是---锁整个 hash


3. hashmap的原理   底层结构:Entry数组 + 链表
		1.判断当前确定的索引位置是否存在相同hashcode和相同key的元素，如果存在相同的hashcode和相同的key的元素，那么新值覆盖原来的旧值，并返回旧值。  
		2.如果存在相同的hashcode，那么他们确定的索引位置就相同，这时判断他们的key是否相同，如果不相同，这时就是产生了hash冲突。  
		3.Hash冲突后，那么HashMap的单个bucket里存储的不是一个 Entry，而是一个 Entry 链。  
		4.系统只能必须按顺序遍历每个 Entry，直到找到想搜索的 Entry 为止，如果恰好要搜索的 Entry 位于该 Entry 链的最末端，那系统必须循环到最后才能找到该元素。

		
        总结就是更具key的hash值确定tables中的存储位置，一般是单槽存放entry，hash冲突时，就是一个entry链，key相同覆盖，不同链表。取的时候遍历获取
        hashset中的必须满足hashcode和equals方法一样，才算重复
        hashmap的

		Java集合类HashMap内部就有一个静态内部类Entry。Entry是HashMap存放元素的抽象，HashMap 内部维护 Entry 数组用了存放元素。


4. hashmap的扩容问题
	底层是数组+链表的结构，数组的长度是固定的，当元素大于长度的时候就需要扩容，叫做resize，默认的数组大小是16。这个扩容过程有点像jvm的动态增加内存一样
	HashMap()：构建一个初始容量为 16，负载因子为 0.75 的 HashMap。超过16*0.75=12，就扩容一倍，比较消耗性能，最好指定已知的初始容量，和合适的负载因子
	
5. 集合在遍历时候，不能修改本身否则或发生并发修改异常
    类似list要使用迭代器才能修改list内容

6. 使用迭代器 list 的remove操作
		使用list操作会有索引左移和并发修改问题，建议使用迭代器删除
		Iterator<Integer> it=list.iterator();
		while(it.hasNext()){
				if(it.next()==3){it.remove();}
			}
		System.out.println(list);
		
		iterator.next() 这里的每次next就会迭到下一个元素，最好用变量接收iterator.next()

	list转逗号分割 	StringUtils.join(orderPayStrs.toArray(), ",");	

7. 双循环的终止问题，continue 和break都只影响本身的循环，不会影响上层循环体

8. 	List相关
	ArrayList 和linkedlist区别
		ArrayList是实现了基于动态数组的数据结构，LinkedList是基于链表结构。
		对于随机访问的get和set方法，ArrayList要优于LinkedList，因为LinkedList要移动指针。
		对于新增和删除操作add和remove，LinkedList比较占优势，因为ArrayList要移动数据。

	list初始化
		List<String> names = new ArrayList<>() {{
			add("Tom");
			add("Sally");
		}};
		List<String> colors = Stream.of("blue", "red", "yellow").collect(toList());


9. 基本介绍
	LinkedList 是链表结构，增删块，查找慢
	HashSet 首先判断两个元素的哈希值，如果哈希值一样，接着会比较equals 方法 如果 equls 结果为 true ，HashSet 就视为同一个元素。如果 equals 为 false 就不是同一个元素
	hashmap 在jdk7中 	数组+链表
			在jdk8中 	数组+链表+红黑树 组成	当链表中的元素超过了8个以后，会将链表转换为红黑树
	ConcurrentHashMap 是一个 Segment 数组，Segment 通过继承ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment，这样只要保证个 Segment 是线程安全的，也就实现了全局的线程安全。默认16个Segments
	队列是一种特殊的线性表，特殊之处在于它只允许在表的前端（front）进行删除操作，而在表的后端（rear）进行插入操作，和栈一样，队列是一种操作受限制的线性表。进行插入操作的端称为队尾，进行删除操作的端称为队头。


## 杂项记录
1. 自增
    1、uuid   2、redis.incr  3、date+random   4、mysql自增
    
2. 在interceptor中取到的信息可以放进request中，再传递到controller中	   			request.setAttribute(a,b)
3. 域名的分配 
	一级域名	taotao.com
	二级域名	www.taotao.com

4. 解决post乱码：在web.xml中配置字符集过滤
解决个体乱码：	
1、tomcat中    
 ```<Connector URLEncoding="utf-8" port="8080" 		protocol="HTTP/1.1"  connectionTimeout="20000" redirectPort="8443" />```
2、new String(request.getParammeter("a").getBytes("ISO8859-1"),"utf-8")
     
5. restful支持： 
    非rest url http://.../queryitem?id=001&type=t01
    rest url   http;//.../item/001
    实现rest访问 前端控制器需要配置/拦截
    配置/ ,那么静态资源js也会由前端控制器拦截，所以找不到，
    在springmvc.xml中添加静态资源解析即可，<mvc:resources location='/js/'  mapping='/js/**'>
    
6. 在安装mysql的过程中出现server一直启动中，很可能是之前的版本没有，删除干净，使用Uninstall Tool删除干净后再安装即可
7. java操作excel的两种方式： poi和jxl，都很简单 看看简单的demo，分模块理解即可
8. 装饰模式和继承的灵活性
    装饰类和被装饰类需要实现统一接口或者属于同一父类
9. jdk版本之间更换后install失败：
    Unsupported major.minor version 52.0（jdk8用的）  项目的库和java版本都要统一，

10. 数据库建表的经验：
	1、统一把主键设置为bigint类型，int类型最大值才20亿左右
	2、tinyint 默认4，smallint 默认6，mediumint 默认9，int 默认11，bigint 默认20。一般使用默认，varchar需要按需设置显示长度
	3、整型数系统已经限制了取值范围，tinyint占1个字节、int占4个字节。
		所以整型数后面的m不是表示的数据长度，而是表示数据在显示时显示的最小长度。
		没有zerofill(长度不足就补零)，(m)就是无用的。
		总结：int(11)，tinyint(1)，bigint(20)，后面的数字，不代表占用空间容量。
			而代表最小显示位数。这个东西基本没有意义，除非你对字段指定zerofill。
			
	4、	字符类型若为gbk，每个字符最多占2个字节
		字符类型若为utf8，每个字符最多占3个字节

        char长度固定，varchar长度可变
11. mysql忘记密码
```
    GRANT ALL PRIVILEGES ON *.* TO kaifa@"%" IDENTIFIED BY '123123'; 后面的数据库是要加密后存进mysql的

    跳过权限登录linux的mysql
    # mysqld_safe --user=mysql --skip-grant-tables --skip-networking &
    # mysql -u root mysql

    mysql> UPDATE user SET Password=PASSWORD('newpassword') where USER='root';
    mysql> FLUSH PRIVILEGES;
    mysql> quit
```
12. 获取客户端的IP地址：
	代理服务器在转发请求的HTTP头信息中，增加了X-FORWARDED-FOR信息。用以跟踪原有的客户端 IP地址和原来客户端请求的服务器地址。
```			
            String ip = request.getHeader("x-forwarded-for");
			if (StringUtils.isEmpty(ip) || IP_UNKNOWN.equalsIgnoreCase(ip))
			{
				ip = request.getHeader("Proxy-Client-IP");
			}
			if (StringUtils.isEmpty(ip) || IP_UNKNOWN.equalsIgnoreCase(ip))
			{
				ip = request.getHeader("WL-Proxy-Client-IP");
			}
			if (StringUtils.isEmpty(ip) || IP_UNKNOWN.equalsIgnoreCase(ip))
			{
				ip = request.getRemoteAddr();
			}
			return ip;
```
13. 集合排序
    Collections.sort 排序的使用    类的内部实现compare接口，或者外部使用比较器
    List<String> keys = new ArrayList<String>(payParams.keySet());
    Collections.sort(keys);//基本类型的直接排就行

14. hashcode和equals方法
	equals 方法  原本是 == 比较两个对象的地址是否相等(即，是否是同一个对象)
	hashCode() 在散列表中hashCode() 的作用是获取对象的散列码，进而确定该对象在散列表中的位置。
	1、如果两个对象相等，那么它们的hashCode()值一定要相同；
	2、如果两个对象hashCode()相等，它们并不一定相等。
        hashCode()不相等，两个对象一定不equals()

    hashcode是用于散列数据的快速存取,如利用HashSet/HashMap等存储数据时，根据存储对象的hashcode值来进行判断是否相同的
    hashCode方法实际上返回的就是对象存储位置的映像。


	自定义类要重写equals方法来进行等值比较，(不重写equals，比较的是对象的引用是否指向同一块内存地址)
	自定义类要重写compareTo方法来进行不同对象大小的比较，
	自定义类重写hashcode(),方便类存入hashmap等数据时，相等对象必须具有相同的hashcode()

    hashCode存值原理
		这样一来，当集合要添加新的元素时，先调用这个元素的hashCode方法，就能定位到它应该放置的存储位置。
		如果这个位置上没有元素，它就可以直接存储在这个位置上，不用再进行任何比较了；
		如果这个位置上已经有元素了，就调用它的equals方法与新元素进行比较，相同的话就不存了，不相同就表示发生冲突了，冲突后散列表特殊处理，最终将新元素保存在适当位置。
15. 路径操作
    String getServerName()：获取服务器名，localhost；
	String getServerPort()：获取服务器端口号，8080；
	String getContextPath()：获取项目名，/Example；
	String getServletPath()：获取Servlet路径，/AServlet；
	String getQueryString()：获取参数部分，即问号后面的部分：username=zhangsan
	String getRequestURI()：获取请求URI，等于项目名+Servlet路径：/Example/AServlet
	String getRequestURL()：获取请求URL，等于不包含参数的整个请求路径：http://localhost:8080/Example/AServlet 。

16. tomcat 和nginx的ssl相同吗，
	不一样，nginx使用的是，wohaha.crt，nihaha.key;使用openssl创建吧应该，
	tomcat中的使用jdk自带的keystool工具生成

17. ant 风格资源地址匹配：
	?: 匹配文件名中的一个字符
	*：匹配文件名中任意字符	
	**：匹配多层路径

18. spring api 中  requestContextHolder能在controller中获取request 和 session，用到了吗？
    但是需在web.xml中配置requestcontextlistener

19. 装饰者模式（Decorator）,使用例子：
	ServletRequestWrapper 和 HttpServletRequestWrapper 提供对 request 对象进行包装的
	方法，但是默认情况下每个方法都是调用原来 request 对象的方法，
	也就是说包装类并没有对 request 进行增强在这两个包装类基础上，继承 HttpServletRequestWrapper ，覆盖需要增强的方法即可

20. final修饰：
		类：阻止继承
		方法：不可重写
		域：初始化后无法修改，常与static组合创建常量

21. main函数是静态的，只能调用静态方法，只能new对象调用非静态方法

	cmd 不识别mysql命令的时候，需要在环境变量中的path中添加mysql对应的bin目录

22. 关于，创建对象的堆，栈和常量池
	String str = "abc"创建对象的过程
		1 首先在常量池中查找是否存在内容为"abc"字符串对象
		2 如果不存在则在常量池中创建"abc"，并让str引用该对象
		3 如果存在则直接让str引用该对象
		
	String str = new String("abc")创建实例的过程
		1 首先在堆中（不是常量池）创建一个指定的对象"abc"，并让str引用指向该对象
		2 在字符串常量池中查看，是否存在内容为"abc"字符串对象
		3 若存在，则将new出来的字符串对象与字符串常量池中的对象联系起来
		4 若不存在，则在字符串常量池中创建一个内容为"abc"的字符串对象，并将堆中的对象与之联系起来
		
		String str1 = "abc"; String str2 = "ab" + "c"; str1==str2是ture
		String str1 = "abc"; String str2 = "ab"; String str3 = str2 + "c"; str1==str3是false
		
		小结：字符串若变量相加，是先开空间，再拼接；若常量相加，是先加，然后再常量池中找，存在返回，不存在创建
        
 23. jdk版本切换要点(忽略)
        cmd  echo %path% 输出系统的环境变量
        更换java_home
        删除path中的变量C:\Program Files (x86)\Common Files\Oracle\Java\javapath;
        删除C:\ProgramData\Oracle\Java，将Java文件直接删除
        然后更换system32中的三个java文件对应版本即可
        最多还要修改下注册表	
        HKEY_LOCAL_MACHINE\SOFTWARE\JavaSoft\Java Runtime Environment
        HKEY_LOCAL_MACHINE\SOFTWARE\JavaSoft\Java Development Kit

 24. try 在for之外，那么异常是会终止循环的，若在之内，捕获后可继续循环

 25. post请求中，"转码，url中的正常&是不能转义的
	 String param = dataForSign.replaceAll("\"", "%22").replaceAll("}", "%7d").replaceAll("\\{", "%7b").replaceAll(" ", "%20");
      
 26. nignx先断3秒后关机,留给上一个请求处理时间

 27. 为日志增加变量输出
		MDC.put(STR_USER, accountNo);
		MDC.remove(STR_USER);    这个最终在finally中需要删除掉

28. 正则表达式：
		.（点号）也是一个正则表达式，它匹配任何一个字符
		.*	任意字符匹配多次	a*   多个字符匹配多次  依次匹配
		.*?	任意字符匹配一次	a*?
		\s+	匹配任意多个上面的字符。另因为反斜杠在Java里是转义字符，所以在Java里，我们要这么用\\s+
		. 匹配除换行符以外的任意字符

		\w 匹配字母或数字或下划线或汉字 等价于 '[^A-Za-z0-9_]'。
		\s 匹配任意的空白符
		\d 匹配数字
		\b 匹配单词的开始或结束
		^ 匹配字符串的开始
		$ 匹配字符串的结束

		^\d+(\.\d+)?

		1,^ 定义了以什么开始
		2,\d+ 匹配一个或多个数字
		? 设置括号内的选项是可选的
		\. 匹配 "."
		可以匹配的实例："5", "1.5" 和 "2.21"。

		特殊字符必须转义之后才能当做字符串
		java中\\代表一个\

		^匹配输入字符串的开始位置，除非在方括号表达式中使用，此时它表示不接受该字符集合。要匹配 ^ 字符本身，请使用 \^。
		
	正则表达式：
			字符串 String 的 split 方法，传入的分隔字符串是正则表达式！部分关键字（比如.[]()\|等）需要转义. |
			"a.ab.abc".split("\\."); // 结果为["a", "ab", "abc"]
			"a|ab|abc".split("\\|"); // 结果为["a", "ab", "abc"]

29. solr	
        CommitWithin
            简单的说就是告诉solr在多少毫秒内提交，比如如果我指定<add commitWithin=10000>，将会高速solr在10s内提交我的document。用法
            1.可以在add方法设置参数，比如 server.add(mySolrInputDocument, 10000);
            solrServer.add(doc, Constants.CREATE_INDEX_MS);

30. 数据，类型转换
	原来的  Double.valueOf(21604435.94d) 这里会有科学计数法原因
	统一使用bigdecimal转换
	public static Long doubleToLong(double money)
		{
			BigDecimal b1 = new BigDecimal(money);
			return b1.multiply(new BigDecimal(100)).longValue();
		}

	double的保留位数和四舍五入处理,BigDecimal处理金额计算
		public static double setDifScare(double arg) {
		BigDecimal bl = new BigDecimal(arg).setScale(2, BigDecimal.ROUND_HALF_UP);
		return Double.parseDouble(bl.toString());}

31. ajax回来的请求只能是数据，跳页面还的事表单或者
 ```
	function payError(jSon) {
		var redirectLink;
		redirectLink = jSon.redirectLink;
		$("#form1").before("<form id='payError' method='post' action='#'><input type='hidden' name='resultPayOrderId' id='resultPayOrderId' value=''/>" +
		$("#terminalCode").val(jSon.terminalCode);
		$("#payError").attr("action", redirectLink);
		$("#payError").submit();
		
	}

	<script type='text/javascript'>
			var base = '${base}';
			var ctx="${ctx}";
	</script>


	private freemarker.template.Configuration configuration;
	configuration.setSharedVariable("base", "/xye-open");

	pUrl = base + "/payGateWay/egjPayPage.htm";			
	window.location.href = base+"/rechargetGateWay/showInside.htm?refresh="+Math.random();
	window.location.href= jSon.pcUrl;
 ```

 32. github 
	创建文件夹，  /dir/aa.txt  就可以创建dir目录
	
	执行一个.bat文件，如若双击，错误闪退，如果是cmd进去执行，错误会显示出来

33. 接口中的变量值
	在interface里面的变量都是public static final 的。所以你可以这样写：
	public static final int i=10;
	或
	int i=10；（可以省略掉一部分）
	注意在声明的时候要给变量赋予初值

34. 如果一个类，没有定义构造函数，那么系统默认有一个无参构造函数
	如果你自定义了构造函数(无论有参还是无参)，那么编译器就不会创建无参构造函数。若还需无参构造，就必须显式的声明一个

35. 接口和实现类
	class a 实现 接口b(继承接口c)，那么a需要实现所有方法(包括c中的)，但是若a继承了一个实现c接口的类，就不用都实现(只认implements)

	接口中方法注释可以上层显示，实现类中也能看到。优先接口中添加说明备注。

36. javax.servlet-api
	javax.servlet-api   4.0.1 provided     上线使用的tomcat中的，旧版本servlet-api.jar，接口中是没有方法体的
	当我们运行Tomcat的时候，肯定把Tomcat依赖的jar包都导入了，而<scope>provided</scope>的作用就是让servlet-api依赖只在编译的时候起作用，
	运行的时候不起作用，避免和Tomcat自带的依赖产生冲突，所以我们引入servlet-api依赖
			
			

37. web项目的标准结构：java+resource+webapp.这个默认的结构，一般不会去自己定义

38. 引用复制
	
		UserInfo userInfo = new UserInfo();		userInfo.setNickName("ceshi1");
		UserInfo userInfo2 = new UserInfo();	userInfo2=userInfo;
		userInfo2.setNickName("ceshi2");
		这种引用传递要注意,最终会将userInfo的信息也变更了
		obj.sonObj    这种类中包含属性类的情况，也属于引用复制，改变新的，也会改变老的子属性 要注意

39. 网银支付，网银网页跳转
		后端生成自动跳转的Html表单串(包含验签信息),将生成的html写到浏览器中完成自动跳转打开银联支付页面；

	设计的时候有三种架构图特别的实用，用例图，类图和模块图

40. lombok
		1.引入lombokjar 2.ide中安装lombok插件	3.使用@data注解
		不过一般不建议用，需要别人强制安装插件。

41. restful
		rest:根据三个单词缩写，资源(标识定位资源)+表现(获取资源后json等形式展示出来)+状态转换(增删改查等操作)
		简单参是用@pathvariable,复杂的用@requestBody接收json绑定转换为java对象(多个参数可以用json传递)


## 数据库相关,mysql相关
1. timestamp和datetime：
    只能表示从1970年到2038年的时间，而datetime不受此限制。
    结论：永远使用datetime来表示时间，决不使用timestamp，除非每次更新都要更新的时间，才考虑使用timestamp

2. 查询自增的返回
 ```
  SELECT table_name,AUTO_INCREMENT FROM information_schema.tables WHERE table_schema="db_xiaoyuer" 
 ``` 

3. 记录相关的sql
 ```   查询某字段大于2的记录统计
	   SELECT * FROM user_base_info 
        WHERE Delete_Mark = 0
		GROUP BY User_Id HAVING COUNT(id)>1

        HAVING类似于WHERE（唯一的差别是WHERE过滤行，HAVING过滤组），是跟着group by 使用的，以组为查询的维度

 
    日期的时间变化，注意时分秒的精度
	SELECT DATE_SUB('2019-07-02 17:21:08', INTERVAL 1 DAY)
	SELECT DATE('2019-07-02 17:21:08'-INTERVAL 1 DAY)
 ```



4. MySQL InnoDB 默认行级锁。行级锁都是基于索引的，如果一条 SQL 语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住。 
5.  注入过程的工作方式是提前终止文本字符串，然后追加一个新的命令。 提前;-- 结束
	防止sql注入的方法：
	1、普通用户与系统管理员用户的权限要有严格的区分。普通用户不能有Drop Table等表结构的权限
	2、强迫使用参数化语，不能让sql直接嵌入进去,参数化的语句使用参数而不是将用户输入变量嵌入到 SQL 语句中。视为字符值而不是可执行代码,类似的就是sql中的#和$,
	3、加强对用户输入内容的检查与验证，
		在 SQLServer 数据库中，有比较多的用户输入内容验证工具，检查输入内容的合法性(大小和数据类型,长度、格式和范围)


6. 主从数据库：
	修改的254从库，但是生产是从253主库读取的，
	所以页面读取不到（253主-从，但是254的数据库只是备份用的）254修改后没反应，
	生产读取的是253的库，254只是备份用的库，只能算是展示功能，

7. 主从数据库的
	热备份是实时备份，发生倒换也不影响业务；一般是基于binlog实现复制
    冷备份则是周期性备份（如：定时每天凌晨开始备份），发生倒换时，备机的数据不是最新的。
        冷备份指在数据库关闭后,进行备份,适用于所有模式的数据库的定期复制

8. 负载均衡：分布式服务通过内置负载均衡实现高可用，关系型数据库通过主备方式实现高可用

9. 读写分离解决的是读压力大的问题
	数据库读写分离会遇到如下问题：
	数据复制问题： 考虑时延、数据库的支持、复制条件支持。
	应用对于数据源的路由问题

10. 分布分表
    数据库分库分表后的相关问题
			垂直分表的时候，跨库join，数据冗余(常用数据冗余)；分多次查询；借助外部系统：搜索引擎等

11. mysql中的重要的日志文件：
	redo log：保证数据可靠的入磁盘
		作用：确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。
		生命周期：事务开始之后就产生redo log，在事务执行过程中，就写入redo log文件中，
				  当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。
				  使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。(随着事务的开始，逐步开始的)
　　			这一点是必须要知道的，因为这可以很好地解释再大的事务的提交（commit）的时间也是很短暂的。

	undo log:	用于回滚
		作用：保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读
		生命周期：事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性
				  当事务提交之后，undo log并不能立马被删除，
　　			  而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。
	
	binlog：记录的就是sql语句
		作用：
		　　1，用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。
		　　2，用于数据库的基于时间点的还原。
		生命周期：事务提交的时候，一次性将事务中的sql语句按照一定的格式记录到binlog中。
	
	mysql内部的xa事务提交 ，以 binlog 的写入与否作为事务提交成功与否的标志
	MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。 

12. 数据库中的锁
		根据锁定对象的不同分为
			表级锁
			行级锁
		从并发事务锁定的关系上看：
			共享锁，又称为读锁，可以查看但无法修改和删除数据。
			排他锁，又称为写锁、独占锁，既能读数据，又能修改数据。

13. 采用分段长整型编码方案,将主键编码分段，这样可以创建一个全局唯一的整数型主键值

14. dao的设计
			dao基类的设计：使用通用baseDao<T>设计基类，将常用方法封装，后续子dao继承。

15. 索引
    索引有两个特征，即唯一性索引和复合索引
	在复合索引中，列的排列顺序是非常重要的，原则上，应该首先定义最唯一的列；
	为了使查询优化器使用复合索引，查询语句中的WHERE 子句必须参考复合索引中第一个列；
	where 语句中索引独立出现，索引才会起作用，不要放在表达式中(如: 转换函数一般放在值那边，不要放在列那边)，或发生不合适的隐式转换

	聚集索引和非聚集索引的根本区别是表中记录的物理顺序和索引的排列顺序是否一致。

16. 
 ```
    select address,count(id) from student where 1=1 group by address having count(*)>2
 ```	
17. 单纯的select * from a,b是笛卡尔乘积。
	 如果对两个表进行关联:select * from a,b where a.id = b.id 意思就变了，等价于：select * from a inner join b on a.id = b.id。即就是内连接。

18. 梯度漏斗   
		select *from t where a = 1 and b = 2 and c = 3; 
		就等于在满足 a = 1 的结果集中过滤掉b = 2 的 再从 a = 1 and b = 2 结果集中过滤掉 c = 3 的，得到最终的结果集越多查询越高效

19. 最左匹配原则(只针对联合索引)
		联合索引中，最左前缀原则指的是，如果查询的时候查询条件精确匹配索引的左边连续一列或几列，该列就可以用作索引
		索引文件以B－Tree格式保存 重点是联合索引的最左边字段(没有就匹配失败，不走该索引)
		index(a,b,c)		相当于创建了多个索引：key(a)、key(a,b)、key(a,b,c)，只能从左到右顺序连贯组合
		where a=3 and c=4    仅使用了a
			
		最左匹配原则都是针对联合索引来说的，in 和 = 都可以乱序，MySQL优化器会将其优化成索引可以匹配的形式
		
		范围查询(>、<、between、like)就会停止匹配。联合索引中使用范围查询(>、<、between、like)的字段后的索引在该条 SQL 中都不会起作用。
		比如
			某表现有索引(a,b,c),现在你有如下语句
			select * from t where a=1 and b>1 and c =1;     #这样a,b可以用到（a,b,c），c不可以

20. mysql优化
		联表关联时，确保ON和USING中的列上有索引。有一个表的列有就行
		确保任何的GROUP 和 ORDER BY 中的表达式只涉及一个表中的列，这样mysql才可能使用索引来优化

		避免where子句中对字段施加函数，如 to_date(create_time) ＞xxxxx，这会造成无法命中索引
		将打算加索引的列设置为 NOT NULL ，否则将导致引擎放弃使用索引而进行全表扫描

		mysql 索引列不能参与计算：带函数的查询不参与索引

		应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描
		尽量避免在WHERE子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描
		启慢查询日志来找出较慢的SQL

		为null的列是无法参与到查询中的
		避免多表join 尽量使用冗余策略解决联表问题

		库名、表名、字段名：小写，下划线风格，不超过32个字符，禁止拼音英文混用
		禁止使用TEXT、BLOB类型解读：会浪费更多的磁盘和内存空间，非必要的大量的大字段查询会淘汰掉热数据，导致内存命中率急剧降低，影响数据库性能
		必须使用varchar(20)存储手机号解读,不要用外键，影响性能
		建立组合索引，必须把区分度高的字段放在前面解读：能够更加有效的过滤数据
		
		几个禁止
			禁止使用SELECT *   会增加无意义的字段消耗，不能有效的利用覆盖索引
			禁止使用属性隐式转换解读：SELECT uid FROM t_user WHERE phone=13800000000 会导致全表扫描，而不能命中phone索引，猜猜为什么？（这个线上问题不止出现过一次）
			禁止在WHERE条件的属性上使用函数或者表达式解读
			禁止负向查询，以及%开头的模糊查询解读：
				a）负向查询条件：NOT、!=、<>、!<、!>、NOT IN、NOT LIKE等，会导致全表扫描
				b）%开头的模糊查询，会导致全表扫描	
					like 模糊查询中，右模糊查询（321%）会使用索引，而%321 和%321%会放弃索引而使用全局扫描。
				
			禁止使用OR条件，必须改为IN查询解读：旧版本Mysql的OR查询是不能命中索引的，即使能命中索引，为何要让数据库耗费更多的CPU帮助实施查询优化呢
				where 字句有 or 出现还是会遍历全表。
		
		最左前缀匹配原则，mysql 会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，
		理论上索引对顺序是敏感的，但是由于MySQL的查询优化器会自动调整where子句的条件顺序以使用适合的索引，例如我们将where中的条件顺序颠倒：效果一样
		mysql在处理where条件是，优化查询条件一批匹配索引的位置，直到遇到范围查询(>、<、between、like)就停止匹配，也就是说mysql会自动优化查询条件来匹配索引，来满足使用索引的条件。
		where a,b  和 where b，a是一样的


		sql优化
			SELECT * FROM mytable t
			WHERE (CASE aPARAM WHEN 'a' THEN t.a = aID WHEN 'b' THEN t.b = aID WHEN 'c' THEN t.c = aID ELSE TRUE END)
			等价于
			SELECT * FROM mytable t
			WHERE ( t.a = aID AND aPARAM = 'a') OR (t.b = aID AND aPARAM = 'b') OR (t.c = aID AND aPARAM = 'c') OR (aPARAM NOT IN ('a','b','c'))

			这里CASE WHEN 可以和OR  或者union all 相互转换，当case when影响到索引使用的使用，可以使用union all 来替换，兼容索引使用
			
			
21. 几种常见的mysql未命中索引的情况
			1.条件中有or，即使有条件带索引也不会使用，除非or条件中的每个列都加上索引
			2.like查询以%开头，索引不会命中。但是以%结尾，索引可以使用。
			3.使用正确的字段类型，强制转换会无法命中索引。(若列类型是字符串，使用引号引用起来，否则不使用索引。)
			4.采用 not in, not exist
			5.链表时候，两个字段的编码不同

22. 使用explain解释，关注三个参数
		type		显示那种类别，有无使用索引。如果为ALL,说明进行全表扫描
		key			显示mysql实际决定使用的键(索引)。如果没有命中索引，键是NULL
		EXtra		特殊的备注信息
		
	explain中的type=const  表示查询结果最多匹配一行(只有在使用了主键和唯一索引情况下，进行常数值比较时查询的type才为const)

	这里可以看explain中的key_len长度， 个位数小差别是mysql的平衡量
		select * from table_name where a = '1' and c = '3' 
		如果不连续时，只用到了a列的索引，b列和c列都没有用到 
		结果显示是，使用到了(a,b,c)索引，但是key_len是一个字段的长度，说明，只有a列走了索引，c没走，走了几个字段的索引，看key_len大概。

23. 索引相关
	mysql中的btree索引使用的是
		其数据文件本身就是索引文件,相比MyISAM ，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data
		保存了完整的数据记录 
		这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引 这被称为聚簇索引(也叫聚集索引), 
		其余的索引为辅助索引 ，辅助索引 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM同的地方
		在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引 
		因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂

	索引失效的场景
		1.当查询的列不是独立的，而是表达式或者函数一部分时，将无法使用该列的索引。
		2.当查询的列需要进行模糊匹配时，索引失效，全表扫描
			模糊匹配，因为%表示全匹配，如果已经全匹配就不需要索引，还不如直接全表扫描。a%不确定
		3.IN可以使用索引， NOT IN 无法使用索引
		



	mysql索引结构，sql优化，limit优化，回表，索引覆盖
		参看链接
		https://blog.csdn.net/mu_wind/article/details/110128016
		https://blog.csdn.net/sinat_14913533/article/details/115537106  
		https://www.cnblogs.com/myseries/p/11265849.html 

		叶子节点(深度为0的节点)才会有data，其他都是索引(附带指针指向了下个节点)
		聚集索引 和 普通索引的区别
			本质区别：表记录的排列顺序和与索引的排列顺序是否一致
			聚集（clustered）索引，也叫聚簇索引，聚集索引clustered index(id), 非聚集索引index(username)
			类似字典中的拼音就是聚集索引，偏旁部首查汉字，就是非聚集索引。
			
			1.聚集索引：索引顺序和表中数据排序一致(聚集索引的顺序就是数据的物理存储顺序) ,一个表只能有一个聚族索引(因为数据在物理存放时只能有一种排列方式)。 
				聚集索引的叶子节点就是对应的数据节点，叶子节点中保存存了索引列和具体的数据
				InnoDB中,把数据data存放在B+树中的叶子节点上(存储了表中行数据)，而B+树的键值就是主键(索引和数据行保存在同一个B-Tree中)。命中叶子节点可以直接取出数据，相比非聚簇索引需要第二次查询
				
				InnoDB默认对主键建立聚簇索引。
					如果你不指定主键，InnoDB会用一个具有唯一且非空值的索引来代替。
					如果不存在这样的索引，InnoDB会定义一个隐藏的主键，然后对其建立聚簇索引。
				
			2.非聚集索引(辅助索引，普通索引，二级索引)： 索引顺序与物理存储顺序不同
				除了聚集索引以外都是非聚集索引，细分：普通索引，唯一索引，全文索引
				叶节
				B+Tree的叶子节点仍然是索引节点，其上的data，不是数据本身，而是数据存放的地址（不是指向行的物理指针，而是行的主键值）。b+中非叶子节点只有键值，叶子节点包含完成数据。
				回表二次查询
					查找时，存储引擎需要在二级索引中找到相应的叶子节点，获得行的主键值，然后使用主键去聚簇索引中查找数据行，这需要两次B-Tree查找，检索两次索引
				
				查询过程	扫描两次索引 
					要查询name = C 的数据，其搜索过程如下：
					1.辅助索引B+树中检索Name，到达其叶子节点获取对应的主键。
					2.使用主键在主索引B+树种再检索一次，最终到达叶子节点定位到行数据
					
		回表查询	先从普通索引定位主键值，再从聚集索引定位行数据，一般是查询列不在索引覆盖范围情况下				
		覆盖索引
			定义：如果一个索引覆盖所有需要查询的字段的值。即索引的叶子节点中已经包含要查询的数据。
			只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表。
			从非主聚簇索引中就能查到的想要数据，而不需要通过回表从主键索引中查询其他列
			尽量不要使用select *
			实现方法是：将被查询的字段，建立到联合索引里去。    使用联合索引  一定要使用索引并且带上查询列
			使用场景：Limit分页查询
			
			Using where' 在非索引的列上可能仍然会做全表扫描，where相对影响会大点
				EXPLAIN
				SELECT req_code FROM require_info WHERE req_title='测试鱼食——先发后托6'
				这种使用了where 后面没有索引，但是查询列是单个索引列，这种不走索引覆盖，走的全表

				EXPLAIN
				SELECT user_id FROM require_info 
				这种不加where的直接查询，user_id会走索引覆盖
				索引覆盖，必须要使用索引

				EXPLAIN
				SELECT req_code,req_title FROM require_info
				这种没有使用索引，不走索引覆盖
			
		mysql中的extra(有没有使用索引要看type)
			using idex						使用了覆盖索引				避免访问了表的数据行，效率不错
			using where 					只表示发生了where过滤		过滤条件字段无索引；如果type是all 就是扫全表， 常见的优化方法为，在where过滤属性上添加索引
			using where using index			发生了where过滤，索引覆盖了查询
			extra为null， type为ref，		表明虽然用到了索引，但是没有索引覆盖，产生了回表，常见于，where后面使用索引，但是查询的列回表了
				有点类似Using index condition
				
		升级联合索引(name, sex)，联合索引也是一棵B+树，不同的是联合索引的键值数量不是1，而是大于等于2.相当于创建了多个索引
			select id,name … where name=‘shenjian’;
			select id,name,sex … where name=‘shenjian’;
			都能够命中索引覆盖，无需回表。

		B+ 树
			B+ 树非叶子节点上是不存储数据的，仅存储键值，不存储数据，那么就会存储更多的键值，相应的树的阶数（节点的子节点树）就会更大，树就会更矮更胖，
			B+ 树索引的所有数据均存储在叶子节点，而且数据是按照顺序排列的。


		索引覆盖来优化SQL？
			全表count查询优化
			列查询回表优化				单列索引(name)升级为联合索引(name, sex)，即可避免回表
			分页查询					将单列索引(name)升级为联合索引(name, sex)，也可以避免回表

		索引覆盖
		SELECT * FROM require_info   	是按照id asc
		SELECT id FROM require_info		排序就乱了

		大数据量的limit优化思路
			1.尽可能的减少筛选出来的数据，不要扫描大量无用行。想过办法通过索引覆盖查询来查出必要的需要扫描的行，然后再去扫描实际的数据行
			2.避免回表(常发生在查询的列不在索引覆盖范围内)
			3.除了使用覆盖索引，优化查询速度外，我们还可以使用 Redis 缓存，将热点数据进行缓存储存。
			
			方法：1.采取的是限制分页(只查看前几千条数据)和增加缓存(记录上次查询的最大id，带到下次查询中筛选)。
					2.子查询的分页方式或者JOIN分页方式,用到的是索引覆盖，这两种逻辑一样，功能也一样
					想过办法通过索引覆盖查询来查出必要的需要扫描的行，然后再去扫描实际的数据行
					select orderNo,ctime from `order` order by orderNo limit 2000000,20
					select orderNo,ctime from `order` inner join ( select orderNo from `order` order by orderNo limit 2000000, 20 ) as o using(orderNo);    //using等价于join操作中的on
					分析：inner join的表通过索引覆盖查询直接通过索引找到了需要返回的数据行，然后order表通过与这个派生表进行关联，只扫描20行数据就可以了(第一种跨越大量数据块并取出)
					子查询是在索引上完成的，而普通的查询时在数据文件上完成的
					*****对limit的优化，不是直接使用limit，而是首先获取到offset的id，然后直接使用limit size来获取数据。*****
						
					SELECT * FROM tableName ORDER BY id LIMIT 500000 , 2
					
					-- 基于排序做条件过滤，有一定限制，主键id必须有序，同样适用创建时间等其他字段，但是必须要设置索引
					SELECT * FROM tableName
					WHERE id >= (SELECT id FROM tableName ORDER BY id LIMIT 500000 , 1)
					LIMIT 2;
					时间: 0.274s
					
					SELECT * FROM tableName AS t1
					JOIN (SELECT id FROM tableName ORDER BY id desc LIMIT 500000, 1) AS t2
					WHERE t1.id >= t2.id ORDER BY t1.id  LIMIT 2;
					时间: 0.278s
				
					-- 基于索引覆盖，这种更为高效
					SELECT * FROM tableName AS t1
					JOIN (SELECT id FROM tableName ORDER BY id desc LIMIT 500000, 2) AS t2
					WHERE t1.id = t2.id;


	InnoDB默认的行锁可以使得操作不同行时不会产生相互影响、不会阻塞，从而很好的解决了多事务和并发的问题。
	但是基于一个前提，即 Where 条件中使用上了索引；反之，如果没有使用上索引，则是全表扫描、全部阻塞
	
24. binlog是用来做point-in-point的恢复和主从复制的，由数据库上层生成，是sql执行的逻辑日志，事务提交完成后进行一次写入。


25. 查看表作为其他表的外键(忽略)
		SELECT
		ke.referenced_table_name parent,
		ke.table_name child,
		ke.REFERENCED_COLUMN_NAME parent_column,
		ke.column_name child_column,
		ke.constraint_name
		FROM
		information_schema.KEY_COLUMN_USAGE ke
		WHERE
		ke.referenced_table_name IS NOT NULL
		AND ke.referenced_table_name = 'Base_Skill_Appli;'
		AND ke.REFERENCED_COLUMN_NAME = 'id'
		AND ke.REFERENCED_TABLE_SCHEMA = 'db_xiaoyuer'
		ORDER BY
		ke.referenced_table_name;

	在5.5中，information_schema 库中增加了三个关于锁的表（MEMORY引擎）；
		innodb_trx ## 当前运行的所有事务
		innodb_locks ## 当前出现的锁
		innodb_lock_waits ## 锁等待的对应关系
	
		SELECT * FROM information_schema.innodb_trx
		SELECT * FROM information_schema.innodb_locks
		SELECT * FROM information_schema.innodb_lock_waits
				
		SHOW ENGINE INNODB STATUS			查看mysql事务处理列表，可查询死锁和事务相关的信息，
		SHOW FULL PROCESSLIST				查看所有mysql进程id

26. COUNT(*)  COUNT(1)  COUNT(id)比较
			结论是优先使用count(*)
			1、执行速度上：针对一般情况（SQL语句中没有where条件）执行速度上
			count(*)=count(1)>count(主键)>count(其他列)，在没有特殊查询要求推荐使用count(*)来代替其他的count。
			2、执行结果上，count(*)与count(1)以及count(主键)的结果完全相同，即返回表中的所有行数，包含null值；count(其他列)会排除掉该列值为null的记录，返回的值小于或者等于总行数。
			
27. 格式化
			时间 	DATE_FORMAT(si.date_insert,'%Y-%m-%d %T') AS releaseTime
			数字 	CAST( 120.6 AS DECIMAL(15,2))		
					FORMAT(13625.265,2)	13,625.27     

28. 4.0版本以下，varchar(20)，指的是20字节，如果存放UTF8汉字时，只能存6个（每个汉字3字节） 
	5.0版本以上，varchar(20)，指的是20字符，无论存放的是数字、字母还是UTF8汉字（每个汉字3字节），都可以存放20个，最大大小是65532字节

	mysql 中double  字段长度 20,2
	GROUP BY 合并 取结果集的第一条显示

29. 锁相关
	
	共享锁：又称读锁，获取共享锁的事务，只能读不能改。
		
		排他锁：又称为写锁，事务对一个数据加上排他锁后，其他事务不能再对此数据加任何其他类型的锁。
				能读能写，innoDB的增删改会默认加排他锁。典型的是select for update加排他锁
		
		InnoDB 行级锁是基于索引实现的，如果查询语句未命中任何索引，那么 InnoDB 会使用表级锁
		InnoDB 行级锁是针对索引加的锁，不针对数据记录，因此即使访问不同行的记录，如果使用到了相同的索引键仍然会现锁冲突
		
		行级锁是一种排他锁，防止其他事务修改此行；在使用以下语句时，Oracle 会自动应用行级锁：
		1.INSERT、UPDATE、DELETE、SELECT … FOR UPDATE [OF columns] [WAIT n | NOWAIT];
		2.SELECT … FOR UPDATE 语句允许用户一次锁定多条记录进行更新
		3.使用COMMIT 或 ROLLBACK 语句释放锁。

30. 事务隔离的实现基于锁机制和并发调度 其中并发调度使用的 MVCC （多版本并发控制），通过保存修改行的旧版本信息来支持并发一致性读和回滚等特性
	MVCC(多版本并发控制), 通过版本号来减少锁的争用

31. mysql-connector  mysql时区
		serverTimezone=UTC   在mysql-connector高版本8.x中会有时区的问题，方案要么配置serverTimezone=Asia/Shanghai,要么换用低版本的mysql-connector
		com.mysql.jdbc.Driver和mysql-connector-java 5一起用。
		com.mysql.cj.jdbc.Driver和mysql-connector-java 8 一起用。	需要配置市区serverTimezone=GMT%2B8
		TIMESTAMPDIFF(MINUTE,'2020-08-27 10:38:00','2020-08-27 11:38:00')  			计算两个时间差

	java.sql.Date		这个是数据库中的类型date，指精确到年月日
	java.util.Date		这个是数据库中的类型dateTime，精确到时分秒，一般开发用这个

32. 分库分表
	使用场景：当我们使用读写分离、缓存后，数据库的压力还是很大的时候，这就需要使用到数据库拆分。

	垂直水平拆分，类似业务拆分和数据拆分
		1.按照合理拆分规则拆分，join操作基本避免跨库。
		2.分片事务一致性难以解决。
		3.数据多次扩展难度跟维护量极大。
		4.跨库join性能较差
		5.垂直分区会主键冗余，并会引起 Join 操作，可以通过在应用层进行 Join 来解决
		6.水平分支持大数据量存储，应用端改造少，但分片事务难以解决，

	拆分引入问题
		1. 引入分布式事务的问题。
		2. 跨节点Join 的问题。
		3. 跨节点合并排序分页问题。

	拆分原则
		1. 尽量不拆分，架构是进化而来，不是一蹴而就。(SOA)
		2. 最大可能的找到最合适的切分维度。
		3. 由于数据库中间件对数据Join 实现的优劣难以把握，而且实现高性能难度极大，业务读取 尽量少使用多表Join -尽量通过数据冗余，分组避免数据垮库多表join。
		4. 尽量避免分布式事务。
		5. 单表拆分到数据1000万以内。
		切分方范围、枚举、时间、取模、哈希、指定等
	
	数据库的访问规则
		注意分表后的表名问题
			固定hash规则
				分库分表中的常用方法就是取模,分x张表就mod数值x
			映射表法
				将id和对应的表和库建立一个关系表，每次查询关系表，确定数据库和表。这种方法，一般用来以上面的规则为基础，作为配合使用。
			自定义规则，
				自定义函数，确定数据库的访问规则

	分库分表  这里需要考虑到扩容的情况，这个是避不开的问题
			拆表的数量一般是2的n次方
			分表解决的是单表数据量过大带来的查询效率的下降问题
			单纯的分库和分表 都是可以通过单独的取模进行分
			比如根据user_id划分256张表，那么就是user_id%256  这0-255共256张表
			
	如果同时进行分库和分(这种数据量就很大了，分库还能缓解单库的写操作压力)
		一种分库分表的路由策略
			1.中间变量=user_id%(库数量*每个库的表数量)
			2.库=取整(中间变量/每个库的表数量)
			3.表=中间变量%每个库的表数量

	1.引入多表关联查询，2.必须执行路由字段，3.扩容问题，4.分布式事务

33. 数据库的迁移
	关键是迁移过程中可能出现的数据变化
	当然最稳就是先停机，再迁移，最后切换。
	实际优化方案	1.正常迁移，	2.记录增量 	3.暂停待迁移的数据写操作，	4.处理完增量，切换规则。

	这里好处是停止写操作的时间只是在处理增量的操作中。减少了停机时间。
	这里就是用日志，记录增量变动，针对变动停机修复。
	1.数据迁移时，记录增量日志，迁移技术后，对增量变化进行处理。
	2.最后可以把要被迁移的数据写暂停，保证增量日志都处理完毕后，再切换规则，放开所有的写，完成迁移工作。

34. DISTINCT 和 group by
		DISTINCT 简单用来去重列值(去重)，而group by更多是用来统计(聚合统计)，以某个维度来统计数据
		DISTINCT 用在所有的检测列之前，并且它是作用于所有列，不能部分使用
		
		单纯的去重操作使用distinct(可单列或者多列，多列相当于联合唯一)，速度是快于group by的。
		group by 必须在查询结果中包含一个聚集函数，而distinct不用。 常用来统计数据
		聚合函数 ：AVG、MAX、MIN、SUM、COUNT


35. 隔离级别
	RR级别下防止幻读
		快照读：使用MVCC防止幻读
		当前读：使用间隙所防止幻读

36. 关联查询
	子查询		将子查询语句包装成外查询的条件		将select * from a where id>(select id from a where id=1)
	自联结		自己关联自己的表结构				实际使用场景是省市区   自联结比子查询快

	子查询和join 目前看可以转换
	内连接：(INNER) JOIN，返回两张表都匹配上的行
	join = inner join = from a, b where 过滤条件





## Docker相关
	docker的核心组件：
		1、docker的客户端和服务端，		连接方式：命令行工具或api调用
		2、docker镜像					相当于容器的“源代码”，生命周期中的构建或者打包阶段
		3、registry						相当于远程/私有库 										官方的使用的是docker hub
		4、docker容器					启动或者执行阶段
		
	总结docker容器就是：一个镜像格式，一系列标准的操作，一个执行环境
	
	查看docker toolbox的ip地址（即decker服务器的localhost或者ip地址）：$ docker-machine ip default
    docker toolbox创建了一个本地虚拟机，拥有自己的网络接口和ip地址
	docker程序是docker守护进程的客户端程序
	
	开始：
	从下往上，由基础镜像往上，最终生成一个可写容器，创建dockerfile时，每条run指令都会创建一个镜像层，指令成功，镜像层提交
	
	相关的linux命令：
		1、cat命令主要用来查看文件内容，创建文件，文件合并，追加文件内容等功能。
		2、ps -aux 查看容器的进程
	
	创建一个可交互的容器， 这样就创建了新容器，直接root进入了容器操作，/bin/bash就是交互的shell，交互式容器
		sudo docker run -i -t ubuntu /bin/bash  	也可以使用--name来给容器命名，跟在run后面 创建交互式的容器
		exit 										退出容器(容器停止运行)，回到宿主机命令提示符，容器仍然存在，只有在指定的/bin/bash命令运行时，容器才运行。
		docker ps -a 								查看当前系统中的容器列表，不带-a查看运行中的
		sudo docker start test_linux				重新启动容器
		sudo docker attach test_linux				重新附着到容器的会话上
		sudo docker run --name daemon_dave ubuntu /bin/sh -c "while ture; do echo hello world; sleep 1; done" 创建守护式容器，-d 创建守护容器
		sudo docker logs -f daemon_dave 			查看容器日志
		sudo docker top test_linux					查看容器中的进程
		docker exec 								容器内启动新进程
		docker stop test_linux						停止容器
		docker rm test_linux						删除容器
		docker images								查看镜像
		docker pull fedora:20 						从远程拉取镜像
		docker rmi									删除镜像
		
		docker build -t="jamtur01/static_web" .      基于dockerfile(vim编写)创建一个镜像，其中设置了仓库和名称
		
		下载war挂在到数据卷中，然后启动带有tomcat的容器，最后会将数据卷中的war挂载到tomcat对应的容器执行
		
		启用微服务，在dockerfile中的 配置容器启动后执行的命令，ENTRYPOINT ["java","-jar","/app.jar"],打成镜像，配置端口，直接run即可


## 系统优化方案
	1.静态化页面
	效率最高、消耗最少的就是纯静态化的html页面。对于一些更新频率不频繁而又被大量访问的页面，我们就可以做静态化处理，来避免大规模的数据库访问。
	2.通过缓存加速数据库的访问。

	3.对数据库分库分表，读写分离
	可以解决容量和性能问题。
	读写分离：就是将数据库分成读库和写库，再通过主从来属性同步数据库。
	分库分表：分为水平切分和垂直切分。水平切分就是将一个特大的表拆分成多个小的表。垂直切分则是根据业务的不同来切分。
	关于数据库的优化，在另一篇文章中有记录。

	4.使用CDN加速全国用户的静态文件访问
		这里简单记录一下CDN原理：将数据内容缓存到附近的机房，用户访问时先从最近的机房获取数据，减少网络访问的路径，提高用户访问网站的响应速度和网站的可用性。解决网络宽带小、用户访问量大、网点分布不均等问题。

        cdn部署在网络提供商的机房，使请求近地区机房获取数据；而反向代理提供在网站的中心机房

		加速使用cdn
		目前主要用来缓存静态数据
			其实就是一种网络缓存技术
			cdn作用是把用户需要的内容分发到离用户近的节点，使用户就近获取所需内容。
			cdn系统分为cdn源站，cdn节点。源站提供节点使用的数据源头，而节点部署在距离最终用户比较近的地方。

	5.反向代理（可归类为5）
		Nginx反向代理的作用：
		1.保护网络安全：任何的请求都必须先经过代理服务器，可以过滤一些非安全请求。
		2.通过配置缓存功能加速web请求。可以缓存服务器上的某些静态资源，减轻服务器的负载压力。
		3.实现负载均衡：充当负载均衡服务器均衡的分发请求，平衡集群中各个服务器的负载压力。

6. 集群：多台服务器部署相同应用构成一个群体，通过负载均衡设备共同对外提供服务，这里使用了失效转移机制
7. 首页是不应该访问数据库的，一般从缓存服务器或者搜索引擎服务器获取数据

8. 网站的伸缩性:1、根据功能进行物理分离实现伸缩，即服务化，多个机器不同服务
			   2、单一功能通过集群实现伸缩，多个机器同服务

## 日志相关
    
	localhost_acces log.*.txt   Tomcat存取日志：
		位于 Tomcat log 目录下，清晰地记录了 HTTP 服务请求的来源、响应时间、返回的 HTTP 代码等，可用于统计服务的成功数和失败数，也可用于统计接口的响应时间，还可用于统计服务的请求数和吞吐量等。
	catalina.out	Tomcat控制台目志
		位于 Tomcat log 目录下，包含 Tomcat是否成功启动、启动所使用的时间，以及应用打印的控制台日志等信息。
	localhost. *. txt	Tomcat 本地日志
		位于 Tomcat log 目录下，程序异常在没有被捕获时会被一直抛出到容器层，容器处理后记录在这个目志里。
	ELK的适用场景：日志采集器，日志缓冲队列和日志解析器	
		对集群中个节点的日志又不方便通过 Linux 命令行进行聚合查找和统计。通常采用 ELK ( Elasticsearch+Logstash+Kibana ）架构来实现。
		日志缓冲队列是大数据日志处理器系统的核心，连接了日志收集器和日志解析器	

    stdout 输出到控制台，对应linux会输出到catalina.out
		自己配置日志路径	<property name="logbackpath" value="C:/Users/xiaoyuer/Desktop/xye-log"></property>  可行
		C:\Users\xiaoyuer\Desktop\xye-log  不行	
	
1. logback中   appender是打印器  需要绑定到logger中  而root是根logger
	
	案例：
     ```
		<logger name="orderValidate" additivity="false">
			<level value="INFO" />
			<appender-ref ref="orderValidate" />
			<appender-ref ref="STDOUT" />      不加控制台不打印，加上打印，不加orderValidate，控制台也不打印，一个appender也不指定，也不会继承root，因为这里已经匹配了相应的logger了
		</logger>
		<root>
			<level value="INFO" />
			<appender-ref ref="STDOUT" />
			<appender-ref ref="ERROR" />
		</root>
     ```
		orderValidate不加STDOUT，控制台是看不到的额，因为指定匹配了logger，没有使用root的
		<logger name="ch.qos.logback" level="ERROR" />  和 root 和日志级别关系    
			root的作用是收集下面所有反馈上来的信息流并根据配置在root中appender进行输出，
			additivity="false"  子Logger不继承父logger的输出，只会在自己的appender里输出，不会在父Logger的appender里输出，不会反馈到root中
			
		<logger name="org.springframework" level="ERROR" />
			这个是单独配置的级别  其中的参数默认覆盖root中的，其他的按照root默认来，会优先匹配logger，匹配不到才使用root的。
		
	logback MDC机制
			作用：扩展logback内置的日志字段，自定义业务数据
			原理：内部持有一个InheritableThreadLocal实例，用于保存context数据。注意操作完要MDC.clear()方法
			案例：实际使用中可以用一个filter专门定制自定义的日志字段。也可以个别类中单独处理。只要是一个线程请求即可。
			
 ```            
			代码实例
				MDC.put("sessionId",sessionId);
				logger.info("test23");
				MDC.remove("sessionId");

			logback.xml中的配置
				<property name="pattern" value="%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread|%X{invokeNo}|%X{sessionId}] %-5level %logger{36}-%msg%n"/>
				<appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender">
				<File>${logbackpath}/xye.log</File>
				<rollingPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy">
					<FileNamePattern>${logbackpath}/xye.%d{yyyy-MM-dd}-%i.log</FileNamePattern>
					<maxFileSize>500MB</maxFileSize>
				</rollingPolicy>
					<encoder>
						<pattern>${pattern}</pattern>
					</encoder>
				</appender>
 ```

 2. MDC.put   	MDC.remove
	结合类java.lang.ThreadLocal<T>及Thread类可以知道，
	MDC中的put方法其实就是讲键值对放入一个Hashtable对象中，然后赋值给当前线程的ThreadLocal.ThreadLocalMap对象，即threadLocals，这保证了各个线程的在MDC键值对的独立性。
	是的单线程的日志输出具有共享变量

3. 	这里是工程中以war工程为目录起点，后面可以单独测试下
	<property name="logbackpath" value="../logs/"></property>  作为一个jar包执行的话就是  jar的上级目录
	String path = System.getProperty("user.dir").replace("\\", "/");//获取当前应用所在目录
	path = path.substring(0, path.lastIndexOf("/"));			这里jar目录截取到d盘
	path = path + "/conf/xye-datasource.properties";
	logger.info("datasource-path:{}",path);


## 消息队列
### rocketmq

    生产者发送msg发送给namesrv（路由管理），namesrv通过broker存储转发消息到consumer集群，再消费给consumer(配合listener订阅topic)

	jms消息模型
	1、点对点模型，消息一次性消费
	2、发布者/订阅者模型

	消息中间件
		消息存储：消息的Header信息(投递次数等基本信息)，消息的Body(主要内容)，消息的投递对象。
				
		消息的可靠性
			一定要业务处理成功之后，再返回确认消息。否则消息就丢失了。
			分布式系统的三个重要点，服务框架，消息中间件，和数据访问层。

		rocketmq producer 发送消息失败，总是连接不上服务器地址
		1. 目前这种写法Rocket默认开启了VIP通道，VIP通道端口为10911-2=10909。若Rocket服务器未启动端口10909，则报connect to <> failed。
		2. 解决方式：增加一行代码producer.setVipChannelEnabled(false);


	rocketmq  后台可以新增消息发送   topic选项新增消息发送
		rocketmq常见异常 	https://blog.csdn.net/weixin_43439073/article/details/95746775


	boot中已经能继承mq了，引入依赖rocketmq-spring-boot-starter，并添加相关配置(暂未使用)
			rocketmq.producer.group = producer_bank2
			rocketmq.name-server = 127.0.0.1:9876
			
			@Component
			@RocketMQMessageListener(topic="topic_notifymsg",consumerGroup="consumer_group_notifymsg_bank1") 
			public class NotifyMsgListener implements RocketMQListener<AccountPay> {
				@Autowired
				AccountInfoService accountInfoService;
				@Override
				public void onMessage(AccountPay accountPay) {
					log.info("接收到消息:{}", JSON.toJSONString(accountPay)); 
					AccountChangeEvent accountChangeEvent = new AccountChangeEvent();
					accountChangeEvent.setAmount(accountPay.getPayAmount());
					accountInfoService.updateAccountBalance(accountChangeEvent); 
					log.info("处理消息完成:{}", JSON.toJSONString(accountChangeEvent));
				} 
			}
			
			
	系统中使用mq
		小鱼儿中是@PostConstruct中初始化mq的监听配置
		defaultMQPushConsumer.registerMessageListener(new MessageListenerConcurrently() {});
		// Consumer对象在使用之前必须要调用start初始化，初始化一次即可<br>
		消费者初始化，defaultMQPushConsumer.start();
		生产者也是同样的初始化， defaultMQProducer.start();
		
		本地使用
		@Component("egjTradeConsumer")
		public class EgjTradeConsumer {
		@PostConstruct
			public void startConsumer() throws Exception {
				DefaultMQPushConsumer consumer = new DefaultMQPushConsumer(consumerGroup);
				consumer.setVipChannelEnabled(false);
				consumer.setNamesrvAddr(nameServerAddress);
				consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET);
				consumer.setMessageModel(MessageModel.CLUSTERING);
				consumer.subscribe(MQConstants.TOPIC_EGJ_ORDER, "*");
				consumer.registerMessageListener(new MessageListenerConcurrently() {
				//目前是只请求一次预付交易接口，用并发消费，后期若出现多次有序请求的场景，请重新评估消费模式是否应当选择顺序消费
					
				@Override
				public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) {
					StringBuffer sb = new StringBuffer();//拼装出异常短信的发送内容，人工检查
					for(MessageExt msg:msgs) {JSONObject data = JSONObject.parseObject(new String(msg.getBody()));}
				}
			}
		}

	
### rabbitmq
	rabbitmq
	server.port=9898
	spring.application.name=spring-cloud-stream
	spring.rabbitmq.host=192.168.174.128
	spring.rabbitmq.port=5672
	spring.rabbitmq.username=guest
	spring.rabbitmq.password=guest

	#指定输入通道对应的主题名
	spring.cloud.stream.bindings.myInput.destination=minestream
	spring.cloud.stream.bindings.myOutput.destination=minestream

	windows 系统环境标量设置好了后，一定要重新运行cmd测试

	rabbitmq  映射2个端口：15672是Web管理界面的端口；5672是MQ访问的端口。

	安装了rabbitmq测试了下，
		1.安装erl环境包
		2.直接安装rabbitmq服务端
		3.打开插件才能看到后台管理页面
		4.发送和接收要绑定统一个通道名
		
		
		sink.class 和 source.class   通道绑定暂不细看
		
		@EnableBinding用来绑定多个消息通道		启动消息驱动功能
			@EnableBinding(value = { Sink.class, MsgSender.class })   创建发送实例
		@StreamListener	将某方法注册为A消息通道的监听处理器
		
		
	rabbitmq-plugins enable rabbitmq_management   开启插件后才能使用后台管理页面

	ERROR: node with name "rabbit" already running on "xxx"
	tasklist | find /i "erl"指令，发现进程
	taskkill /pid 13776 -t -f		kill进程
	重启目录下rabbitmq启动程序 rabbitmq-server.bat	

    
三个点：生产者:
		消费者： 
		消息存储与转发  broker :
		分布式系统:
			通讯协议: tcp/ip、http、
			数据传输: 序列化，
			分布式事务：暂不支持
		2、通讯层的设计：rpc 自定义的协议请求头
		3、存储层设计：数据文件+索引文件
		刷盘方式  同步/异步刷盘
		pagecache  内存页  通过异步线程回写磁盘		
			三种发送消息的机制：1、同步发送 	返回消息发送成功
								2、异步发送 	有消息丢失的可能		
								3、oneway		kafak日志收集 肯定丢失
		broker设计，横向扩容两个，支持大数据量：
			topic 主题
			queue 队列
			topic中存在多个消息队列，有下标



1. 幂等性 去重处理即可，一般建议业务去重   
https://www.cnblogs.com/wxd0108/p/6038543.html

2.mq的部署问题：
	1、4.2.0需要jdk8，需要设置rocketmq_home 启动.cmd格式的就ok
	2、项目中netty-tcnative jar找不到，需要将maven的中无关修饰去掉
	3、启动broker   mqbroker -n localhost:9876 制定nameserver地址即可
3. 消费模式	创建consumer的时候，指定同一groupname，即在同一组中
		广播模式：全部接收，发送给订阅topic中的组的每个消费者consumer
		集群模式：消息均摊，天然的负载均衡，订阅topic中的其中一个consumer组中的成员均分消息，自带多层次（组和组成员）负载均衡，一个topic/queue可以被多个组消费，组之间也是均分的， 
4.消息过滤(忽略)
		1、简单是订阅使用tags过滤即可
		2、在broker端的机器，开启mqfiltersrv，自定义filter的java文件实现msssagefilter,实现match方法，mixall.file2String(),subscribe(a，b，c)即可，filter不允许有中文
5. 	集群模式
		2m模式，其中一台宕机，消费可能延迟。起不来就消费补了上次的信息，重点不是双m获得同样的信息，是分配的，
		多m/s，异步复制 ，主从数据同步的方式：异步复制  m刷盘（未刷盘或尚未同步，m挂了，信息丢失），返回ack给客户端，同时异步复制到s上
		多m/s，同步双写，写完m，刷盘，同步s成功后返回ack，数据不丢失，性能低，安全高
6. pushconsumer是通过监听器获取消息，属于长连接，实时被动接受消息
   pullconsumer是主动去获取信息，属于短连接，主动拉取消息

    mq核心的存储概念    commitlog：消息体存放  
                       consumequeue：记录消息的位置
		
    每个broker\consumer与nameserver集群中的每个节点建立长连接，定期从nameserver取topic路由信息，并向broker建立长连接，发送心跳



7. 	生产者的可靠性投递和消费者的幂等性去重
		
        为保证消息发送可靠性，重要的消息发送前，一定要有消息的备份，创建消息临时表
        防止宕机的情况,事务结束后想发补偿mq消息或者后期job轮询发送，
        为加快发送速度，可以使用线程池发送消息，excutorservice.submit(new runable(){})

        在发之前将mq消息持久化，发送成功后再删除，开启job定时扫描长时间存在的消息并重新发送        

        消息重试机制：
			生产者：消息重投重试，保证数据可靠
			自定义属性，msg.putUserProperty("a","1")单独设置属性，传递后面是map形式,msg.getUserProperty("a")
	
			消费者：消息异常处理，失败返回重试标记consumer_later，1s,5s,10s执行重试的策略
					同一个组中两个consumer，其中一个终端，没有返回ack和status，则重试另一个consumer，msg.getconsumertimes，获取重试次数，也可以获取上次的originid（第一次是null）
	
		消息幂等性处理：
			去重原则：1、幂等性 2业务去重
			去重策略：去重表机制（key去重，主键比如msgid），业务拼接去重策略（比如指纹码、唯一流水号等，联合索引）
			高并发下去重：redis去重（key天然支持原子性且要求不可重复），但是由于不在一个事务内，所以需要适当的补偿策略
							1、利用redis的事务、主键（我们必须把全量的操作数据，都存放到redis，然后定时和db同步）
							2、利用redis和关系型数据库  一起做去重机制
			不允许补偿（大额转账）

            关于mq的消费去重，可以增加mq消息去重表，groupname，tag ，key，msgid作为联合唯一键，用于并发时主键冲突，
	        对于想要重试的消息，直接返回false即可，mq有重试的机制，一般超过3次人工处理

            在下单支付后，第三方有异步的回调操作，可以把回调结果发送给mq，解耦支付的业务耦合。
            消费者要去重和幂等处理，不仅仅以消息id区别，还可以在消息体中增加唯一业务编号
            对于失败的消息需要失败重试处理（失败次数），保证消息完全消费

8. rockeqmq的producer三种方式：
		1、normalProducer(常用，其他两个先不看)
		2、orderProducer 搭配consumer的实现order监听，一般一轮顺序消费指定一个队列，同一消息下的指定队列
		3、transactionProducer（两阶段提交）
			第一阶段：将消息传递给mq，但是消费端不可见，但是数据已经发送到broker
			第二阶段是本地回调处理，成功返回commit_message，则再broker上对消费者可见，失败为rollback_message，消费端不可见

	producer的主要配置：重试次数，maxsize，timeout

9. 消费端
	每种类型的监听者都应该有自己的实现逻辑，增加统一的message处理接口，每个server端的consumer，都有自己的对应的接口实现，直接调用即可

在消费端：可以自定义listener实现源码中的messagelistenerconcurrently接口，在consumer端，监听消息的时候，可以定义一个接口，
	专门用于处理监听到的消息，这样可以解耦业务处理，这个思想不错

    顺序消费：针对同一队列中的顺序
		生产端是messagequeueselector，同时指定队列，消费端是注册监听，实现的接口是messagelilstenerorderly

 ```
 @Override
	public ConsumeConcurrentlyStatus consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) {
		for(MessageExt msg :  msgs){
    		String topic = msg.getTopic();
    		String tag = msg.getTags();
    		String msgBody = null;
    		try {
				msgBody = new String(msg.getBody(),"utf-8");
			} catch (UnsupportedEncodingException e) {
				logger.error("",e);
			}
		}	
	}	
 ```





	
10. mq解决数据一致性
	调用远程服务，扣优惠券，扣余额，如果调用成功——>更改订单状态可见，失败->发送mq消息，进行取消订单
        1、具体的思路，本地的步骤1和2，全部写完，
        2、开始分步调用远程的服务，优惠券，成功了进行下一个，失败直接异常抛出
        3、扣余额，返回失败，异常抛出
        4、扣库存，返回失败，异常抛出
        5、try catch全部步骤，将相关的回退参数传过去，异常发送mq，每个server端监听，这里使用了topic和tag的监听
        6、全部成功，更改订单状态
        7、后续会有定时器轮询，长时间订单状态没改变的，有可能是mq发送失败，补发消息
        8、consumer端，最好的是使用统一的消息处理接口，重点重点重点：监听业务有没有操作记录，有记录回退，没有记录不用处理，即每个server都需要做相应的处理，处理逻辑看情况和操作日志来定
        9、消费端可以启动多个消费端，这样可以将处理的实现类，注入到通用的consumer配置中，实现，可配置处理
		
    mq处理事务
		处理多个服务之间的一致性：后者失败，前者补偿操作，事务不要太多
			1、创建不可见的订单，执行多个小事务，并且这些是同时监听一个回滚topic的，只要有一失败就发送消息到mq，其他的监听到并进行回滚操作
			2、需要执行另一个查询订单状态的任务，异常的全部取消

	使用mq解决分布式事务：
		service-foo 和 service-bar
		1.foo进表后，增加event表，事件进入mq(写入名为"foo-success-queue"队列)
		2.从mq中获取event，调用bar,然后bar进表。若bar异常，就回滚，将原event写入Failure queue中，
		3.foo将作为消费者从失败队列中找到event，根据eventId找到对应的foo，然后操作回滚
	
## 线程相关，锁相关
1. final这类的不可变对象一定是线程安全的。典型的String类就是
   final的方法不能被重写。所以父类中的private方法默认是final的，子类将无法访问、覆盖该方法

2. ThreadLocal
	一个thread对象中都有一个threadlocalmap的对象，该对象存储了一组以threadlocal.threadlocalhashcode为键，以本地线程变量为值的k-v值对，这样就保证了线程变量的唯一性
	Thread.ThreadLocalMap<ThreadLocal, Object>;

    threadlocal，并不是一个线程，是保存本地线程变量副本的容器，属于当前线程的专有属性，与其他线程相隔离
		
	这个变量一般是跟着private static用的，在一个共同的外部类使用threadlocal保存资源。

    实现原理：
        在Threadlocal类中有一个Map，用于存储每个线程的变量副本，key-线程对象，value-对应线程的变量副本
		
    使用同步机制要求：1.变量读写时间，2.锁定对象的时间 3.释放对象的时间
    同步机制：		时间换空间，访问串行化，对象共享化。同一份变量，排队
    threadlocal：	空间换时间，访问并行化，对象独享化。不同变量副本，不用排队


	treadlocal 是一次线程的操作，存一个对象 key-value，可以存一个map，这样可以多存几个值，用完记得移除

	线程变量会有线程挂起？(避免资源的浪费)
		挂起之后，线程的挂起操作实质上就是线程进入"非可执行"状态下，在这个状态下CPU不会分给线程时间片，进入这个状态可以用来暂停一个线程的运行。
		线程挂起后(阻塞状态 cpu不分配运行时间)，可以通过重新唤醒线程来使之恢复运行。



	ThreadLocal无法在父子线程之间传递--内容保存在线程对象中，子线程无法继承父线程的内容
	父线程的概念(创建线程,类似main中开线程)，只是一种逻辑称呼，创建线程的当前线程就是新线程的父线程，新线程的一些资源来自于这个父线程

	1. 每个线程中都有一个自己的 ThreadLocalMap 类对象(t.inheritableThreadLocals)，可以将线程自己的对象保持到其中，各管各的，线程可以正确的访问到自己的对象。
	2. 将一个共用的 ThreadLocal 静态实例(static final)作为 key，将不同对象的引用保存到不同线程的ThreadLocalMap 中，然后在线程执行的各处通过这个静态 ThreadLocal 实例的 get()方法取得自己线程保存的那个对象，避免了将这个对象作为参数传递的麻烦。
	3. ThreadLocalMap 其实就是线程里面的一个属性，它在 Thread 类中定义ThreadLocal.ThreadLocalMap threadLocals = null;


	//这里是将value存在了每个线程的ThreadLocalMap中，key是共用的 ThreadLocal静态实例，value是当前线程的值
	//private static final ThreadLocal<ApplicationContext> opContextHolder = new ThreadLocal<ApplicationContext>();
	//ThreadLocalMap，当前线程为key，存放value
	//ThreadLocal
	public void set(T value) {
        Thread t = Thread.currentThread();
        ThreadLocalMap map = getMap(t);
        if (map != null)
            map.set(this, value);
        else
            createMap(t, value);
    }
	
	 void createMap(Thread t, T firstValue) {
        t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);
    }
	

	本地系统实现

		op系统gateway传值
		重定向redirect，服务器端在响应第一次请求的时候，让浏览器再向另外一个URL发出请求，从而达到转发的目的。它本质上是两次HTTP请求，对应两个request对象。
		转发forward，客户端浏览器只发出一次请求，Servlet把请求转发给Servlet、HTML、JSP或其它信息资源，由第2个信息资源响应该请求，两个信息资源共享同一个request对象。	
	
		1.将参数放进threadlocal中
		2.在接下来的另一个方法中，取出threadlocal中存的data信息，放进session中
		3.重定向后从session中取出data信息。
		那么这里threadlocal的使用，只不过是为了再后面的方法中不带参数的传递信息，后面方法直接取线程变量，不需要由前传到后。本质上还是从session中取数据。
		重定向后，因为是同一个域名，www.xiaoyuer.com,所以是同一个sessionid
		这其实可以直接存session，然后重定向后获取。

		小鱼儿系统
		每次来一个线程就存一次context，每次覆盖一个新的CommonConstant.PAGE_SERVICE_SESSION_KEY, uuid 来存值setContext中存。相当于将信息存在了session中
 ```		
		private GenericResult<Object> invokePageService(OpService opService)
			throws IOException
		{
			String uuid = UUID.randomUUID().toString();
			ApplicationContext context = ApplicationContext.getContext();
			HttpServletRequest request =((ServletRequestAttributes)RequestContextHolder.getRequestAttributes()).getRequest();
			request.getSession().setAttribute(uuid, context);
			request.getSession().setAttribute(CommonConstant.PAGE_SERVICE_SESSION_KEY, uuid);
			LOGGER.info("设置session{},UUID是:{}", request.getSession().getId(),uuid);
			GenericResult<Object> result = new GenericResult<Object>();
			result.setObject(opService.getPageTarget());
			return result;
		}
 ```

 ```
		1.存入线程变量
		private void setContext(Map<String, Object> parameters, OpPartner opPartner, OpService opService,OpPartnerService ops)
		{
			ApplicationContext.getContext().setParameters(parameters);
			ApplicationContext.getContext().setPartnerService(ops);
			...
		}
		2.存入session
		private GenericResult<Object> invokePageService(OpService opService)throws IOException
		{
			String uuid = UUID.randomUUID().toString();
			ApplicationContext context = ApplicationContext.getContext();
			HttpServletRequest request =((ServletRequestAttributes)RequestContextHolder.getRequestAttributes()).getRequest();
			request.getSession().setAttribute(uuid, context);
			request.getSession().setAttribute(CommonConstant.PAGE_SERVICE_SESSION_KEY, uuid);
			return result;
		}
		3.
		重定向之后  重定向之后，
		uuid = String.valueOf(request.getSession().getAttribute(CommonConstant.PAGE_SERVICE_SESSION_KEY));
		context= (ApplicationContext)request.getSession().getAttribute(uuid);
 ```


3.  sleep 和 wait
    sleep()方法是 Thread 类中方法，而 wait()方法是 Object 类中的方法。
    sleep()方法导致了程序暂停执行指定的时间，让出 cpu 该其他线程，但是他的
    监控状态依然保持者，当指定的时间到了又会自动恢复运行状态，
    sleep()方法，线程不会释放对象锁。
    wait()方法，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用 notify()方法后本线程才进入对象锁定池准备。


4. 两种匿名内部类创建方式：
 ```
	  new Thread() {
            public void run() {
                for (int i = 0; i < 10; i++) {
                    System.out.println("aaaaaaaaa");
                }
            }
        }.start();//开启线程

        new Thread(new Runnable() {
            public void run() {
                for (int i = 0; i < 10; i++) {
                    System.out.println("bbbbbbbbb");
                }
            }
        }).start();//开启线程
 ```
 5. 悲观锁是避免冲突，遇到就等；	冲突率很高的并发场景下适合用悲观锁
		select ... for update ，容易死锁，因为会一直等到锁可用，两个用户都需要a，b资源，这时候会出现互相等待的场景
		悲观锁开销在于加锁本身，需要很复杂的同步与调度机制，即使没有真正发生冲突也增加额外开销，


        elect... for update  和update都可以实现悲观锁(一般伴随事务一起使用，数据锁定时间可能会很长)
        事物提交是在整个方法执行完才会提交。

	乐观锁是提交时才判断冲突。
		乐观锁通常来说根本没有真正的锁，而只是检查了一个标记决定是否真的进行提交，开销要小得多，但是一旦发生冲突需要撤销整个transaction重做。
        所以冲突相对少的时候乐观锁有优势。	并发高的时可能会出现失败次数多的情况
        UPDATE seckill  SET number=number-?,version=version+1 WHERE seckill_id=? AND version = ?

    select * from table_xxx where id='xxx' for update; 
	注意：id字段一定是主键或者唯一索引，不然是锁表

 6. lock 和 synchronized

    1. 使用两种锁锁方法
		   public static void lock(int i){
				lock.lock();
				num1 ++;
				lock.unlock();
			}
			public static synchronized void sync(int i){
				num2 ++;
			}
			







6. 线程池相关
    Executors是线程池的工厂类
			ExecutorService executorService = Executors.newFixedThreadPool(11);
			new ThreadPoolExecutor(nThreads, nThreads,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue<Runnable>()); 这样默认的是最大的队列值
			ListenableFuture是guava中的多线程能得到结果的方法,可得到多线程调用的结果  这个知道概念就行了


3. 分布式锁

    可行的一些方案：
        1、基于数据库资源表的分布式锁，这里是乐观锁(版本号的更新概念)
        2、使用了Redis 的 setnx()和 expire()的分布式锁解决的问题
        3、使用了 memecahed 的 add()方法(不常用)
        4、使用 zookeeper，用于分布式锁。(不常用)



	实现方式：
		1. 数据库乐观锁；2. 基于Redis的分布式锁；3. 基于ZooKeeper的分布式锁。

	满足的条件
		系统是一个分布式系统（关键是分布式，单机的可以使用ReentrantLock或者synchronized代码块来实现）
		共享资源（各个系统访问同一个资源，资源的载体可能是传统关系型数据库或者NoSQL）
		同步访问（即有很多个进程同事访问同一个共享资源。没有同步访问，谁管你资源竞争不竞争）
	

        ReentrantLock 的 lock 和 unlock 要求必须是
        在同一线程进行，而分布式应用中，lock 和 unlock 是两次不相关的请求，因此肯
        定不是同一线程，因此分布式锁中，无法使用 ReentrantLock。



	必要性：
		如果不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，访问该资源时，往往需要互斥来防止彼此干扰来保证一致性，在这种情况下，便需要使用到分布式锁。


    乐观锁的：
		(1). 这种操作方式，使原本一次的 update 操作，必须变为 2 次操作: select 版本号一次；update 一次。增加了数据库操作的次
		(2).基于数据库操作，在高并发的要求下，对数据库连接的开销一定是无法忍受的
	
	使用redis的锁实现分布式的相关操作：
		1. setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功
		2. expire()命令对 lockkey 设置超时时间，为的是避免死锁问题。
		3. 执行完业务代码后，可以通过 delete 命令删除 key。
		方案的弊端就是，在设置超时时间的时候，会出现宕机，这样就会出现死锁问题。
		
		**********redis实现的原理***************
		所以如果要对其进行完善的话，可以使用 redis 的 setnx()、get()和 getset()方法来实现分布式锁。方案待定，不一定适用。
		
		1. setnx(lockkey, 当前时间+过期超时时间) ，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。
		2. get(lockkey)获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。
		3. 计算 newExpireTime=当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值 currentExpireTime。
		4. 判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。
		5. 在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处
	

		
4. 多线程的实现
    1.继承 Thread 类、
    2.实现 Runnable 接口
    3.Future 实现有返回结果

5. 在 java 中有以下 3 种方法可以终止正在运行的线程：
    1.使用退出标志，使线程正常退出，也就是当 run 方法完成后线程终止。
    2.使用 stop 方法强行终止，但是不推荐这个方法，因为 stop 和 suspend 及 resume 一样都是过期作废的方法。
    3.使用 interrupt 方法中断线
6. Lock 和 synchronized
    像i/o等耗时的计算或操作，执行这些操作期间不要占有锁
    1.Lock的锁定是通过代码实现，lock是一个类，可实现同步访问，而 synchronized 是java的关键字，是在 JVM 层面上实现的，
        synchronized 会自动释放锁，而 Lock一定要手工释放，且须在finally 中释放。Lock 锁的范围有局限性，块范围，而 synchronized 可以锁住块、对象、类
    2.Lock lock = new ReentrantLock(); //注意这个地方
        在 insert 方法中的 lock 变量是局部变量，每个线程执行该方法时
        都会保存一个副本，那么理所当然每个线程执行到 lock.lock()处获取的是不同的锁，所以就不会发生冲突。

    3.synchronized 缺点：
        代码块被 synchronized 修饰，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况：
        1）获取锁的线程执行完了该代码块，然后线程释放对锁的占有；
        2）线程执行发生异常，此时 JVM 会让线程自动释放锁。
        那么如果这个获取锁的线程由于要等待 IO 或者其他原因（比如调用 sleep 方法）被阻塞了，但是又没有释放锁，其他线程便只能干巴巴地等待，影响程序执行效率
        还有尝尽个就是读写操作的，使用synchronized关键字的话，多个读操作就要相互等待，浪费资源，
        因此就需要有一种机制可以不让等待的线程一直无期限地等待下去（比如只等待一定的时间或者能够响应中断），通过 Lock 就可以办到,ock可以控制等待的时间

    4.Lock 和 synchronized 的选择
        1）Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言实现；
        2）synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，因此使用 Lock 时需要在 finally 块中释放锁；
        3）Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用synchronized 时，等待的线程会一直等待下去，不能够响应中断；
        4）通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。
        5）Lock 可以提高多个线程进行读操作的效率。

        1、可重入锁：synchronized 和 ReentrantLock 都是可重入锁，进入对象的第二个锁方法，不需要重新获取锁
            class MyClass {
                public synchronized void method1() {
                method2();
                }
                public synchronized void method2() {
                }
            }
        2、可中断锁	synchronized 就不是可中断锁，而 Lock 是可中断锁。

        3、公平锁
            公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个
            锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。
            
            synchronized 就是非公平锁，它无法保证等待的线程获取锁的顺序。
            ReentrantLock 和 ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁
            
        4、读写锁
            ReentrantReadWriteLock并未实现 Lock 接口，它实现的是ReadWriteLock 接口
            可以通过 readLock()获取读锁，通过 writeLock()获取写锁。

    	5、synchronized,锁对象和方法(就是该方法所在对象本身)，静态的synchronized方法从class对象上获取锁
			内部锁在java中是互斥锁的存在，但是会带来的响应性的问题。优先锁代码块

		ReentrantLock synchronized 相比 ，更加灵活，且具有等待可中断、可实现公平锁可以绑定多个条件等特性
		解决并发思路：
		1.锁，小粒度，reetrantlock
		2.无锁
			CAS ：即 Compare And Swap ，这是一种类似于乐观锁的机制 每次更新值的时候都使用旧值与变量的当前值做比较，如果相同则进行更新，否则重试直到成功
			Threadlocal ：本地存储变量，这样每 个线程都有一份数据的副本，也就不会存在并发问题了
			不可变对象： 不可变对象自然不会有并发问题
			cas重要的缺点是，强迫调用者处理竞争(重试，回退或放弃)，然而在锁被获得之前，却可以通过阻塞自动处理竞争




7. 线程修改变量的过程：(了解即可)
		每一个线程运行时都有一个线程栈，线程栈保存了线程运行时候变量值信息。
		当线程访问某一个对象时候值的时候，首先通过对象的引用找到对应在堆内存
		的变量的值，然后把堆内存变量的具体值 load 到线程本地内存中，建立一个变
		量副本，之后线程就不再和对象在堆内存变量值有任何关系，而是直接修改副
		本变量的值，在修改完之后的某一个时刻（线程退出之前），自动把线程变量
		副本的值回写到对象在堆中变量。这样在堆中的对象的值就产生变化了
		
		Java内存模型规定了所有的变量都存储在主内存中。
		每条线程有自己的工作内存，其中使用的变量是主内存中的拷贝的变量副本，线程对变量的所有操作（读取，赋值）都必须在工作内存中进行。
		不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。

8. 线程共享进程范围内的资源，但是每个线程都有自己的程序计数器，栈，本地变量(这些本地变量存储在线程的栈中)

9. 当调度程序临时挂起当前运行的线程，另一个线程开始运行。保存和恢复线程执行的上下文，cpu的时间会花费在对线程的调度而不是运行上。
10. 原子操作：当其他线程想要查看或者修改一个状态时，必须在我们线程开始之前或者完成之后，而不能在操作过程中。
	count++，获得当前值，加1，写回新值，是3个离散的操作，是一个读-改-写的操作过程。
    

11. 重排序
    处理器在进行重排序时会考虑指令之间的数据依赖性，指令重排序不影响单线程的处理，那么理解就是按顺序执行就行（忽略）
12. volatile变量
	对于volatile修饰的变量，jvm虚拟机只是保证从主内存加载到线程工作内存的值是最新的(相当于get和reload操作)
	总结下来：
	第一：使用volatile关键字会强制将修改的值立即写入主存；
	第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量的缓存行无效；
		每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态。
		操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，用时会从内存重新读取
	第三：由于线程1的工作内存中缓存变量的缓存行无效，所以线程1再次读取变量的值时会去主存读取。
		当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里
	
		对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。
		对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。

        加锁可以保证可见性和原子性，volatile变量只能保证可见性


13. 并发涉及到的三个特性
		1、原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。
		2、可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。
		3、有序性：即程序执行的顺序按照代码的先后顺序执行。
	
	可见性：（涉及到本地线程内存和主内存的概念，高速缓存（相当于本地的线程内存/工作内存）中的数据刷新到主存当中）
		对于可见性，Java提供了volatile关键字来保证可见性,但是不保证原子性(在多个线程访问的时候，原子性就不能保证了，单线程是可以的)
　　	当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去主内存中读取新值。
		通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。

     原子性：提供了互斥访问，同一时刻只能有一个线程对它进行操作 

14. Threadlocal

    threadlocal提供了get和set访问器，为使用它的线程维护一份单独的拷贝，get总是返回由当前执行线程通过set设置的最新值
	threadlocal<T>可以看作是map<thread,t>，存储了与线程相关的值。是线程限制
	实现变量的初始化(忽略)
 ```
	ThreadLocal<Integer> iin=new ThreadLocal<Intege r>(){
				 public Integer initialValue() {
					 	int a=1;
				        return a;
				    }
				};
 ```	

    常用用法：和context结合使用，将context和线程关联起来，降低了每个方法传递执行上下文信息的需要。
    便于线程的上下文传输，隐藏参数传递
	注意这里是静态持有上下文的，有两个特性，一个是封闭隐藏，一个是传输性。降低重用性，引入隐晦的类间耦合
 ```    
	public class ApplicationContext implements Serializable
	{
    /** 应用上下文线程变量 */
	private static final ThreadLocal<ApplicationContext> opContextHolder = new ThreadLocal<ApplicationContext>();
    private Object info;
    public static ApplicationContext getContext()
    {
        ApplicationContext context = opContextHolder.get();
        if (null == context)
        {
            context = new ApplicationContext();
            opContextHolder.set(context);
        }
        return context;
    }
  ```

15. countDownLatch 是并发包使用的一个计数器，		调用await()方法的线程会被挂起，它会等待直到count值为0才继续执行


   
	
## springboot相关

    约定优先原理:自动配置加载一个类的配置时，首先读取项目中的配置，项目中没有才启用默认配置

1. 现在基本上是主要java配置+少数属性配置用xml，比如dubbo.xml
    @importresoutce,可以加载xml配置 
2. java 配置方式：取代xml
		使用@configuretion 和@bean  前者用在类上，相当于xml，后者作用方法上，相当于bean,默认将方法名作为bean的id，可以指定@Bean(name = "dataSource")
3. 	@PropertySource可以读取指定的配置文件，@value获取，需要搭配@configuretion，等同于在xml中配置properties文件
	@PropertySource(value={"a.properties" , "b.properties"},ignoreresoureNotFound=true)
4. 整合mybatis
		配置mybatis-spring-boot-starter需指定version，不属于boot启动依赖，不属于同一个groupId
	
	如果是java代码配置(现在都用boot配置，忽略)
    需要指定@AutoConfigureAfter(MybatisConfig.class)，mapperscan需要sqlSessionfactory配置后才生效
	
	一般spingboot整合mybatis：1.dataSource 2.sqlSessionfactory  3.mapperscan  
	思路是由mapper映射xml查询数据库，mapperscan-sqlfactory-datasource      
	
	配置的时候除了先idea的坑，需要再pom中<build>属性中<resource>相关mapper.xml到classpath下，
	springboot再javapackage中自己是不会编译xml的，只会编译java类文件，resource只会编译资源文件
	再spingboot的tomcat部署，会默认java 和resources 打到classpath下，直接可用，但是一旦使用了resource，就必须指定资源文件了，
	默认tomcat配置将失效，但是maven编译则需要再build中添加进来
	总结就两点 source root下不会编译xml文件，使用<resource>后，覆盖默认，需要指定所有资源文件

5. 原先时使用<tx:advice>定义事务策略，使用<aop:config>定义切点，并融合策略。
    boot中推荐使用@transactional 实现申明事务，需要jdbc起步依赖，自动创建事务管理器，
    需要 @EnableTransactionManagement 开启事务(这个好像是默认开启了)，相当于<tx:annotation-driven />

6. 	测试bean，有个小细节就是框架会自动为我们注入有参参数，容器默认的bean。(测试用，忽略)
    @Bean
    public Object testBean(PlatformTransactionManager platformTransactionManager){
        System.out.println(">>>>>>>>>>" + platformTransactionManager.getClass().getName());
        return new Object();
    }
7.  指定事务管理器(好像是默认的，不需要配置的，暂记录)
	@Bean
    public PlatformTransactionManager txManager(DataSource dataSource) {
        return new DataSourceTransactionManager(dataSource);
    }
8. SpringBoot默认指扫描当前启动类所在的包里的对象，
	如果当前启动类没有包，则在启动时会报错,启动类不能直接放在main/java文件夹下,必须要建一个包把它放进去或者使用@ComponentScan指明要扫描的包。
	默认扫描@SpringBootApplication所在类的目录包以及其子包
	
9.多个事务管理器(忽略)
 ```
	//实现接口TransactionManagementConfigurer方法，用来多事务管理器下，指定默认管理器，
	@EnableTransactionManagement // 开启注解事务管理，等同于xml配置文件中的 <tx:annotation-driven />
	@SpringBootApplication
	public class ProfiledemoApplication implements TransactionManagementConfigurer {
		@Resource(name="txManager2")
		private PlatformTransactionManager txManager2;
		
		// 创建事务管理器1
		@Bean(name = "txManager1")
		public PlatformTransactionManager txManager(DataSource dataSource) {
			return new DataSourceTransactionManager(dataSource);
		}

		// 创建事务管理器2
		@Bean(name = "txManager2")
		public PlatformTransactionManager txManager2(EntityManagerFactory factory) {
			return new JpaTransactionManager(factory);
		}

		// 实现接口 TransactionManagementConfigurer 方法，其返回值代表在拥有多个事务管理器的情况下默认使用的事务管理器
		@Override
		public PlatformTransactionManager annotationDrivenTransactionManager() {
			return txManager2;
		}

		public static void main(String[] args) {
			SpringApplication.run(ProfiledemoApplication.class, args);
		}
	}
 ```
 10.	属性文件的加载，加载属性配置
 		属性文件和bean之间的转化
        @ConfigurationProperties注解主要用来把properties配置文件转化为bean来使用的，
		@configurationProperties(prefix="spring.redis")读取属性文件的值
			foo.enabled=false
			foo.security.username=user
			foo.security.password=pwd						#其中security是内部静态类，具有相关的属性
			
		而@EnableConfigurationProperties注解的作用是@ConfigurationProperties注解生效。
		当然在@ConfigurationProperties加入注解的类上加@Component也可以使交于springboot管理。

        @Component
        @PropertySource("classpath:application.properties")		#添加自定义的属性文件进来,将属性文件加入到容器，后续可以直接用@value注入
        @ConfigurationProperties(prefix = "application.dubbo.demo.server")	#写在类上，省略前缀，匹配后面的名字，但是注意要有set方法
        Class some{}


		默认从全局配置文件中获取值,如果想加载指定属性文件，就得使用@PropertySource进行加载后再使用@ConfigurationProperties。

		使用 Configuration configs = new PropertiesConfiguration(filePath);直接临时读取属性文件，初始化

		PropertiesUtil   自动状态属性类 	  这里就可以在static初始化中加载属性文件，后面直接静态方法调用即可
		InputStream is = PropertiesUtil.class.getClassLoader().getResourceAsStream(propName);
		prop.load(is);


		@Value(”$(database.driverName)”),${}代表占位符，会读取上下文的属性值装配到属性中，是一个spring表达式


		从属性文件中加载list或者map
			blog-top-links={"home":"/home"}
			blog-list=1,2,3

			@Value("#{'${blog-list}'.split(',')}")
			private List<String> pList;

			@Value("#{${blog-top-links}}")
			private Map<String, String> topLinks;

			
			@Value("#{'${key}'.split(',')}")


		普通文件的读取
 ```
			从classpath下加载
			InputStream resourceAsStream = this.getClass().getClassLoader().getResourceAsStream("cer/nihao_dev.txt");
					InputStreamReader isr = new InputStreamReader(resourceAsStream);
					BufferedReader br = new BufferedReader(isr);
					String lineTxt = null;
					while ((lineTxt = br.readLine()) != null) {
						System.out.println(lineTxt);
					}
					br.close();
			}
			
			File in = new FileInputStream(file);  这个是直接路径加载。类似d盘某个路径
			
			/**获取文件路径*/
			private static String getRootPath() {
				String oriPath = DSGJ0001.class.getClassLoader().getResource("").getFile();
				if ("\\".equals(File.separator)) {
					oriPath = oriPath.substring(1, oriPath.length());
				} else if ("/".equals(File.separator)) {
					// linux
				}
				oriPath=oriPath.replace("%20", " ");
				return oriPath;
			}
 ```



11. @SpringBootApplication(exclude={a.class})排除自动配置的类，排除的类在spingboot-autoconfigure包中有
12. boot的自动配置原理：
		spingboot-autoconfigure，自动配置包的核心
		boot在进行springapplication对象实列化时会加载META-INF/spring.factories文件，将该配置文件中的配置加入到spring的容器中，这些bean也是jar引入进来的，各个bean，根据属性读取自动配置
		@conditonalonclass 和 @conditionalonmissingbean  类似的属于条件注解

		spring-boot-autoconfigure-2.0.0.RELEASE.jar 包下的自动配置 /META-INF/spring.factories，其中是加载自动配置项


13. 属性文件中debug=true  就可以查看详细的加载配置


14. 数据源加载
		DataSourceBuilder 和 JndiObjectFactoryBean

15. 分页插件
    目前的分页插件PagePlugin，也是网上随便copy的一份下来用的，对mapper有代码侵入，无法封装总页数
	分页插件的原理  物理和逻辑分页
	逻辑分页，利用游标分页，好处是所有数据库都统一，坏处就是效率低。 
	物理分页，数据库本身提供了分页方式，如mysql的limit，好处是效率高

    mybatis-plus(暂时没用)
        插件介绍	https://www.cnblogs.com/leeego-123/p/10734330.html

    boot原本配置
		mybatis:
			mapper-locations: classpath:mappers/*.xml
			 虽然可以配置这项来进行pojo包扫描，但我更倾向于在mapper.xml写全类名
			 type-aliases-package: com.rhine.blog.po     配置之后好像可以省略xml中的包名，<resultMap id="userMap" type="UserBean">

		plus插件的配置，但是需要排斥其他的mybatis依赖，在boot中
			<!-- 
			<dependency>
					<groupId>org.mybatis.spring.boot</groupId>
					<artifactId>mybatis-spring-boot-starter</artifactId>
					<version>1.3.2</version>
				</dependency>
			-->
		mybatis-plus:
		  mapper-locations: classpath:mappers/*.xml
		  type-aliases-package: com.rhine.blog.po

    pagehelper
     ```
            PageHelper.startPage(1,3);
            List<UserBean> byEmail = userMapper.findByEmail("100");//实际查询返回的是page对象，也是实现list接口的额，
            PageInfo page = new PageInfo(byEmail);
            long total = page.getTotal();

            <dependency>
                <groupId>com.github.pagehelper</groupId>
                <artifactId>pagehelper-spring-boot-starter</artifactId>
                <version>1.2.5</version>
                <exclusions>
                    <exclusion>
                        <groupId>org.mybatis.spring.boot</groupId>
                        <artifactId>mybatis-spring-boot-starter</artifactId>
                    </exclusion>
                </exclusions>
            </dependency>
            //分页时，实际返回的结果list类型是Page<E>，如果想取出分页信息，需要强制转换为Page<E>，
            //或者使用PageInfo类对结果进行包装，可以拿到多有的page属性
            //继承arraylist后，数据都是放在elementData数组中的,返回的page<e>就是一个数组，元素在elementData中（list中的数据组），
            PageInfo page = new PageInfo(list);
            Page<UserBean> byEmail = (Page)userMapper.findByEmail("100");
     ```    
        总结：PageHelper首先将前端传递的参数保存到page这个对象中，接着将page的副本存放入ThreadLoacl中，这样可以保证分页的时候，参数互不影响，接着利用了mybatis提供的拦截器，取得ThreadLocal的值，重新拼装分页SQL，完成分页。

        在threadlocal中设置分页参数，之后在查询的时候，获取当前线程中的分页参数，执行查询的时候通过拦截器再sql中添加分页参数，之后实现分页查询，查询结束后在finally语句中清除threadlocal中的查询参数

        原理：使用ThreadLocal来传递和保存Page对象，每次查询，都需要单独设置PageHelper.startPage()方法
        PageHelper.startPage()和查询方法连着用，实际就是拦截器再查询方法的时候，从线程变量中拿到分页信息组装的结果。

        实现原理过程
            1.在你要使用分页查询的时候，先使用PageHelper.startPage这样的语句在当前线程上下文中设置一个ThreadLocal变量，
            2.再利用mybatis提供的拦截器（插件）实现一个com.github.pagehelper.PageInterceptor接口，
            3.这个分页拦截器拦截到后会从ThreadLocal中拿到分页的信息，如果有分页信息，这进行分页查询，最后再把ThreadLocal中的东西清除掉。
            4.最后实在finally中清除的

        查询结果是page转对象问题
            使用pagehelper查询出对象是page对象，然后放入json中，如果取的时候是getString,然后用arrayList转会报错。除非放入限定好的对象中或者直接list<E>强转
            就是pagehelper查询出的page对象，放json中，然后用getString反转为对象就要注意，直接强转
        
    mybatis 分页插件
		MyBatis 3.4.1或者其以上版本(使用MyBatis 3.4.1(不包含)以下没有Integer.class)
		@Intercepts({ @Signature(type = StatementHandler.class, method = "prepare", args = { Connection.class，Interger.class}) })
        
    boot 2.0引入pagehelper
		1.pom引入pagehelper-spring-boot-starter
		2.属性文件配置
			#pagehelper
			pagehelper.helper-dialect=mysql
			pagehelper.reasonable=true							这个属性要注意，默认是false(超限返回空数据)，设置为true，页数超限就显示最后一页的内容
			pagehelper.support-methods-arguments=true
			pagehelper.params=count=countSql

    dao中引入了tk-mybatis，其中使用了3.4.5的mybatis版本。然后admin中引入的pagehelper和mybatis对应的是mybatis是3.5几的版本

16. SpringBootServletInitializer初始化servlet代替了web.xml


### 杂项纪录
1. AnnotationConfigApplicationContext,用于注解加载Spring的应用上下文，一般测试用，忽略
2. 搞懂了classpath指向的classes里放的东西，我们再来看看classpath: 和classpath*:的区别。
		1.classpath：只会到你的classes路径中查找找文件。
		2.classpath*：不仅会到classes路径，还包括jar文件中(classes路径)进行查找。所以即使直接的class下没有路径也不会启动报错，但是使用上面的会启动报错
3. 懒加载
 ```
     private static RequestConfig requestConfig = null;
        static
        {
            // 设置请求和传输超时时间
            requestConfig = RequestConfig.custom().setSocketTimeout(2000).setConnectTimeout(2000).build();
        }
 ```
4. 大型电商网站架构案例和技术架构【推荐】
	https://blog.csdn.net/jianai0602/article/details/80346837 

5. 对接接口的安全性，1、使用同一的token校验，2、增加ip白名单过滤，3、获取动态口令，优先时间60秒
6. 	job相关
	quartz相关
	使用Quartz做计划任务时，默认情况下，当前任务总会执行，无论前一个任务是否结束。  
    <property name="concurrent" value="false" /> 可以让Job顺序执行。 true可以让Job并行执行，而不用管上一个Job是否结束。

	时间梯度，总的来说就是定30,60,100规则穿，记录次数，10job一次，然后每次判断下次的时间点到没到，漏发的再补发一次就可以了

	实现job接口或者继承QuartzJobBean，系统job自动执行。
	context.getMergedJobDataMap().get(ScheduleConstants.TASK_PROPERTIES));
	可以使用这个属性将当前系统job绑定一个自定义的job，当系统执行的时候，然后通过绑定的job信息，执行对应的逻辑。支付中是直接将路劲放在库的trigger_name中的
	意思是通过绑定参数，封装执行的方法


	配置job
	启动加载进入内存
	统一的service中管理各个job，通过自定义job注解添加配置信息，然后启动加载进入系统即可。老版的是集中在xml中，新版的是集中代码注入
	LinKunJobConfig extends SchedulerFactoryBean  实现其中的registerJobsAndTriggers方法  最终setTriggers(triggers); super.registerJobsAndTriggers();
		//生成每个trigger，主要步骤，jobDetailFactory，cronTriggerFactory
		private CronTrigger registerCronJobTrigger(String methodName,LinKunJob linKunJob) throws Exception {
			String cronExpression = linKunJob.cronExpression();
			int jobType = linKunJob.jobType();
			String[] arguments = linKunJob.arguments();
			MethodInvokingJobDetailFactoryBean jobDetailFactory = new MethodInvokingJobDetailFactoryBean();
			jobDetailFactory.setTargetMethod(methodName);
			jobDetailFactory.setConcurrent(false);
			jobDetailFactory.setArguments(arguments);
			jobDetailFactory.setTargetObject(applicationContext.getBean("manualJobService"));
			jobDetailFactory.setName(methodName + "_detail_" + linKunJob.jobType());
			jobDetailFactory.afterPropertiesSet();
			CronTriggerFactoryBean cronTriggerFactory = new CronTriggerFactoryBean();
			cronTriggerFactory.setJobDetail(jobDetailFactory.getObject());
			cronTriggerFactory.setCronExpression(cronExpression);
			cronTriggerFactory.setName(methodName + "_trigger_" + linKunJob.jobType());
			cronTriggerFactory.afterPropertiesSet();
			return cronTriggerFactory.getObject();
		}
		
 	cron表达式
		0 0/3 20,23 * * ?” 	每天 20点至20:59 和 23点至 23:59分两个时间段内 每3min一次触发
		cron中 	?  	不指定值，用于处理天和星期天配置的冲突
				- 	指定时间区间
				/ 	指定时间间隔执行		
			
		"0 0 */3 * * ? *"      "* * 0/3 * * ? *" 注意* 是匹配任意。这里按时为界线,到了小时点，就按规则执行

	xxl-job相关
		最重要的两个部分：	1.执行器，一般是bean执行器，分散配置在各自的服务中，在spring的基础上，@XxlJob注入任务(将执行器的name和注册地址作为一对，放入了admin的地址list中) 
						  2.统一的调度中心，就是xxl-job-admin。
		当然可以定义一个通用的httpjobhander，然后配置多个任务附带不同的参数就可以了，也不行直接一个http的请求地址也行
		增加执行器后，admin增加配置，会有心跳检测，间隔一段时间就能连上。




7. 抽象类和接口
	类是对事物的抽象(抽象了属性和行为)，抽象类是对类的抽象，接口是对抽象类的抽象。
    抽象类可以定义一些默认行为，并促使子类提供任意特殊化行为。但是接口好像是全实现。
			子类继承抽象类必须实现其中抽象方法，除非子类为抽象类。
			抽象类就是可以把多个接口公用部分放在抽象类中，然后各子类在实现特性方法
			抽象类是为了代码的复用，而使用接口的动机是为了实现多态性。
			抽象类中  抽象方法必须子类实现，普通方法可选，但是加上final就不能重写了
			抽象实现特定，普通方法实现共性

	子类继承父类要重写父类的 抽象方法吗
	1. 普通类继承，并非一定要重写父类方法。
	2. 抽象类继承，如果子类也是一个抽象类，并不要求一定重写父类方法。如果子类不是抽象类，则要求子类一定要实现父类中的抽象方法。
	3. 接口类继承。如果是一个子接口，可以扩展父接口的方法；如果是一个子抽象类，可以部分或全部实现父接口的方法；如果子类不是抽象类，	则要求子类一定要实现父接口中定义的所有方法。


	当接口有多个实现类时，提供了@order注解实现自定义执行顺序，也可以实现Ordered接口来自定义顺序。(数字越小，优先级越高,)
	注意：也就是@Order(1)注解的类会在@Order(2)注解的类之前执行


8. xml解析
    xml 和java对象关系比较近的是xstream, 是java 对象和xml之间的一个双向转换器。
		xstream可以 别整dom xpath（复杂的xml处理模型
		xml 和 json都是数据交换的一种规范。
		web service中 xml用的比较多

	对于xml解析的实用类，XStream用的比较常用，//把xml为转换为实体对象 对于嵌套的xml内容使用内部类接收
		解析list
		实际获得的记录xml中的list
		<?xml version="1.0" encoding="utf-8"?>
		<ROOT>
			<RSP_CODE>00000</RSP_CODE>
			<LIST>
				<ROW><USER_ID></USER_ID></ROW>
				<ROW><USER_ID></USER_ID></ROW>
			</LIST>
			<SIGN_INFO>AAA==</SIGN_INFO>
		</ROOT>
			
		public static Object getObjectListFromXML(String xml, Class clazz,Class clazzt){
			XStream xStreamForResponseData = new XStream();
			xStreamForResponseData.alias("xml", clazz);
			xStreamForResponseData.alias("ROW", clazzt);
			xStreamForResponseData.ignoreUnknownElements();//忽略掉一些新增字段
			return xStreamForResponseData.fromXML(xml);
		}



9. java的可变参数
 ```
		public void print(String... args) {
			for (int i = 0; i < args.length; i++) {
				out.println(args[i]);
			}
		}
 ```
	
	int i=0;
	int i=i++;  最后值为0			
	JVM 在处理 i = i++; 时 , 会建立一个临时变量来接收 i++ 的值 , 然后返回这个临时变量的值 ,
	返回的值再被等号左边的变量接收了 , 这样就是说 i 虽然自增了但是又被赋值了0 , 这样输出的结果自然就是 0 了
	不妨我们用 temp 临时变量来接收 i++ 的值 , 来看一下结果 :
	int i = 0;
	int temp = i++; //temp的值是 : 0



10. Random rand = newRandom();：
	rand.nextInt(100);
	这行代码将生成范围[0, 100) 之间的随机数。

11. 默认的无参构造，会将所有的实例域设为默认值，如果定义了指定的构造函数，那么无参构造就没了

12. 内部类的两种创建方式：
	1、outer.inner p=new outer().new inner（）；
	2、outer.inner p=new outer.inner();    //静态内部类
	3、Outter outter = new Outter();
       Outter.Inner inner = outter.new Inner();  //必须通过Outter对象来创建
	4、局部内部类访问局部变量注意事项：
		局部内部类访问局部变量必须用final修饰，因为局部变量是栈中随方法的，调用玩就消失，而堆中难过的不会立刻消失	

	和外部类关系密切的，且不依赖外部类实例的，可以使用静态内部类。


13. String.format中是%s占位符，log中使用的是{}作为占位符

	一个字节等于8位  1byte = 8bit      int占用4个字节，long 8个字节，

14. 移动端的日志插件(忽略)
	 <script type="text/javascript" src="https://www.w3cways.com/demo/vconsole/vconsole.min.js?v=2.2.0">
	 <script>
			var vConsole = new VConsole();
	 </script>
	后面直接使用日志打印即可，移动端会有vconsole的显示
	try{
						
	}catch(err){
	   console.log(err)
	   console.log(err.message);
	}
15. jdk升级的tomcat问题:
			Tomcat 从7升级到8的时候出现了 java .lang.IllegalArgumentException: An inval id domain [.xxx.com] was specified for this cookie 
			在 tomcat context.xml中配置 <CookieProcessor className="org. apache .tomcat.util. http .LegacyCookieProcessor" />

16. 属性文件相关
		PropertiesConfiguration 快速读取属性文件，使用apache的PropertiesConfiguration接收
		  //先看看Properties
			String propertiesFileName="a.properties";
			Properties props = new Properties();
			props.load(new FileInputStream(propertiesFileName));
			String value =props.getProperties("key");

			//然后是PropertiesConfiguration
			PropertiesConfiguration propsConfig=new PropertiesConfiguration();
			propsConfig.setEncoding("UTF-8") //默认的编码格式是ISO-8859-1，所以才在读取文件之前先设置了编码格式
			propsConfig.load(propertiesFileName);
			String strValue=propsConfig.getString("key");
			String longValue=propsConfig.getLong("longKey");
			String[] strArray=propsConfig.getStringArray(arrayKey);
			//值得一提的是。propsConfig的默认分割符是','，换句话说，如果值使用','分割，使用getString去取的话是会抛出异常的，因为这被认为是个数组，分割符可以使用setListDelimiter设置。
			...
			三、总结
			告别java.util.Properties。
		
17. eclipse创建目录 https://www.cnblogs.com/yuyu666/p/10049954.html

	创建boot父工程起始就决定你是普通maven工程还是boot工程。是boot就直接父，普通就直接maven
	普通maven工程，子模块再继续


	简单概括，子模块用boot好处是目录和启动类直接ok，但是pom中的parent引用要变，这个改动小点。
	子模块用普通maven，好处是pom中的parent引用现成的，但是目录和启动类没有。

	建议创建聚合工程，都是用maven创建子模块。但是boot子模块启动目录和类没有
	子模块用boot，需要更新更改下parent引用
	如果是单独一个boot工程直接boot创建

	两种都可以
	起点普通mavenpom，就需要删除目录，复制引用(可以从子boot模块中复制)。
	起点是boot，pom工程，一步到位，

	这里其实也可以普通maven pom，然后子模块直接建boot，这样两个不是关联的，不存在jar的相互引用，就是boot不继承pom
		子模块不一定要继承parent，module聚合功能1.公用父依赖，2.整体打包

	方式1 
		1.建普通maven工程，删除无效目录，直接在父pom中引入spring-boot-starter-parent。  #需要删除手工目录
			File --> New --> Project --> Maven --> Next --> 填写包路径，项目名称 --> Next --> 修改pom.xml文件
			更改为pom工程
		2.创建其他module(修改pom继承父pom)
		
	方式2
		1.直接建boot父工程，只建一个pom.xml不需要其他的目录    							#目录结构不需要变
		2.创建其他module(修改pom继承父pom)												
		
	maven modules
	　　从字面意思来说，module就是模块，而pom.xml中的modules也正是这个意思，用来管理同个项目中的各个模块；如果maven用的比较简单，或者说项目的模块在pom.xml没进行划分，那么此元素是用不到的；不过一般大一点的项目是要用到的。
	　　1.需求场景
	　　　　如果我们的项目分成了好几个模块，那么我们构建的时候是不是有几个模块就需要构建几次了（到每个模块的目录下执行mvn命令）？当然，你逐个构建没问题，但是非要这么麻烦的一个一个的构建吗，那么简单的做法就是使用聚合，一次构建全部模块。
	　　2.具体实现
	　　　　a.既然使用聚合，那么就需要一个聚合的载体，先创建一个普通的maven项目account-aggregator,
	　　　　因为是个聚合体，仅仅负责聚合其他模块，那么就只需要上述目录，该删除的就删了；注意的是pom文件的书写（红色标明的）：

		子模块中不一定要parent继承，这是eclipse默认补全的，不是必须的。

18. 常用的工具类
	ResourceUtils，IOUtils	
	Kaptcha  一个可配置的实用验证码生成工具
	联系我们中的地图   使用的是百度地图的开放api
	Pattern类  url路径匹配工具类

	比较常用的工具类
		apache commons ，google guava, joda time，fastjson
		HttpClient，工具类现在已 经从 Apache Commons 移到 Apache HttpComponents 中，并且包名被改为 org apache.http
		PropertyUtils 其和 BeanUtils 功能几乎一致 不同的是 BeanUtil 在对Bean 赋值时会进行自动类型转化，只要属性名相同，类型会尝试转换，而 PropertyUtil会报错
		httpClient 是使用HttpEntity来现的 常用的几个 httpEntity:UrlEncodedFormEntity,MultipartFormEntity,StringEntiry

	httpclient操作
		DefaultHttpClient client = new DefaultHttpClient();
		client.getParams().setParameter("http.protocol.content-charset","UTF-8");
		HttpPost httpPost = new HttpPost(url);
		JSONObject jsonObject = null;
			
		//建立一个NameValuePair数组，用于存储欲传送的参数	
		List<NameValuePair> params = new ArrayList<NameValuePair>();
		params.add(new BasicNameValuePair("name", "zhangsan"));
		// 添加参数,设置编码
		//httpPost.addHeader("Content-Type", "application/json");
		httpPost.setEntity(new UrlEncodedFormEntity(params, HTTP.UTF_8));
		HttpResponse response = client.execute(httpPost);
		int statusCode = response.getStatusLine().getStatusCode();
		if (statusCode == 200) {
			// Read the response body
			String body = EntityUtils.toString(response.getEntity());
			jsonObject = JSONArray.parseObject(body);
		}

	Java字符串用\\表示\
		AntPathMatcher是URLs匹配工具类



19. javap签名 (忽略)
	javap -s a.class 这里常出现的问题就是jar版本不一致导致的方法变更
	
	Boolean 比较特殊, 对应的是 Z ， Long 对应J
　　引用数据类型：比较麻烦点，以“L”开头，以“；”结束，中间对应的是该类型的路径

       如：	String ： Ljava/lang/String；
			Object： Ljava/lang/Object；
       自定义类 Cat  对应  package com.duicky;
              Cat ： Lcom/duicky/Cat；

　　数组表示：  数组表示的时候以“[” 为标志，一个“[”表示一维数组
       如：int [] ：[I
           Long[][]  ： [[J
           Object[][][] ： [[[Ljava/lang/Object；

20. 在notepad++中勾选正则表达式，替换首尾字符，     ^/$->'/',

21. return null;  和	return;
	一个是有返回值的return  还有一个是void的返回结束

22. Websocket 电签  上传图片
	Websocket之前， long poll 和 ajax轮询。  服务端能主动调用客户端
	程序设计中，这种设计叫做回调
	1.前段开启连接，需要带上userid。前端会将session传过去，通过参数绑定唯一的userid
	2.后端配置WebSocketServer，通过onOpen将session和userid绑定。WebSocketServer中奖session和userid绑定。
	3.发送消息就调用对应的server发消息

	打开websocket连接开启,生成二维码，扫码跳转地址，打开另一个websocket连接(和第一个同参数，但是不同session)，签名发送消息，前端接收。

	引入jquery.qrcode.min.js插件，然后直接调用即可
	$('#qrcode').qrcode({
			render: 'canvas', //table,canvas方式
			width: 120, //宽度
			height:120, //高度
			text: "http://www.runoob.com" //二维码内容
		});

	  手写功能：
	  jSignature.js  然后var $sigdiv = $("#signature").jSignature({'UndoButton':true});初始化插件即可
	  
	  
	  函数放script中可以直接执行，比如alert 和 bind等
	  $(document).ready(function() {}

	List tempList = upload.parseRequest(request);
	InputStream is = item.getInputStream();
	然后outstream输出即可
		指令重排也是有限制的，即不会出现下面的顺序，进行重排时候，必须考虑到指令之间的数据依赖性
		
		编译期重排序的典型就是通过调整指令顺序，做到在不改变程序语义的前提下，尽可能减少寄存器的读取、存储次数，充分复用寄存器的存储值。
			只要程序的最终结果等同于他在严格的顺序化环境中执行的结果那么上诉的所有行为就是被允许的。

23. 跨域相关		
	https://blog.csdn.net/itcats_cn/article/details/82318092
	跨域问题是针对JS和ajax的，html本身没有跨域问题
	JavaScript的"同源策略"，即只有 协议+主机名+端口号 (如存在)相同
	请注意：localhost和127.0.0.1虽然都指向本机，但也属于跨域。
	1、响应头添加Header允许访问											类似文件 CorsFilter，后端filter中设置设置res.setHeader("Access-Control-Allow-Origin", "*");
	2、jsonp 只支持get请求不支持post请求
	3、httpClient内部转发
	4、使用接口网关——nginx、springcloud zuul   (互联网公司常规解决方案)     同域名访问，用nginx转发请求
	
	在前后分离的架构下，跨域问题难免会遇见比如，站点 http://domain-a.com 的某 HTML 页面通过  的 src 请求 http://domain-b.com/image.jpg。网络上的许多页面都会加载来自不同域的CSS样式表，图像和脚本等资源。

	出于安全原因，浏览器限制从脚本内发起的跨源HTTP请求。 例如，XMLHttpRequest和Fetch API遵循同源策略。 这意味着使用这些API的Web应用程序只能从加载应用程序的同一个域请求HTTP资源，除非使用CORS头文件。
	
	@crossorigin可以针对单个的路径实现，要求Spring4.2及以上的版本

	公司在几年前就采用了前后端分离的开发模式，前端所有请求都使用ajax
	传统结构项目中，shiro从cookie中读取sessionId以此来维持会话，在前后端分离的项目中（也可在移动APP项目使用），我们选择在ajax的请求头中传递sessionId，


24. 当天时间
 ```
		Calendar calendar = Calendar.getInstance();
		calendar.setTime(new Date());
		calendar.set(Calendar.HOUR_OF_DAY, 0);
		calendar.set(Calendar.MINUTE, 0);
		calendar.set(Calendar.SECOND, 0);
		Date zero = calendar.getTime();
			
		Calendar.HOUR_OF_DAY是24小时制
		Calendar.HOUR是12小时制
		所以下面方法是结果是不同的
		calendar.set(Calendar.HOUR_OF_DAY, 23); ?输出日期?2017-04-13 23:07:02
		calendar.set(Calendar.HOUR, 23); ?输出日期2017-04-13 11:07:02
 ```
25. mybatis-plus  tkmybatis不同的快捷框架吧
	sitemesh的设计思想是装饰者(decorator)设计模式。SiteMesh使用一个Servlet过滤器，它可以拦截返回的Web浏览器的HTML，提取相关内容，并将其合并到被称为装饰器（Decorator）的模板。

	装饰器模式可以动态的把新的职责添加到对象上。这里关键点是“动态”，也就是运行时；而继承在编译的时候已经确定了。没啥意思   io是装饰模式

26. boot本地运行
		ROOTPATH = System.getProperty("user.dir");
		C:\Users\xiaoyuer\git\xye-netpay\xye-netpay-pom\xye-netpay-boot
		之前是获取类加载路径

	类加载路径
		Test.class.getClassLoader().getResource("")=Test.class.getResource("/")
		ClassLoader.getResource的path中不能以/开头，path是默认是从ClassPath根目录下进行读取的否则读取为null
		Class.getResource(String path)		path不以’/'开头时，默认是从此类所在的包下取资源；path以’/'开头时，则是从ClassPath根下获取；	
		getResourceAsStream  这个读取的是流文件

27. AxureRP文件将resource下的crx文件rar格式解压，然后对应插件中开发者模式加载目录，即可访问index页面

28. js前段编码
		encodeURI()，用来encode整个URL，不会对下列字符进行编码：+ : / ; ?&。它只会对汉语等特殊字符进行编码。针对访问路径，
		url = 'www.xxx.com/aaa/bbb.do?parm1=罗'
			
		encodeURIComponent ()，用来enode URL中想要传输的字符串，它会对所有url敏感字符进行encode。针对参数param
		url = 'www.xxx.com/aaa/bbb.do?parm1=www.xxx.com/ccc/ddd?param=abcd'	

29. 小程序登录相关信息返回
		   String url = "https://api.weixin.qq.com/sns/jscode2session?appid=" + appId + "&secret=" + appSecrect + "&js_code=" + wmpcode + "&grant_type=authorization_code";
           resultStr = HttpClientUtil.httpGet(url);		

30. 字符串比较  String s4 = s3+",world!";  s3+=",world!"; 类似  变量引用会开新地址

31. 网络带宽
	10M的宽带的带宽是1280KB/s。
	ISP提供的线路带宽使用的单位是比特（bit），而一般下载软件显示的是字节（Byte）（1Byte=8bit），所以要通过换算，才能得实际值。
	1Mb/s=1024Kb/s=1024/8KB/s=128KB/s  
	上行宽带(速度)和下行宽带(速度)是不对称的，一般是下行速度大于上行的速度。我们平时所使用的宽带说多少M，都是指的下行宽带，
	
	8位是一个字节，8bit=1byte,一位就是二进制数的一个数字。byte类型的数据是8位带符号的二进制数

	媒体类型
		MediaType,即是Internet Media Type,互联网媒体类型；也叫做MIME类型， 
		在Http协议消息头中，使用Content-Type来表示具体请求中的媒体类型信息。（推荐使用这个，下二）
		常见的媒体格式类型如下
		text/html:HTML格式
		text/xml:XML格式

		以application开头的媒体格式类型：
			application/xml:XML数据格式
			application/json:JSON数据格式
			application/octet-stream:二进制流数据（常见的文件下载)
			application/x-www-form-urlencoded:表单中默认的encType,表单数据被编码为key/value格式发送到服务器

		另外一种常见的媒体格式是上传文件时使用：
		multipart/form-data:需要在表单中进行文件上传时，就需要使用该格式
		
		前段页面中的network中的doc类型  xhr类型(XMLHttpRequest)
		它依赖的是现有的CSS/HTML/Javascript，而其中最核心的依赖是浏览器提供的XMLHttpRequest对象，是这个对象使得浏览器可以发出HTTP请求与接收HTTP响应。
		总结两者的关系：我们使用XMLHttpRequest对象来发送一个Ajax请求

	HttpRequest中常见的四种ContentType
		客户端发起 HTTP POST/PUT 请求时，可以指定Request Header 的 Content-Type，表示向服务端发送的 Request Body 中的数据的格式
		服务端返回数据时，也可以指定Content-Type，表示返回数据的格式

			HTTP 请求分为三个部分：状态行、请求头、消息主体。
			服务端通常是根据请求头（headers）中的 Content-Type 字段来获知请求中的消息主体是用何种方式编码，再对主体进行解析。
			POST 提交数据方案，包含了 Content-Type 和消息主体编码方式两部分。
		<method> <request-URL> <version>
		<headers>
		<entity-body>
		===============
		POST http://www.example.com HTTP/1.1
		Content-Type: application/x-www-form-urlencoded;charset=utf-8
		title=test&sub%5B%5D=1&sub%5B%5D=2&sub%5B%5D=3
		
		1.application/x-www-form-urlencoded	
			浏览器的原生 form 表单,不设置 enctype 属性,默认属性
			浏览器原生支持
		2.multipart/form-data
			一个常见的 POST 数据提交的方式。我们使用表单上传文件时，必须让 form 的 enctyped 等于这个值
			浏览器原生支持
		3.application/json
			低版本 IE 之外的各大浏览器都原生支持 JSON.stringify
			直接提交json串
			POST http://www.example.com HTTP/1.1
			Content-Type: application/json;charset=utf-8
			{"title":"test","sub":[1,2,3]}
			当时我是把 JSON 字符串作为 val，仍然放在键值对里，以 x-www-form-urlencoded 方式提交。(这种就有点old了)
		4.text/xml
			一般不用，没有json灵活







32. 字节长度转换
		注意文件长度是字节长度，不是位长度
		byte[] bytes = string.getBytes("GBK");
		StringBuilder sb = new StringBuilder(minLength);	//执行字节长度
		for (int i = bytes.length; i < minLength; i++) {sb.append(padChar);}


## shiro相关
		*****
		主要的就是shirofilter  securitymanager，和realm(AuthorizingRealm )。
		*****

		https://www.cnblogs.com/yoohot/p/6085830.html   讲解的是shiro的各filter用法
			 
		一般通过继承EnterpriseCacheSessionDAO实现sessiondao的操作，这个是用来实现session的持久化。用来自定义session处理的，也可以用默认的
		有doCreate”、“doReadSession”、“doUpdate”和“doDelete”。其中只有doCreate是实现的，其它的都是没有实现的方法。
		
		
		不过作为前后端分离项目,用户的信息及过期权限等信息依然是靠后端存储,以上依然涉及session,只不过是将产生的jsessionid当作token使用,使用redis存储而已.可以考虑使用jwt,彻底是后端无状态化;

		ThreadPoolExecutor是jdk中的线程池类
		ThreadPoolTaskExecutor这个类则是spring包下的，是sring为我们提供的线程池类
		
		@Override
		protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException {
		…
		SimpleAuthenticationInfo authenticationInfo = new SimpleAuthenticationInfo(loginUser,password,salt,getName());
		return authenticationInfo;  //这里返回的就是shiro中的principal

		也可以使用filterChainDefinitionMap配置权限
		
		shiro注解
			ShiroFilterFactoryBean 中配置相关的拦截配置(但如果接口多，每个接口url都要写一遍太麻烦。所以采用注解的方式，在每个controller方法上加注解。)

		
			/**
			 * 开启Shiro的注解(如@RequiresRoles,@RequiresPermissions),需借助SpringAOP扫描使用Shiro注解的类,并在必要时进行安全逻辑验证
			 * 配置以下两个bean(DefaultAdvisorAutoProxyCreator(可选 depends-on="lifecycleBeanPostProcessor" )和AuthorizationAttributeSourceAdvisor)即可实现此功能
			 * @return

			 
			 开启注解 DefaultAdvisorAutoProxyCreator 和 AuthorizationAttributeSourceAdvisor

		shiro——rememberme	 
			 
			shiro中使用remenberme中 boolen类型，true会在页面写一个cookie(remenberme)，value是经过加密存放的是用户的信息
			cookieRememberMeManager.setCipherKey(Base64.decode("fCq+/xW488hMTCD+cmJ3aQ=="));这个是内部加密用的key，会用这个key加密principal(SimpleAuthenticationInfo),回写到cookie中


			*****shiro会在每一次访问时都会创建一个subject，这是源码中有，并且绑定了线程变量*****
			DefaultSecurityManager.createSubject在创建subejct的时候就会调用resolvrPrincipals方法，
			这个当前方法内部会先从当前的session中获得的subject的principal，如果没有找到再从cookie找，调用的方法是getRememberedInedtity

	 
		 
		必须全部符合（默认不写或者在后面添加logical = Logical.AND）
		@RequiresPermissions(value={“stuMan:find_record_list”,“tea:find_record_list”})
		上面这种情况是默认当前对象必须同时全部拥有指定权限
		符合其中一个即可(logical = Logical.OR)    
		 
		 
		doGetAuthorizationInfo方法(封装了对应的权限内容)
		System.out.println("经试验：并不是每次调用接口就会执行，而是调用需要操作码（permission）的接口就会执行");
		
		shiro的菜单通配部分
		shiro的注解配置

		Subject currentUser = SecurityUtils.getSubject();
		
		currentUser.getprincipal实际上就是当时 SimpleAuthenticationInfo info = new SimpleAuthenticationInfo(user, password, getName());  中的这个存入的user对象
		
		暂时看是从session中拿到DelegatingSubject.RUN_AS_PRINCIPALS_SESSION_KEY作为key的value，那么还是从session中拿到的缓存的principal信息
		
		
		try {
			//在调用了login方法后,SecurityManager会收到AuthenticationToken,并将其发送给已配置的Realm执行必须的认证检查
			//每个Realm都能在必要时对提交的AuthenticationTokens作出反应
			//所以这一步在调用login(token)方法时,它会走到MyRealm.doGetAuthenticationInfo()
		
		
		shiro强大的自定义访问控制拦截器：AccessControlFilter，
		isAccessAllowed：表示是否允许访问；mappedValue就是[urls]配置中拦截器参数部分，如果允许访问返回true，否则false；
		onAccessDenied：表示当访问拒绝时是否已经处理了；如果返回true表示需要继续处理；如果返回false表示该拦截器实例已经处理了，将直接返回即可。基本上到这就重定向
		onPreHandle：会自动调用这两个方法决定是否继续处理；

		isAccessAllowed和onAccessDenied方法会影响到onPreHandle方法，而onPreHandle方法会影响到preHandle方法，而preHandle方法会达到控制filter链是否执行下去的效果。
		
		如果使用PathMatchingFilter就是接是onPreHandle方法走。
		
		WebUtils.issueRedirect(request, response, loginUrl)
		
		onlineSessionfilter 可以用来判断是否满足登录，syncOnlineSessionfilter用来接着同步操作
		
	 
		AuthorizingRealm 中的ispermitted方法可以debug一下
	 
		@RequiresPermissions  会拦截标签，分发到对应的PermissionAnnotationHandler。
		shiro:hasPermission  是好像直接访问到了AuthorizingRealm中的isPermitted，没有走controller的拦截handler
	 	真正的拦截规则是AuthorizingRealm.isPermitted>>>>>>>>>>org.apache.shiro.authz.permission.WildcardPermission#implies
	 
	 
	*****shiro的核心匹配机制*****
	public boolean implies(Permission p) {
			if (!(p instanceof WildcardPermission)) {
				return false;
			} else {
				WildcardPermission wp = (WildcardPermission)p;
				List<Set<String>> otherParts = wp.getParts();
				int i = 0;

				for(Iterator var5 = otherParts.iterator(); var5.hasNext(); ++i) {
				同级别比完，拥有的权限短路径，后面全匹配    用的的是a/c  两级权限，访问的是的三级路径,直接过？不是直接过，前面需要都匹配上才行
					Set<String> otherPart = (Set)var5.next();
					if (this.getParts().size() - 1 < i) {
						return true;
					}
					//同级别比较
					Set<String> part = (Set)this.getParts().get(i);
					if (!part.contains("*") && !part.containsAll(otherPart)) {
						return false;
					}
				}

				比完之后，拥有的路径长，待匹配的短，那么后一位需要时*
				while(i < this.getParts().size()) {
					Set<String> part = (Set)this.getParts().get(i);
					if (!part.contains("*")) {
						return false;
					}
					++i;
				}
				return true;
			}
		}
	 
	权限鉴权
		只有第一次会将信息存入缓存，通过权限过滤，
		其中的路径匹配可以再看看  在org.apache.shiro.authz.permission.WildcardPermission#implies 方法中
		权限的分隔划分，以:划分一个权限的匹配，源码操作
				 
	 
	shiro-页面标签
		使用shiro注解，会还是会使用securityManager.isPermitted方法，最终进入AuthorizingRealm.isPermitted方法，执行同controller进入的匹配方法
		延伸到时html页面
			 thymeleaf中使用shiro:hasPermission标签控制页面显示需要：
			 thymeleaf-extras-shiro
			 或者命名空间  xmlns:shiro="http://www.thymeleaf.org/thymeleaf-extras-shiro"
			 
			 配置一个ShiroDialect的bean
		在freemarker中
			引入shiro-freemarker-tags，页面 使用<@shiro.hasPermission name="权限添加">  
		在jsp中
			在页面顶部引用<%@taglib prefix="shiro" uri="http://shiro.apache.org/tags" %> 标签库，
			页面使用<shiro:hasPermission name="1111">  
	 
		shiro-session
			sessionFactory是创建会话的工厂，根据相应的Subject上下文信息来创建会话；默认提供了SimpleSessionFactory用来创建SimpleSession会话。
			更具需要也可以自钉子新的OnlineSession，搭配自定义 OnlineSessionFactory。实现session的内容增加

			其实这两个都可以使用默认的配置，即不持久化session也不自定义session
			SessionFactory中创建的session实体，Sessiondao操作中是创建了一个sessionid并赋值给当前的session
			 
			顺序是先实例化自定义的session，然后通过sessiondao创建sessionid赋值给对应的session

	
		主站关闭浏览器后的cookie还在吗  rememberme的操作，测试主站的记住我
		kickout使用了cache和Deque队列实现，返回subject.logout退出，然后重定向登录
		WebUtils.issueRedirect(request, response, kickoutUrl);
		deque.push(sessionId);
		cache.put(loginName, deque);// 将用户的sessionId队列缓存
					
		kickoutSession.setAttribute("kickout", true);设置踢出属性，然后判断当前的session，重定向			
		
		这个也可以
		   public RedisCacheManager cacheManager() {
			RedisCacheManager redisCacheManager = new RedisCacheManager();
			redisCacheManager.setRedisManager(redisManager());
			return redisCacheManager;
		}		
		
		使用冒号分隔的权限表达式是org.apache.shiro.authz.permission.WildcardPermission 默认支持的实现方式。这里分别代表了 资源类型：操作：资源ID  




## Springcloud
1. ribbon和feign的区别（转）
		spring cloud的Netflix中提供了两个组件实现软负载均衡调用：ribbon和feign。

		Ribbon
		是一个基于 HTTP 和 TCP 客户端的负载均衡器
		它可以在客户端配置 ribbonServerList（服务端列表），然后轮询请求以实现均衡负载。

		Feign
		Spring Cloud Netflix 的微服务都是以 HTTP 接口的形式暴露的，所以可以用 Apache 的 HttpClient 或 Spring 的 RestTemplate 去调用，
		而 Feign 是一个使用起来更加方便的 HTTP 客戶端，使用起来就像是调用自身工程的方法，而感觉不到是调用远程方法。

		String path = request.getSession().getServletContext().getRealPath("");    #直接砸到了/usr/local/tomcat/webapps/xye-netpay

		@SpringCloudApplication包含了
			@SpringBootApplication
			@EnableDiscoveryClient
			@EnableCircuitBreaker
			hystrix 继承的方式?
		
		cloud 问题记录  https://blog.csdn.net/uotail/article/details/84673347

2.  Nginx和Ribbon应用场景的区别：
		服务器端负载均衡 Nginx
		nginx 是客户端所有请求统一交给 nginx，由 nginx 进行实现负载均衡请求转发，属于服务器端负载均衡。
		既请求由 nginx 服务器端进行转发。

		客户端负载均衡 Ribbon
		Ribbon 是从 eureka 注册中心服务器端上获取服务注册信息列表，缓存到本地，然后在本地实现轮询负载均衡策略。
		既在客户端实现负载均衡。

		Nginx 适合于服务器端实现负载均衡 比如 Tomcat ，
		Ribbon 适合与在微服务中 RPC 远程调用实现本地服务负载均衡，比如 Dubbo、SpringCloud 中都是采用本地负载均衡。

## 加密传输
    公私钥，公钥是钥匙，私钥是锁
1. https的传输使用的是证书，证书之间传递相当于加密了一个公用的私钥(用于信息传输),相关的配置是tomcat和nginx的使用

    1.客户端发送自己支持的加密规则给服务器，代表告诉服务器要进行连接了
	2.服务器从中选出一套加密算法和hash算法以及自己的身份信息(地址等)以证书的形式发送给浏览器，证书中包含服务器信息，加密公钥，证书的办法机构
	3.客户端收到网站的证书之后要做下面的事情： 
		验证证书的合法性
		如果验证通过证书，浏览器会生成一串随机数，并用证书中的公钥进行加密
		用约定好的hash算法计算握手消息，然后用生成的密钥进行加密，然后一起发送给服务器
	4.服务器接收到客户端传送来的信息，要求下面的事情： 
		用私钥解析出密码，，用密码解析握手消息，验证hash值是否和浏览器发来的一致
		使用密钥加密消息，回送
	5.如果计算法hash值一致，握手成功


    访问案例：
        1.小明访问XX，XX将自己的证书给到小明（其实是给到浏览器，小明不会有感知）
        2.浏览器从证书中拿到XX的公钥A
        3.浏览器生成一个只有自己知道的对称密钥B，用公钥A加密，并传给XX（其实是有协商的过程，这里为了便于理解先简化）
        4.XX通过私钥解密，拿到对称密钥B
        5.浏览器、XX 之后的数据通信，都用密钥B进行加密



    ca证书就是对两者之间的传输key进行了加密，确保两者之间的传输key的安全性，这个证书其实就是公钥，认证加密后的公钥，证书中包含了很多信息，最重要的是申请者的公钥，有了这个公钥之后，就可以解密证书，拿到发送方的公钥，然后解密发送方发过来的签名，获取摘要，重新计算摘要
	CA机构在给公钥加密时，用的是一个统一的密钥对，在加密公钥时，用的是其中的私钥，所以ca证书就是ca机构的密钥对中的公钥，ca机构的私钥对发送方的公钥加密。



    下载完ssl相关的内容，其中包含了各个web服务器的证书，比如ningx和tomcat相关的
    使用OPENSSL 命令行来生成 KEY+CSR2 个文件，Tomcat，JBoss，Resin 等使用 KEYTOOL 来生成 JKS 和 CSR 文件

    tomcat中加了https安全证书转换的，post请求都要是https请求
 ```
    <Connector SSLEnabled="true" clientAuth="false" keystoreFile="d:\tomcat.keystore" keystorePass="123456" maxThreads="150" port="9443" protocol="org.apache.coyote.http11.Http11Protocol" scheme="https" secure="true" sslProtocol="TLS"/>
 ```

    https相关
		生产上的tomcat是没有配置ssl的，都是nginx端配置的https，所以请求实际上都是在http上存入缓存

		https请求过程
			1.客户端向服务器端发送请求，将客户端的功能和首选项传送给服务器端，包括客端支持的 SSL 本、加密组件列表等
			2.服务器端发送选择的连接参数（从客户端加密组件中筛选出的加密组件内容和压缩方法）以及证书（包含公钥等信息、）给客户端
			3.客户端读取证书中的所有人、有效期等信息并进行校验，然后通过预置的 CA 验证证书合法性，有问题 提示
			4.客户端生成用于数据加密的对称密钥，然后用服务器的公钥进行加密井发送给服务器端
			5.服务器端使用自己的私钥解密数据， 获得用于数据加密的对称密钥
			6.安全的通道建立完毕，后续基于对称加密算法传输数据

		ssl网址		https://myssl.com/   可以查看xiaoyuer.com的https的证书相关







2. 用约定好的HASH方式（如md5），把握手消息取HASH值，  然后将“握手消息+握手消息HASH值(签名)”  并一起发送给服务端
    使用加密签名的方式，用于验证握手消息在传输过程中没有被篡改过。
    这样就完成了一次请求，后续是用公用的随机key使用对称加密算法进行加密即可

3. 	对称加密：加密数据用的密钥，跟解密数据用的密钥是一样的。
		优点在于加解密效率比较高。
        缺点在于，数据发送方、数据接收方需要协商、共享同一把密钥，并确保密钥不泄露给其他人。
       
	非对称加密：加密数据用的密钥（公钥），跟解密数据用的密钥（私钥）是不一样的。
		私钥能解开公钥加密的数据，但忽略了一点，私钥加密的数据，同样可以用公钥解密出来（公钥是公开的，那么由服务器-》客户端的就存在安全隐患）



## git相关，等工具使用
1. cherry pick 的挑选分支commit，需要同源挑选，不然会出现冲突
	git cherry-pick <commit id＞可以选择某个分支中的一个或几个commit(s）来进行操作

2. git ls-files -v | grep "^[a-z]"   找出   git 中的 assume-unchanged 的文件(忽略)

3. fork：在github页面，点击fork按钮，将别人的仓库复制一份到自己的仓库。
   clone：直接将github中的仓库克隆到自己本地电脑中						clone别人是无法改动提交的，因为没有权限
	pull request的作用
	在A的仓库中fork项目B （此时我们自己的github就有一个一模一样的仓库B，但是URL不同）将我们修改的代码push到自己github中的仓库B中pull request ，源头url仓库就会收到请求，并决定要不要接受你的代码
	
	两个分支针对同源都做了更改，合并的时候就会出问题
	冲突merge之后，就会标记没有变动，重复merge之后没变化
	merge可以提现时间线，rebase是重新设基会覆盖时间线。
	
	永远不要在所有人都在的公共开发分支上做 rebase 操作。一般情况下在临时分支上是需要 rebase 主分支代码的，而 merge 则主要用在主分支上将临时分支的代码合并过来，然后就可以删除临时分支了。暂时也不使用，先过。

	
## jvm相关
1. 程序计数器：当前线程执行的字节码行号指示器
		jvm的多线程是通过线程轮流切换并分配处理器执行时间的的方式实现的，任何时刻，一个处理器只会执行一条线程指令。为了切换后恢复正确的执行位置，每条线程需要独立的程序计数器。
		这类内存区域称为“线程私有”的内存

2. 	java虚拟机栈：是线程私有的，生命周期与线程相同
		是虚拟机中局部变量的表部分，所需的内存空间在编译时期完成分配，方法运行时期不会改变大小，存放了编译器可知的各种基本数据类型，对象引用和returnadress类型（指向了一条字节码指令的地址）
		这个区域的两种异常情况：
			1.当线程请求的栈深度大于jvm允许的深度，抛出stackoverflowError	递归调用会出错
			2.如果jvm动态扩展时无法申请到足够的内存时会抛出outOfMemoryError   经常的编译class文件的内存不够
		使用-Xss配置栈内存容量，可以减少栈内存容量
		定义大量的本地变量，可增加次方法帧中本地变量表的长度
		
		在单个线程下，无论是由于栈帧太大，还是虚拟机栈容量太小，当内存无法分配的时候，虚拟机抛出的都是stackOverflowError
			
	
3. 本地方法栈(stack)：
		虚拟机栈为虚拟机执行java方法（也就是字节码）服务
		本地方法栈为虚拟机使用到的native方法服务
		
4. java堆(heap)：
		是jvm中所管理内存中最大的一块，是所有线程共享的内存区域，jvm启动时创建。用来存放对象实例。
		所有对象的实例都要在堆上分配
		java堆是垃圾收集器管理的主要区域，因此也被称为gc堆。现在的收集器基本采用的是分代手机算法（根据对象存活周期的不同，将内存划分成为几个区域），所有java堆中还可以细分为：新生代（MinorGC）和老年代（MajorGC）
		目前主流的虚拟机都是按照可扩展来实现的（通过-Xmx 和-Xms控制），如果堆中没有内存完成实例分配，并且堆也无法再扩展时，将抛出OutOfMemoryError异常
		将堆的最小值-Xms参数和最大值-Xmx参数设置一样可避免堆自动扩展，增加无效的fullgc，浪费时间，即不可扩展
		
		堆中有eden，survivor，和old三个区域，非堆中有code cache和 perm gen
		
5. 方法区：
		存放class相关信息，如类名、访问修饰符、常量池、字段描述、方法描述
		各线程共享的内存区域，用于存放已被jvm加载的类信息、常量、静态变量、即是编译器编译后的代码等数据。别名Non-Heap(非堆)。区别于堆内存heap
		可选择固定大小或可扩展，该区域内存回收目标主要是针对常量池的回收和对类型的卸载，
		当方法区无法满足内存分配需求时，将抛出outOfMemoryError		PermGen space
		MaxPermSize，最大方法区容量
		1.8之后移除，-XX:PermSize，使用元空间(Metaspace)代替
		-XX:permSize 和 -XX:MaxPermSize 配置大小
        方法区用于存放 Class 相关信息，需要足够大内存的方法区用于保证动态生成的Class可以加载入内存

         方法区（永久代）： 永久代的回收有两种：常量池中的常量，无用的类信息，常量的回收很简单，没有引用了就可以被回收。
         对于无用的类进行回收，必须保证 3 点：
            1. 类的所有实例都已经被回收
            2. 加载类的 ClassLoader 已经被回收
            3. 类对象的 Class 对象没有被引用（即没有通过反射引用该类的地

	
6. 运行时常量池
		属于方法区的一部分，在类加载之后，存放到方法区的运行时常量池中
		
7. 直接内存 	direct memory  
		分配不会受到java堆大小的限制，配置内存容易忽略这块，导致超过物理内存限制，从而导致动态扩展时出现OutOfMemoryError异常
		比如大量的nio操作

8. 内存溢出
    java堆的溢出
		内存映像分析工具分析
		1、内存泄漏			泄漏对象垃圾收集器无法自动回收，
		2、内存溢出			内存中对象必须存活，调节虚拟机的堆参数的配置
	
		内存溢出就是你要求分配的内存超出了系统能给你的，系统不能满足需求，于是产生溢出。

		Java内存泄漏就是没有及时清理内存垃圾，导致系统无法再给你提供内存资源（内存资源耗尽）。
			1.Java内存泄露是说程序逻辑问题,造成申请的内存无法释放.这样的话无论多少内存,早晚都会被占用光的. 最简单的例子就是死循环了.
			2.Java内存泄漏是指在堆上分配的内存没有被释放，从而失去对其控制。这样会造成程序能使用的内存越来越少。

	栈内存溢出：
		每个线程分配到的栈容量越大，可以建立的线程数量自然越少，建立线程时就越容易吧剩下的内存耗尽，
		如果是建立过多线程导致的内存溢出，在不能减少线程数量情况下，只能通过减少最大堆和减少栈容量来换取更多的线程。


    
    内存溢出：	
        第一种OutOfMemoryError： PermGen space   永久区内存溢出(非堆内存溢出) 
            永久保存区域是存放class信息和meta信息，分配了后，jvm是不会去回收的
            发生这种问题的原意是程序中使用了大量的jar或class，使java虚拟机装载类的空间不够，与Permanent Generation space有关。
            
            解决这类问题有以下两种办法：
                1. 增加java虚拟机中的XX:PermSize和XX:MaxPermSize参数的大小，前者是初始永久保存区域大小，后者是是最大永久保存区域大小。
                    如针对tomcat6.0，在catalina.sh 或catalina.bat文件中一系列环境变量名说明结束处（大约在70行左右） 增加一行：JAVA_OPTS=" -XX:PermSize=64M -XX:MaxPermSize=128m"
                2. 清理应用程序中web-inf/lib下的jar，如果tomcat部署了多个应用，很多应用都使用了相同的jar，可以将共同的jar移到tomcat共同的lib下，减少类的重复加载。

        第二种OutOfMemoryError：  Java heap space 堆内存溢出 Xms 和Xmx
            发生这种问题的原因是java虚拟机创建的对象太多，在进行垃圾回收之间，虚拟机分配的到堆内存空间已经用满了，与Heap space有关。
            解决这类问题有两种思路：
                1. 检查程序，看是否有死循环或不必要地重复创建大量对象。找到原因后，修改程序和算法。
                2. 增加Java虚拟机中Xms（初始堆大小）和Xmx（最大堆大小）参数的大小。如：set JAVA_OPTS= -Xms256m -Xmx1024m
            
        内存配置默认是物理内存的1/64;JVM最大分配的内存由-Xmx指定，默认是物理内存的1/4。
        默认空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制;空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、-Xmx相等以避免在每次GC 后调整堆的大小
		



	虚拟机枝和本地方法枝溢出
		StackOverflowError ：线程请求的战深度大于虚拟机所允许的最大深度 循环递归会触发这种 OOM   	常见递归操作
		OutOfMemoryError ：虚拟机在扩展棋时无法申请到足够的内存空间，一般可以通过不停地创建线程触发这种 QOM
		Java 堆溢出： 在创建大量对象并且对象生命周期都很长的情况下，会引发OutOfMemoryError
		方法区溢出： 方法区存放 class 等元数据信息，如果产生大量的类（使用CGLIB ），那么就会引发此内存溢出，即 OutOfMemoryError:PermGen space， 运行期间，jvm不会在主程序运行期间清理。一般发生在启动阶段
	对象访问（句柄访问，指针访问）
		hotspot采用的是直接指针访问：直接保存的是对象实例的地址，对象实例中保存了类型数据的指针。其中实例在堆中，对象类型数据在方法区中。
		根据对象引用能定位到堆中的对象


9.  栈随线程生灭，方法或者线程结束，其内存自然就回收了，但是java堆和方法区不一样。
	堆中存放的是java中的对象实例，已经dead(属于对象是否存活)的对象需要被回收

10. jvm判断对象是否存活，使用的是
		根搜索算法，基本思路是通过一系列名为gc roots 的对象作为起始点，从该节点向下搜索，走过的路径成为引用链，
		当一个对象到gc roots没有任何引用链相连（即从gc roots到这个对象不可达），则对象不可用将被判定为可回收对象

11. java中，可作为gc roots对象包括：
		1、虚拟机栈（栈帧中的本地变量表）中的引用对象
		2、方法区中的类静态属性引用对象
		3、方法区中的常量引用对象
		4、本地方法栈中的native方法的引用的对象

12. finalize()：	
	对象进行根搜索就发现没有与gc roots相连接的引用链，需要看对象是否覆盖finalize(),没有覆盖或者该方法已经被jvm调用过，则对象没必要执行finalize()。
	对象死亡需要经过两次至少两次的标记，一次就是gc roots的不相连接，执行finalize()会对f-queue队列中的对象第二次标记，只要重新与引用链上的任何一个对象建立关联，那么将移除即将回收的集合，即执行finalize()，是对象的自我拯救方法，对象依然可以存活，在被gc时自我拯救，且对象只能执行一次该方法。

13. 分代算法
    新生代中：主要是用来存放新生的对象。一般占据堆的1/3空间。由于频繁创建对象，所以新生代会频繁触发MinorGC进行垃圾回收。
		对象优先在Eden区分配
		Eden区：Java新对象的出生地(如果新创建的对象占用内存很大，则直接分配到老年代)。
		ServivorTo：保留了一次MinorGC过程中的幸存者。
		ServivorFrom：上一次GC的幸存者，作为这一次GC的被扫描者。
		默认Eden与单个Survivor默认比例是8:1
		
	老年代的对象比较稳定，所以MajorGC不会频繁执行。

	在进行MajorGC前一般都先进行了一次MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足够大的连续空间分配给新创建的较大对象时也会提前触发一次MajorGC进行垃圾回收腾出空间。
	
14. 内存分配与回收策略
		对象内存分配，往大方向上讲，就是在堆上分配，对象主要分配在新生代的eden区上
		1、对象优先在eden分配
			当Eden区内存不够的时候就会触发MinorGC，对新生代区进行一次垃圾回收。
		2、大对象直接进入老年代
			指的是需要大量连续内存空间的java对象，典型的是很长的字符串和数组，比如byte[]，
		3、长期存活的对象将进入老年代
			默认gc后年龄计数器+1，达到15进入老年代，参数可配置
		4、动态对象年龄判断
			当年大于survivor空间的一半，大于等于该年龄的直接进入老年代
		5、空间分配担保
			发生minor GC,jvm会检测室之前晋升到老年代的平均值大小，再根据老年代的剩余空间大小，够就开启担保（避免频繁full gc），允许就执行minor gc，不允许就full gc，不够直接full gc，如果担保失败，也进行full gc。
			
        虽然java的垃圾回收机制仅是回收堆区的资源，而对于非堆区无效，这种只能凭借开发人员自身的约束来解决。（堆区有java回收机制、非堆区开发人员能够很好的解决），
        配置堆区：-Xms 、-Xmx、-XX:newSize、-XX:MaxnewSize、-Xmn
        配置非堆区：-XX:PermSize、-XX:MaxPermSize

15. jvm的性能监控域处理工具   
        jps：显示指定系统所有的hotspot jvm进程 常用的是使用-l查看完整的类路径和jar包的位置
        jstat：手机hotspot jvm各方面（类装载，内存，垃圾收集）的运行数据				运行期定位jvm性能首选
        jinfo： 显示虚拟机的配置信息
        jmap：生成jvm的内存转储快照（heapdump文件），java内存映像工具
        jhat：分析heapdump文件，会建立一个http/htm服务器，让用户可在浏览器上查看分析结果
        jstack：显示jvm的线程快照  可定位线程长时间未响应的原因
        jconsole 和jvisualVM 可视化监控工具，目前主推的是jvisualVM这款的功能

16. jvm的类加载机制：jvm把描述类的数据从class文件加载到内存，并对数据进行校验，转换解析和初始化，最终形成可被jvm直接使用的java类型，	
	对于静态字段，只有直接定义这个字段的类才会初始化，因此通过其子类来引用父类中的定义的静态字段，只会触发父类的初始化而不会触发子类的初始化
	静态代码块static{}用来初始化信息
	加载的几个阶段：加载，验证，准备，解析，初始化，使用，卸载，前5个就是类的加载过程，2-4属于连接
	加载：1.获取类的二进制字节流，2.将其代表的静态存储结构转化为方法区的运行时数据结构，3.在堆中生成代表该类的class对象，作为方法区这些数据的访问入口。
	验证：确保class文件的字节流中包含的信息符合当前虚拟机的要求，并不会危害jvm自身安全
	准备：在方法区中，为类变量(被static修饰的变量，不包括实例变量)分配内存并设置类变量的初始值，实例变量将会在对象实例化时随着对象一起分配在java堆中，
	解析：jvm将常量池内存内的符号引用替换为直接引用的过程
	初始化：真正开始执行类中定义的java程序代码(或者说是字节码)

17. 垃圾回收的算法

新生代中的算法:停止-复制
    将 Eden 区和一个 Survivor 中仍然存活的对象拷贝到另一个 Survivor中
    年轻代可以分为 3 个区域：Eden 区（表示内存首次分配的区域，）
    和两个存活（Survivor 0 、Survivor 1,并且两个servivor区中必须有一个是空白的）内存分配过程为，最终gc后存活的就进入老年代，
    
    需要明确一点，“停 止（Stop-the-world）”的意义是在回收内存时，需要暂停其他所有线程的执行。
    这个是很低效的，现在的各种新生代收集器越来越优化这一点，但仍然只是将停止的时间变短，并未彻底取消停止。

    老年代中的算法：标记-整理
        如果使用停止-复制算法，则相当低效。一般，老年代用的算法是标记-整理算法，即：标记出仍然存活的对象（存在引用的），将所有存活的对象向一端移动，以保证内存的连续

    JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块Survivor区域是空闲着的,复制完就清空。存活区默认切换15次就会进入老年代了。


18. 定义类就是在定义类中的成员，，包括成员变量（属性）和成员函数（行为）
	成员变量属于类，在堆中
	局部变量属于方法，在栈中
	new 一个对象的过程：
		Java中所有对象的存储空间都是在堆中分配的，但是这个对象的引用却是在堆栈中分配,也就是说在建立一个对象时从两个地方都分配内存，
		在堆中分配的内存实际建立这个对象，而在栈中分配的内存只是一个指向这个堆对象的指针(引用变量)而已。 
		在堆中分配的内存，由Java虚拟机的自动垃圾回收器来管理。 


19. 双亲委派机制(防止重复加载同一个.class)
	**双亲委派机制，就是一个类只能被一个类加载器加载。**

		类加载器一般是三层的classLoader，是上下子父级关系，不是继承关系，只是调用逻辑关系
			BootstrapclassLoader:
				主要负责加载核心的类库(java.lang.*等)，$JAVA_HOME$/jre/lib，		负责加载 JAVA_HOME\lib 目录中的，
				加载jvm自身工作需要的类，没有字符加载器，jvm控制，别人访问不到
			ExtClassLoader：
				主要负责加载jre/lib/ext目录下的一些扩展的jar。		 					负责加载 JAVA_HOME\lib\ext 目录中的，
				除了System.getProperty("java.ext.dirs")目录下是由其加载，其他都由AppClassLoader来加载
			AppClassLoader：
				主要负责加载应用程序的主函数类，										负责加载用户路径（classpath）上的类库
				是上个加载器的子类，加载classpath目录下的类。
				是自实现类加载器的父加载器

			实际测试 可以遍历this.getClass.getClassLoader 的parent即可，就能看出链	

		*****
			向上递归检查，向下递归加载
			原则：1.自底向上检查类是否已经装载  2.自顶向下尝试加载类
			三层的classLoader负责的范围也不一样，这样依次检查，依次加载(在自己的范围内)。
			逐层往上(接待就返回，没有就抛给上层，直到有一级接待或者上级返回没有接待且不应由上级接待，那么本层就会加载)
		*****

		自底向上，挨个检查是否已经加载了指定类，如果已经载入，那么直接返回该类的实例的引用
		如果bootstapclassloader也未加载成功该类，那么会抛出异常。然后自顶向下挨个尝试加载。直到customclassloader,如果还未能加载，就抛出ClassNotFoundException给调用者。

		类请求递归委派到顶层，放父加载无法完成，子类才会去加载。这里双亲就是指的是父类。
		特殊场景：jdbc的spi加载，因为BootstrapclassLoader加载范围，只能委托子类加载实现。
		
		这种设计有个好处是，如果有人想替换系统级别的类：String.java。篡改它的实现，但是在这种机制下这些系统的类已经被Bootstrap classLoader加载过了，所以并不会再去加载，从一定程度上防止了危险代码的植入

		jvm表示一个类是否是同一个类的条件 1.完整类名是否一致，2.加载该类的classloader实例是否是同一个
	
		jvm显式加载class文件到内存
			1.this.getClass.getClassLoader.loadClass()	2.Class.forName()
			
20. 系统调优相关
		了解系统总体架构，明确压力方向。具体的接口或者是模块的使用率。
		关键业务数据量分析，一天多少量，缓存数据量
		了解系统响应速度，吞吐量，tps,qps等指标需求。
		
		使用top查看，关键看进程id,虚拟内存分配 和物理内存，cpu占有，一般关心物理内存的占用，虚拟内存不用关心
		ps -aux|grep java 相比 -ef 能看物理内存占用情况
		.
		系统层面影响的只有三个，CPU 、内存和 I/O。
		
		使用top  和 ps  先查个大概 ，然后看具体进程的原因
		
		测试在虚拟机上使用root用户是可以的，jstack 和 jstat 相关命令 
		jstat   	查看类加载，内存管理，gc情况
		jstack  	打印异常进程的堆栈信息 dump线程快照，定位死锁，超时问题
		jmap        查看堆内存使用情况，可生成JVM堆的转储快照，dump文件较大，消耗大量资源
		
		
		jps   		查看进程和运行的主类，cmd下测试可用
		jstack
			jstack用于生成java虚拟机当前时刻的线程快照。注意是当前时刻
			线程快照是当前java虚拟机内每一条线程正在执行的方法堆栈的集合，用于定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等。
				
			jstack命令的语法格式： jstack  <pid>。可以用jps查看java进程id。
			jstack 31177 > /home/tengfei.fangtf/dump17
			在实际运行中，往往一次 dump的信息，还不足以确认问题。建议产生三次 dump信息，如果每次dump都指向同一个问题，我们才确定问题的典型性。
		
		**********现在用VisualVM 比较多点，直接线程的客户端，比较好用(直接继承了上面的命令)**********
		目前连接远程，有两种方式，1.服务器上启动jstatd  2.服务器上配置jmx。然后客户端连接
		连接后续有个调优的可以试试
		
		常见的攻击方式
		xss  	 	由页面输入脚本引起，接收转义即可
		crsf  		利用cookie引起，使用token或者在cookie中设置httpOnly
		sql注入		使用预编译语句，用占位符将参数语句当做普通字符串
		
		释放不必要的引用： ThreadLocal 使用完记得释放以防止内存泄漏，各种 stream用完也记得 close
		
		新生代不能设置过小，过小会经常minor GC，

21. 	
		java栈总是和线程关联一起，每创建一个线程，jvm就会创建对应一个java栈，这个线程执行的多个方法，每运行一个方法就创建一个栈帧(包含内部变量，操作栈和方法返回值等信息)
		每一个方法执行完成，弹出栈帧作为方法的返回值，并清除该栈帧，java栈的栈顶的栈帧就是房钱正在执行的方，方法的到调用就是创建活动栈帧，后面逐层出栈。
		栈是非线程共享，堆是线程共享的。
		方法区就是java堆中的永久区。存放的相关class信息和常量池相关
		运行时常量池是方法区的一部分
			

## java8新特性
1. jdk8新特性，interface中的default方法
		default修饰方法只能在接口中使用，在接口种被default标记的方法为普通方法，可以直接写方法体。
		default是可使用默认的方法，不满足需求的时候可以覆盖，static可以直接调用
		实现类会继承接口中的default方法
		如果子类继承父类，父类中有b方法，该子类同时实现的接口中也有b方法（被default修饰），那么子类会继承父类的b方法而不是继承接口中的b方法


	函数式接口(Functional Interface，@FunctionalInterface)就是一个有且仅有一个抽象方法，但是可以有多个非抽象方法的接口。
	函数式接口可以被隐式转换为 lambda 表达式。以前是采用匿名实现类实现的
		1.一个函数式接口有且只有一个抽象方法。
		2.默认方法不是抽象方法，因为它们已经实现了。
		3.重写了超类Object类中任意一个public方法的方法并不算接口中的抽象方法。
		
	因为任何接口的实现都会从其父类Object或其它地方获得这些方法的实现。所以Comparator中的equals不算是接口中的抽象方法


2. Lambda 表达式，其参数和函数体被箭头 -> 分隔开。箭头右侧是从 Lambda 返回的表达式。它与单独定义类和采用匿名内部类等价，但代码少。

	使用lambada的条件，必须只能是函数式接口（概述:接口中只有一个抽象方法）才适用。可用@FunctionalInterface来提前校验函数式接口，编译时提前发现错误。

    Lambda 表达式格式：参数 -> 实现主体 
   Java 8 的方法引用
   		它以 :: 为特征。 :: 的左边是类或对象的名称， :: 的右边是方法的名称，但是没有参数列表
		类::静态方法
		实例::非静态方法
		类名或对象名 :: 方法名称
		本质上是lambda的简写，也是一个接口的匿名实现类
		这个会选择一个函数式接口，将方法体内容作为其函数接口中方法的具体实现，比如Function或者Consumer
		*****方法引用就是将一个方法的方法体实现，映射到一个函数接口的实现中，实质上是函数接口的一个实现类*****

		方法签名强制一致
		最好是将方法名称对应方法(参数类型和返回类型),要和对应的函数接口一致。系统有默认的选择(Function或者Consumer)，


 ```		
	interface Bb {
		void call(String s);
	}
	class Describe {
		void show(String msg) {System.out.println(msg);}
	}
	public static void main(String[] args) {
		Describe d = new Describe();
		Bb bb = d::show; 		 	//相当于将show中的方法自动映射一个函数式接口，放在了Bb的匿名实现类中实现,这里默认是 Consumer<String> show = describe::show;
		bb.call("123");  
	}

	class Go {
	static void go() {System.out.println("Go::go()");}
	}

	public class RunnableMethodReference {
		public static void main(String[] args) {
			//1.基础
			new Thread(new Runnable() {
			public void run() {System.out.println("Anonymous");}
			}).start();
			
			//简化lambda
			new Thread(() -> System.out.println("lambda")).start();
			
			//方法引用
			new Thread(Go::go).start();
		}
	}

 ```
3. Lambda 表达式包含类型推导（编译器会自动推导出类型信息，避免了程序员显式地声明）。
	编译器必须能够以某种方式推导出 x 的类型。
	当 Lambda 表达式被赋值时，编译器必须确定 x 和 y 的确切类型以生成正确的代码

	@FunctionalInterface				这个也可以自定义的，但是一般不需要
	Lambda 表达式和方法引用的目标类型。 每个接口只包含一个抽象方法，称为 函数式方法 。
	如果只处理对象而非基本类型，名称则为 Function，Consumer，Predicate 等。参数类型通过泛型添加。



		-- 自定义函数接口接收(忽略)
		方法名称对应有返回值，函数接口方法void类型，也能匹配上
		将Describe 对象的方法引用赋值给 Bb,它没有 show()方法，而是call()方法。但Java 似乎接受用这个看似奇怪的赋值，因为方法引用符合Bb的 call() 方法的签名(参数类型和返回类型)。
		这样可以通过调用 call() 来调用 show()，因为 Java 将 call() 映射到 show()。
		这种将方法映射给函数接口的，操作，代码简单，

		只要参数类型、返回类型与 BiConsumer 的 accept() 相同即可。
		因此，在使用函数接口时，名称无关紧要——只要参数类型和返回类型相同。
		 Java 会将你的方法映射到接口方法。 要调用方法，可以调用接口的函数式方法名（在本例中为 accept()），而不是你的方法名。



	未绑定的方法引用是指没有关联对象的普通（非静态）方法。 使用未绑定的引用时，我们必须先提供对象.这种不推荐用。走正规路子
	标准的就是方法签名匹配，然后 类::静态方法+实例::非静态方法，其他野路子不要用。

	本质上，Lambda是一个匿名实现类，是函数式接口的实现，对应的是一个接口类型
 ```
	interface Bb {
		String detailed(String head);
	}

	class Testgo {
		Bb bb= h -> h+"zenme";
	}
 ```

	Lambda 表达式的基本语法:  参数 -> 方法体
		[1] 当只用一个参数，可以不需要括号 ()。 
		[2] 正常情况使用括号 () 包裹参数。 为了保持一致性，也可以使用括号 () 包裹单个参数，虽然这种情况并不常见。
		[3] 如果没有参数，则必须使用括号 () 表示空参数列表。
		[4] 对于多个参数，将参数列表放在括号 () 中。
		[5]	Lambda 表达式方法体是单行的。该表达式的结果自动成为 Lambda 表达式的返回值，使用return非法。简写方式
			如果在Lambda 表达式中确实需要多行，则必须将这些行放在花括号中。在这种情况下，就需要使用 return。


	代码实例
		List<person> plist = ...;
		//根据超时天数倒序排序
		Comparator<person> comparator = (t1, t2) -> t1.getAge().compareTo(t2.getAge());
		plist.sort(comparator.reversed());	
		实际就是list.sort(Comparator)操作
		List.sort((o1, o2) -> flag ? a.compareTo(b) : b.compareTo(a));


4. 
流式编程
	流(Streams)取代了在集合中迭代元素的做法，使用流即可从管道中提取元素并对其操作。将对流的操作操作串联起来。
	内部迭代（internal iteration），这是流式编程的一个核心特征。

	流是懒加载的。这代表着它只在绝对必要时才计算。由于计算延迟，流使我们能够表示非常大（甚至无限）的序列，而不需要考虑内存问题。
	
	流操作的类型有三种：
		1.创建流，
		2.修改流元素（中间操作， Intermediate Operations），
		3.消费流元素（终端操作， Terminal Operations）。这种类型通常意味着收集流元素(通常是汇入一个集合)

	
	使用Stream.of()将一组元素转化为流
		Stream.of("i ", "am", "a ", "coat ").forEach(System.out::print);
		
	将一个集合生成流
		list.stream()
		map转为流 map.entrySet().stream()
	
		中间操作 map() 会获取流中的所有元素，并且对流中元素应用操作从而产生新的元素，并将其传递到后续的流中。通常 map() 会获取对象并产生新的对象
		有些特殊的流操作，mapToInt() 方法将一个对象流（object stream）转换成为包含整型数字的 IntStream。暂时不用

	#peek()相当于是一个调试功能，查看每个元素的转变情况
		strings.stream().map(String::toUpperCase).peek(System.out::println).map(e -> e+"1").forEach(System.out::println);
			WO
			WO1
			SHI
			SHI1
			NI
			NI1
	peek() 符合无返回值的 Consumer 函数式接口，所以我们只能观察，无法使用不同的元素来替换流中的对象。
	distinct()：在 Randoms.java 类中的 distinct() 可用于消除流中重复元素。相比创建一个 Set 集合来消除重复，工作量要少。
	filter(Predicate)：过滤操作，保留如下元素：若元素传递给过滤函数产生的结果为true 。
	
	集中类型目前看意义不大(忽略)
	map(Function)：将函数操作应用在输入流的元素中，并将返回值传递到输出流中。
	mapToInt(ToIntFunction)：操作同上，但结果是 IntStream。
	mapToLong(ToLongFunction)：操作同上，但结果是 LongStream。
	mapToDouble(ToDoubleFunction)：操作同上，但结果是 DoubleStream。

	终端操作
	获取流的最终结果，无法再继续往后传递流，是我们在流管道中所做的最后一件事
	
	forEach(Consumer)常见如 System.out::println 作为 Consumer 函数。
	forEachOrdered(Consumer)： 保证 forEach 按照原始流顺序操作。
	
	collect(Collector)：使用 Collector 收集流元素到结果集合中
	
	count()：流中的元素个数(忽略)
	max(Comparator)：根据所传入的 Comparator 所决定的“最大”元素。
	min(Comparator)：根据所传入的 Comparator 所决定的“最小”元素。
	min() 和 max() 的返回类型为 Optional，这需要我们使用 orElse()来解包。
	
	
	http的连接操作
		BufferedInputStream bufferedinputstream = new BufferedInputStream(inputStream);
		InputStreamReader isr = new InputStreamReader(bufferedinputstream, charset);
		BufferedReader in = new BufferedReader(isr);
		StringBuffer buff = new StringBuffer();
		String readLine = null;
		String endLine = SYMBOL_END_LINE;
		while ((readLine = in.readLine()) != null)
		{buff.append(readLine).append(endLine);}
		if (buff.length() > 0)
		{response = buff.substring(0, buff.length() - 1);}
		else
		{response = buff.toString();}

5. 匿名内部类中的变量使用
	int limit = 10;
	Runnable r = () -> {
		for (int i = 0; i < limit; i++) {
			System.out.println(i);
		}
	};
	new Thread(r).start();
	代码仍然可以正常编译，正常运行，那么此时的 limit 变量就是“effectively final”的。
	由于 limit 在接下来的代码中没有被重新赋值，编译器就被欺骗了，想当然地认为 limit 就是一个 final 变量（实际上的最终变量）。
	“effectively final”是一个行为类似于“final”的变量，但没有将其声明为“final”变量，


	TriggerParam triggerParam1 = null;
	triggerParam = triggerQueue.poll(3L, TimeUnit.SECONDS);				#这里和下面的effectively final冲突了
	FutureTask<Boolean> futureTask = new FutureTask<Boolean>(new Callable<Boolean>() {
		@Override
		public Boolean call() throws Exception {
			triggerParam.getExecutorHandler();				#报错，这里上面没有指定static就默认是effectively final，但是上面更新对象引用了，会报错
			return true;
		}
	});

	Thread futureThread = new Thread(futureTask);			#这里再记录一个futuretask的线程启动
	futureThread.start();
	Boolean tempResult = futureTask.get(triggerParam.getExecutorTimeout(), TimeUnit.SECONDS);
	

6. 












## Netty相关(忽略)
	Netty 对 JDK 自带的 NIO 的 API 进行了封装,是异步高性能的通信框架。往往作为高性能基础通信组件被这些 RPC 框架使用。

	传统的i/o模式，每个请求都需要独立的线程完成数据read，业务处理，数据write的完整操作问题，容易阻塞
	Netty 的非阻塞 I/O 的实现关键是基于 I/O 复用模型，使用了多路复用器selector，一个 I/O 线程可以并发处理 N 个客户端连接和读写操作，这从根本上解决了传统同步阻塞 I/O 一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。
	传统的 I/O 是面向字节流或字符流的，以流式的方式顺序地从一个 Stream 中读取一个或多个字节, 因此也就不能随意改变读取指针的位置。

	在 NIO 中，抛弃了传统的 I/O 流，而是引入了 Channel 和 Buffer 的概念
	Netty 的线程模型基于主从 Reactor 多线程
	Netty 基于 Selector 对象实现 I/O 多路复用，通过 Selector 一个线程可以监听多个连接的 Channel 事件。
	当向一个 Selector 中注册 Channel 后，Selector 内部的机制就可以自动不断地查询(Select) 这些注册的 Channel 是否有已就绪的 I/O 事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel 
	
	
	在io模型中一个连接需要开一个线程
	NIO解决这个问题的方式是数据读写不再以字节为单位，而是以字节块为单位。每次从缓存区读取一块数据
	
	class java.nio.channels.Selector 是Java 的非阻塞 I/O 实现的关键。它使用了事件通知 API，可在任何的时间检查任意的读操作或者写操作的完成状态，一个单一的线程便可以处理多个并发的连接。统一处理多个socket连接
	
	ChannelFutureListener提供的通知机制消除了手动检查对应的操作是否完成的必要
	Netty 完全是异步和事件驱动的。这里体现监听事件是否完成，
	
	编码解码的事情：这两种方向的转换的原因很简单：网络数据总是一系列的字节
	
	网络数据的基本单位总是字节。Java NIO 提供了 ByteBuffer 作为它的字节容器，但是这个类使用起来过于复杂，而且也有些繁琐
	Netty 的 ByteBuffer 替代品是 ByteBuf，一个强大的实现，既解决了 JDK API 的局限性，又为网络应用程序的开发者提供了更好的 API。
	bio，传统的一请求一应答通信模型，一请求产生一个线程，交互完成，线程销毁，线程资源不可控，会阻塞
	后来出现了线程池，这是伪异步i/o,采用线程池和任务队列可以实现一种叫做伪异步的 I/O 通信框架，线程资源可控，但是还是会阻塞
	
	Reactor模式：
			connection per thread,早起的tomcat就是这样实现的
			一个线程只能对应一个socket
			改进：采用基于事件驱动的设计，当有事件触发时，才会调用处理器进行数据处理。使用Reactor模式，对线程的数量进行控制，一个线程处理大量的事件。
			
			实际上的Reactor模式，是基于Java NIO的，在他的基础上，抽象出来两个组件——Reactor和Handler两个组件：
		（1）Reactor：负责响应IO事件，当检测到一个新的事件，将其发送给相应的Handler去处理；新的事件包含连接建立就绪、读就绪、写就绪等。
		（2）Handler:将自身（handler）与事件绑定，负责事件的处理，完成channel的读入，完成处理业务逻辑后，负责将结果写出channel。



## 分布式事务
1. 2pc 和 tcc 
2PC需要对整个资源加锁，因此不适用于高并发的分布式场景；而tcc只对需要的资源进行加锁，加锁的粒度小，且try commit Cancel都是本地短事务，因此能在保证强一致性的同时最大化提高系统可用性
2PC是有数据库来保证回滚，而TCC是应用层实现回滚：为每一个try操作提供一个对应的cancel操作 

2. CAP定理
    一致性(Consistency) ： 客户端知道一系列的操作都会同时发生(生效)，数据一致更新，所有数据变动都是同步的。可以从原子性理解
    可用性(Availability) ： 每个操作都必须以可预期的响应结束
    分区容错性(Partition tolerance) ： 即使出现单个组件无法可用,操作依然可以完成

    分布式系统中，一个Web应用至多只能同时支持上面的两个属性。

    zookeeper实现了cap中的cp特性，因为zk集群有leader选举机制，牺牲了短暂的可用性，但是保证了容错性
    zk的地址信息变动会通知其他的客户端，要么全成功，要么全失败，类似事务的原子性，实现一致性。

    BASE理论
    Basically Available（基本可用）         分布式系统出现不可预知故障，允许损失部分可用性
    Soft state（软状态）                    允许中间状态，允许一定的处理延迟
    Eventually consistent（最终一致性）     类似异步mq，流量取峰，最终一致即可
    BASE理论是对CAP中的一致性和可用性进行一个权衡的结果:无法做到强一致,采用适当的方式来使系统达到最终一致性

4. 两段式提交(two-phase commit)。
	在两段式提交过程中，涉及两类角色，协调者(Coordinator)和参与者(Participants)。
	第一个阶段：预提交阶段，也可以称之为投票阶段，一票否决性,各个server端，操作数据库先做各自的预提交
	第二个阶段：提交决定阶段。
               协调者根据上一个阶段的投票结果决定是Commit还是Abort，这个决定是全局性的，会通知到所有的参与者执行最终的决定，并回传一个ack确认信息。
               判断预提交都是ok的，在进行第二次的统一事务提交，若有错误，回滚全部

	强一致性的目的，长生命周期的分布式事务就不适合两段式提交。
	整个完成才释放资源，锁力度大，性能差

    TCC
    TCC包含了三个阶段：Try，Confirm，Cancel，因此而得名「TCC」。一种柔性事务解决方案
        Try: 尝试执行业务
            完成所有业务检查(一致性)
            预留必须业务资源(准隔离性)          
        Confirm:确认执行业务
            真正执行业务
            不作任何业务检查
            只使用Try阶段预留的业务资源 
            Confirm操作要满足幂等性
        Cancel: 取消执行业务
            释放Try阶段预留的业务资源 
            Cancel操作要满足幂等性

    TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作，TCC的Try、Confirm和Cancel操作功能需业务提供，开发成本高。

    TCC与2PC协议比较：
        位于业务服务层而非资源层
        没有单独的准备(Prepare)阶段， Try操作兼备资源操作与准备能力 
        Try操作可以灵活选择业务资源的锁定粒度(以业务定粒度) 
        2PC的强一致性依赖于数据库，而TCC的强一致性依赖于应用层的Commit与cancel

    将事务管理器称为协调者将资源管理器称为参与者
	

	两阶段提交：
		需引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果，并最终指示这些节点是否要把操作结果进行真正的提交的反馈情报决定各参与者是否要提交操作还是中止操作。

		准备阶段： 只写日志，不提交事务
			写 redo 或 undo 日志，然后锁定资源，
			事务协调者(事务管理器)给每个参与者(资源管理器)发送 Prepare 消息，每个参与者要么直接返回失败，要么在本地执行事务，写本地的 redo 和 undo 日志，但不提交
		提交阶段：
			预留资源和执行操作成功，则变更释放资源，否则回退执行undo，释放锁定资源
			如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(Rollback)消息；否则，发送提交(Commit)消息；
			参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)

		失败情况
			在XA的第一阶段，如果某个事务参与者反馈失败消息，说明该节点的本地事务执行不成功，必须回滚。
			于是在第二阶段，事务协调节点向所有的事务参与者发送Abort请求。接收到Abort请求之后，各个事务参与者节点需要在本地进行事务的回滚操作，回滚操作依照Undo Log来进行。

		
		无法解决的问题（数据状态不确定）忽略
			协调者再发出 commit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。


	三阶段提交：新增超时机制，解决阻塞问题，新增询问阶段 (忽略)
		询问阶段：协调者询问参与者是否可以完成指令，无需执行真正的操作，超时会终止
		
		与两阶段提交不同的是，三阶段提交有两个改动点。
		引入超时机制。同时在协调者和参与者中都引入超时机制。在第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前各参与节点的状态是一致的。
		也就是说，除了引入超时机制之外，3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。
				
		PC最关键要解决的就是协调者和参与者同时挂掉的问题，所以3PC把2PC的准备阶段再次一分为二，这样三阶段提交就有CanCommit、PreCommit、DoCommit三个阶段。
		在第一阶段，只是询问所有参与者是否可可以执行事务操作，并不在本阶段执行事务操作。当协调者收到所有的参与者都返回YES时，在第二阶段才执行事务操作，然后在第三阶段在执行commit或者rollback
	
		XA三阶段提交在两阶段提交的基础上增加了CanCommit阶段，并且引入了超时机制。
		一旦事物参与者迟迟没有接到协调者的commit请求，会自动进行本地commit。有效解决了协调者单点故障的问题。但是性能问题和不一致的问题仍然没有根本解决。
		
		1.协调者询问事务是否可以执行，这一步不会锁定资源
		2.参与者反馈，协调者接收到所有YES指令
		3.协调者发送事务执行指令，这一步锁住资源
		4.参与者执行事务操作，反馈状态，协调者收到所有参与者的ACK响应，通知所有参与者执行事务的commit
		5.执行commit操作，反馈状态
		
		简单概括一下就是，如果挂掉的那台机器已经执行了commit，那么协调者可以从所有未挂掉的参与者的状态中分析出来，并执行commit。如果挂掉的那个参与者执行了rollback，那么协调者和其他的参与者执行的肯定也是rollback操作。所以，再多引入一个阶段之后，3PC解决了2PC中存在的那种由于协调者和参与者同时挂掉有可能导致的数据一致性问题。


	目前tcc,try confirm cancel
		我们给出一个使用 TCC 的实际案例，在秒杀的场景中，用户发起下订单请求，应用层先
		询库存，确认商品库存还有余量，则锁定库存，此时订单状态为待支付，然后指引用户去支付
		由于某种原因用户支付失败或者支付超时，则系统会自动将锁定的库存解锁以供其他用户秒杀。


    分布式事务的相关
	方案	
    2pc两阶段提交，一般使用jta规范实现，(Atomikos,实现两阶段的提交)。
			
			
	最大努力通知方案（多次尝试） 
	消息中间件mq方案
	tcc(try-confirm-cancel)两阶段补偿方案
		try阶段；完成所有业务检查（一致性），预留业务资源（准隔离性）
		confirm阶段：确认执行业务操作，只使用上阶段预留的业务资源
		cancel阶段：有一个失败，取消所有业务资源请求
			失败重试机制，
			补偿机制，比如日志，继续或回滚
	减小了系统间的锁粒度，提升并发性能，类似买票先预定，事务也是提交的，后购票。


	场景充值和账户
		最大努力通知方案是分布式事务中对一致性要求最低的一种，适用于一些最终一致性时间敏感度低的业务。
		最大努力通知方案需要实现如下功能：
			1、消息重复通知机制。   账户系统没收到就一直发送，收到返回ack
			2、消息校对机制。		账户系统先查询充值结果，确认ok了再进行更新
	
	tcc和xa/jta
		前者时业务层面的分布式事务，最终一致性，不会一致持有资源锁，分布释放锁
		后者是资源层面的分布式事务，强一致性，两阶段提交的过程中一致会持有资源锁
		
		
	tcc开源框架：
		atomikos，tcc-transcation（推荐），spring-cloud-rest-tcc，支付宝xts

	1.2PC/3PC：依赖于数据库，能够很好的提供强一致性和强事务性，但相对来说延迟比较高，比较适合传统的单体应用，在同一个方法中存在跨库操作的情况，不适合高并发和高性能要求的场景。
	2.TCC：适用于执行时间确定且较短，实时性要求高，对数据一致性要求高，比如互联网金融企业最核心的三个服务：交易、支付、账务。
	3.本地消息表/MQ 事务：都适用于事务中参与方支持操作幂等，对一致性要求不高，业务上能容忍数据不一致到一个人工检查周期，事务涉及的参与方、参与环节较少，业务上有对账/校验系统兜底。
	4.Saga事务：由于 Saga 事务不能保证隔离性，需要在业务层控制并发，适合于业务场景事务并发操作同一资源较少的情况。 Saga 相比缺少预提交动作，导致补偿动作的实现比较麻烦，适用于补偿动作容易处理的场景
	




5. java.net.SocketTimeoutException: connect timed out
    系统间的调用，会出现超时的情况，关键的回调，需要做job的补偿回调。对于及时性比较高的，需要在超时间内，得到补偿信息

6. 多系统间的调用，补偿的job还是很有必要的
	
	我们对复杂的分布式事务进行拆解，对其中的每个步骤都记录其状态，
	有问题时可以根据记录的状态来继续执行任务（或者终止），达到最终一致。
	说白了就是增加操作日志

7. 一致性是事务的最终目的，原子性、隔离性、持久性都是为了实现一致性。数据一致性等


8. 

## 前段相关
1. 将jquery的相关js引入到classpath下的js文件夹下，
    最简洁的ajax使用,ajax和js是不允许跨域请求的
    ```
     #页面引入 <script  src="js/jquery-1.8.3.min.js">，即可使用。
 			$.ajax({
		             type: "post",
		             url: "http://192.168.1.102:8081/addTalents",
		             data: {"a":"nihao"},
		             dataType: "json",
		             success: function(data){} 
		        	});
    ```
2. tcc-transaction 开源框架（忽略）
	TCC解决分布式事物的思路是，一个大事务拆解成多个小事务。
	https://my.oschina.net/sword4j?tab=newest&catalogId=5734750		整体详细的文档

	1  TCC的主要优点有
	因为Try阶段检查并预留了资源，所以confirm阶段一般都可以执行成功。
	资源锁定都是在业务代码中完成，不会block住DB，可以做到对db性能无影响。
	2.TCC的实时性较高，所有的DB写操作都集中在confirm中，写操作的结果实时返回（失败,因定时job，略有延迟）
		
		Try 阶段 创建root事务，添加参与者，全部try完再决定是confirm还是cancel
		
		根事务(root)----对应-----分支事务(branch)	
		
		all branch 事务成功，则修改all branch事务状态为confirm，并执行confirm逻辑
		如果某个分支业务逻辑成功，则删除对应的事务记录；(有一个失败，所有事务状态是cancel，执行cancel逻辑)
		如果业务逻辑执行成功，则删除对应的事务记录。(all branch ok，执行root 的confirm或者cancel逻辑),执行成功后，然后删除事务记录。
		
		每个线程绑定了一个线程变量，存放的是一个事务队列(peek()返回队列的头元素)。
		
		*********
		主try-两次dubbotry(各有两次，一次代理(supports)，一次实际调用)-主confirm-两个dubbo的confirm(各两次，一次代理(supports)，一次实际)
		拦截两次，第一次的代理拦截是在主线程中添加dubbo的两个confirm动作
		子事务的执行是在主conmit中调用的，其中有参与者列表participants，这样第二次进拦截器走的是provide操作，就是commit操作
		
		transaction的xid通过dubbo隐式传参获取，两次 一次是try阶段  还有一次是confirm阶段
		
	主线程会注册一次代理的接口，然后资源拦截器会拦截，添加进参与者（封装的是原接口的方法和参数，添加进当前线程队列，使用的是全局id和分支id），将事务id-上下文注册到缓存中，
	然后进入远程调用，根据传递过来的txid，将confirm等上下文存入缓存

    在接口上也需要实现Compensable，这样才会代理，但是注册参与者的时候是注册的接口(commit生成实例是通过工厂类绑定的代理类)

	创建dubbo代理接口的时候，注解中添加了DubboTransactionContextEditor  事务编辑器


	//实现原理：
	所有的create 和update 都会进缓存，绑定对应的事务txid和当前事务
	两个拦截器；主try包含两个从try，主事务ommit包含三个参与者信息；

	try执行ok，主事务执行confirm(包含了远程两个参与者)（封装的是dubbo 原try方法的调用，但是状态是confirming,会走provider，走confirm）

	dubbo代理接口--->实现类，RpcContext.getContext() 实现隐式传入了2的事务txid，和3共用，然后3中存入缓存的是xid-branch 事务(包含confirm等参与者的信息)， putToCache(transaction)

		1.root进第一拦截器(root事务入库，事务进线程变量),进资源拦截器(创建参与者，branchid自建，将参与者加入根事务，然后更新根事务到数据库，其中事务序列化后存入了content字段)
		2.dubbo代理接口，进第一拦截器(supports,没有事务上下文，直接放行)，进资源拦截器(创建参与者，branchid自建，使用全局事务id，封装的本身的调用record方法，同上，主要是根事务新增了参与者)
		3.dubbo代理接口的实现类，进入第一拦截器(带了上下文[是2中dubbo context中存的xid]，进入provider事务，新建了branch事务，入库，事务进线程)
			进入资源拦截器(创建参与者，branchid自建，使用全局事务id，封装confirm等方法进入上下文，数据库更新branch事务，进缓存[使用的也是2中的xid-事务]，主要是更新参与者)
		4.root的confirm,正常。dubbo的代理confim进第一拦截(supports放过)，第二拦截(不是trying 放过)
		5.dubbo  confirm service，进第一拦截器(带上下文,进provider事务，根据txid从缓存中找到步骤3存的调用上下文，实现事务中的参与者反射调用)，进入第二拦截器(不是trying,放过)

	RpcContext.getContext()

		相当于将在调用前将存放的参数封装传到服务端，是跟着这个方法走的，是一次调用适用

		客户端：RpcContext.getContext().setAttachment("sourceid", "15700007");--A
		调dubbo接口：smsService.smsSend();
		服务端：RpcContext.getContext().getAttachment("sourceid");--B
		一定要注意，调接口时，必须是A直接到B，如果A没有直接到B，而是先到C，再由C到B，那么在B里getAttachment()，就获取不到值了。

		RpcContext对象是绑定在线程临时变量LOCAL上，所以可以通过线程临时变量来获取到RpcContext的相关参数值
		在调用提供者之前，在源码“41处”，会获取当前线程临时变量里的RpcContext对象，再将RpcContext对象里的参数设置到Invocation对象，最后调用doInvoke(Invocation invocation)方法，就会发送参数给提供者。

		
		这里远离是将设置放在了线程变量中然后添加进dubbo的参数中传过去
		RpcContext.getContext().setAttachment
			这里会消费端将参数传入dubbo参数中，传给服务端invocation.addAttachmentsIfAbsent(attachment);
		invocation.getAttachments();
			这里服务端会从入参中获取加入到RpcContext中，invocation.getAttachments()；RpcContext.getContext().setAttachments(attachments);
		dubbo接口直接从工厂类中获取（使用的还是spring的单例）
		confirm中 dubbo接口调用，会从容器中拿到代理类代理执行。  静态map后面继续使用
		
		
	创建job也很简单，定义一个启动类，
	1.初始化的时候  scheduler.scheduleJob(jobDetail.getObject(), cronTrigger.getObject());
	定义好jobdetail 和触发策略cronTrigger
	2.启动scheduler.start();
		public class DefaultRecoverConfig implements RecoverConfig {
			public static final RecoverConfig INSTANCE = new DefaultRecoverConfig();
		
		}
    recovery job 中
        就是从数据库中读取事务(封装了事务的上下文)到缓存中，然后重新执行
        异常出现的时候，有一个confrim异常
        主order  分支cap 和red
        在cap的confirm中抛异常，会返回消费者拿到异常，然后直接结束，这样 order和cap是confirming，red是trying
        事务信息被持久化到外部的存储器中。事务存储是事务恢复的基础。通过读取外部存储器中的异常事务，定时任务会按照一定频率对事务进行重试，直到事务完成或超过最大重试次数。
        实际分支事务对应的应用服务器也可以重试分支事务，不是必须根事务发起重试，从而一起重试分支事务。	
		        	
	