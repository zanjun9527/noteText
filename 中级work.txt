
分布式服务架构：原理、设计与实战  	比较实用

相关的推荐博客：
1.	大型电商网站架构案例和技术架构【推荐】
	https://blog.csdn.net/jianai0602/article/details/80346837 


XA协议采用两阶段提交方式来管理分布式事务

2PC需要对整个资源加锁，因此不适用于高并发的分布式场景；而tcc只对需要的资源进行加锁，加锁的粒度小，且try commit Cancel都是本地短事务，因此能在保证强一致性的同时最大化提高系统可用性
2PC是有数据库来保证回滚，而TCC是应用层实现回滚：为每一个try操作提供一个对应的cancel操作



CAP定理
WEB服务无法同时满足一下3个属性：
一致性(Consistency) ： 客户端知道一系列的操作都会同时发生(生效)，数据一致更新，所有数据变动都是同步的。可以从原子性理解
可用性(Availability) ： 每个操作都必须以可预期的响应结束
分区容错性(Partition tolerance) ： 即使出现单个组件无法可用,操作依然可以完成
具体地讲在分布式系统中，在任何数据库设计中，一个Web应用至多只能同时支持上面的两个属性。显然，任何横向扩展策略都要依赖于数据分区。因此，设计人员必须在一致性与可用性之间做出选择。

zookeeper实现了cap中的cp特性，因为zk集群有leader选举机制，牺牲了短暂的可用性，但是保证了容错性
zk的地址信息变动会通知其他的客户端，要么全成功，要么全失败，类似事务的原子性，实现一致性。



BASE理论
在分布式系统中，我们往往追求的是可用性，它的重要程序比一致性要高，BASE理论，它是用来对CAP定理进行进一步扩充的。BASE理论指的是：
Basically Available（基本可用）
Soft state（软状态）
Eventually consistent（最终一致性）
BASE理论是对CAP中的一致性和可用性进行一个权衡的结果，理论的核心思想就是：我们无法做到强一致，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。


最经典的分布式事务解决方法就是“两段式提交(two-phase commit)”。XA/JTA方案
	在两段式提交过程中，涉及两类角色，协调者(Coordinator)和参与者(Participants)。
	第一个阶段：预提交阶段，也可以称之为投票阶段，一票否决性
	第二个阶段：提交决定阶段。协调者根据上一个阶段的投票结果决定是Commit还是Abort，这个决定是全局性的，会通知到所有的参与者执行最终的决定，并回传一个ack确认信息。
	强一致性的目的，长生命周期的分布式事务就不适合两段式提交。比如旅游订票的过程，中间应该增加重试的机制。
	整个完成才释放资源，锁力度大，性能差
	
	
TCC
TCC包含了三个阶段：Try，Confirm，Cancel，因此而得名「TCC」。一种柔性事务解决方案
	Try: 尝试执行业务
		 完成所有业务检查(一致性)
		 预留必须业务资源(准隔离性)          
	Confirm:确认执行业务
		 真正执行业务
		 不作任何业务检查
		 只使用Try阶段预留的业务资源 
		 Confirm操作要满足幂等性
	Cancel: 取消执行业务
		 释放Try阶段预留的业务资源 
		 Cancel操作要满足幂等性

TCC 其实就是采用的补偿机制，其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作，TCC的Try、Confirm和Cancel操作功能需业务提供，开发成本高。
TCC	数据库层的二阶段提交上提到了应用层来实现，对于数据库来说是一阶段提交，规避了数据库层的2PC性能低下问题

TCC与2PC协议比较：
	 位于业务服务层而非资源层
	 没有单独的准备(Prepare)阶段， Try操作兼备资源操作与准备能力 
	 Try操作可以灵活选择业务资源的锁定粒度(以业务定粒度) 
	 较高开发成本


2PC的强一致性依赖于数据库，而TCC的强一致性依赖于应用层的Commit与cancel




SQL Server 数据库是由两个文件组成的，一个数据库文件和一个日志文件，每次先记录操作日志，再写数据库。



jvm的相关：
	1、程序计数器：可以看做是当前线程执行的字节码行号指示器
		jvm的多线程是通过线程轮流切换并分配处理器执行时间的的方式实现的，任何时刻，一个处理器只会执行一条线程指令。为了切换后恢复正确的执行位置，每条线程需要独立的程序计数器。
		这类内存区域称为“线程私有”的内存
		
	2、	java虚拟机栈：是线程私有的，生命周期与线程相同
		是虚拟机中局部变量的表部分，所需的内存空间在编译时期完成分配，方法运行时期不会改变大小，存放了编译器可知的各种基本数据类型，对象引用和returnadress类型（指向了一条字节码指令的地址）
		这个区域的两种异常情况：
			1.当线程请求的栈深度大于jvm允许的深度，抛出stackoverflowError	递归调用会出错
			2.如果jvm动态扩展时无法申请到足够的内存时会抛出outOfMemoryError   经常的编译class文件的内存不够
		使用-Xss配置栈内存容量，可以减少栈内存容量
		定义大量的本地变量，可增加次方法帧中本地变量表的长度
		
		在单个线程下，无论是由于栈帧太大，还是虚拟机栈容量太小，当内存无法分配的时候，虚拟机抛出的都是stackOverflowError
			
	
	3、本地方法栈(stack)：
		虚拟机栈为虚拟机执行java方法（也就是字节码）服务
		本地方法栈为虚拟机使用到的native方法服务
		
	4、java堆(heap)：
		是jvm中所管理内存中最大的一块，是所有线程共享的内存区域，jvm启动时创建。用来存放对象实例。
		所有对象的实例都要在堆上分配
		java堆是垃圾收集器管理的主要区域，因此也被称为gc堆。现在的收集器基本采用的是分代手机算法（根据对象存活周期的不同，将内存划分成为几个区域），所有java堆中还可以细分为：新生代（MinorGC）和老年代（MajorGC）
		目前主流的虚拟机都是按照可扩展来实现的（通过-Xmx 和-Xms控制），如果堆中没有内存完成实例分配，并且堆也无法再扩展时，将抛出OutOfMemoryError异常
		将堆的最小值-Xms参数和最大值-Xmx参数设置一样可避免堆自动扩展，增加无效的fullgc，浪费时间，即不可扩展
		
		堆中有eden，survivor，和old三个区域，非堆中有code cache和 perm gen
		
		
	5、方法区：
		存放class相关信息，如类名、访问修饰符、常量池、字段描述、方法描述
		各线程共享的内存区域，用于存放已被jvm加载的类信息、常量、静态变量、即是编译器编译后的代码等数据。别名Non-Heap(非堆)。区别于堆内存heap
		可选择固定大小或可扩展，该区域内存回收目标主要是针对常量池的回收和对类型的卸载，
		当方法区无法满足内存分配需求时，将抛出outOfMemoryError		PermGen space
		MaxPermSize，最大方法区容量
		
		1.8之后移除，-XX:PermSize，使用元空间(Metaspace)代替
		
		-XX:permSize 和 -XX:MaxPermSize 配置大小
	
	6、运行时常量池
		属于方法区的一部分，在类加载之后，存放到方法区的运行时常量池中
		
	7、直接内存 	direct memory  
		分配不会受到java堆大小的限制，配置内存容易忽略这块，导致超过物理内存限制，从而导致动态扩展时出现OutOfMemoryError异常
		比如大量的nio操作
		
	jvm重要的三个内存区域：
		java栈，java堆，方法区
		
		
	reference类型通过1.句柄    2直接指针（这种情况直接存储的就是对象地址）     定位java堆中的具体位置

	
	java堆的溢出
		内存映像分析工具分析
		1、内存泄漏			泄漏对象垃圾收集器无法自动回收，
		2、内存溢出			内存中对象必须存活，调节虚拟机的堆参数的配置
	
		内存溢出就是你要求分配的内存超出了系统能给你的，系统不能满足需求，于是产生溢出。

		Java内存泄漏就是没有及时清理内存垃圾，导致系统无法再给你提供内存资源（内存资源耗尽）。

		1.Java内存泄露是说程序逻辑问题,造成申请的内存无法释放.这样的话无论多少内存,早晚都会被占用光的. 最简单的例子就是死循环了.

		2.Java内存泄漏是指在堆上分配的内存没有被释放，从而失去对其控制。这样会造成程序能使用的内存越来越少。

	
	
	栈内存溢出：jvm-37
		每个线程分配到的栈容量越大，可以建立的线程数量自然越少，建立线程时就越容易吧剩下的内存耗尽，
		如果是建立过多线程导致的内存溢出，在不能减少线程数量情况下，只能通过减少最大堆和减少栈容量来换取更多的线程。
	
	

	对类进行增强时，都会使用cglib这类的字节码，增强的类越多，越需要大的方法区来保证动态生成的class可以加载入内存
	
	栈随线程生灭，方法或者线程结束，其内存自然就回收了，但是java堆和方法区不一样。
	堆中存放的是java中的对象实例，已经dead(属于对象是否存活)的对象需要被回收
	
	jvm判断对象是否存活，并不是使用的是1、引用计数算法（相互引用，不成立）
	而是使用的是2、根搜索算法，基本思路是通过一系列名为gc roots 的对象作为起始点，从该节点向下搜索，走过的路径成为引用链，当一个对象到gc roots没有任何引用链相连（即从gc roots到这个对象不可达），则对象不可用将被判定为可回收对象
	
	java中，可作为gc roots对象包括：
		1、虚拟机栈（栈帧中的本地变量表）中的引用对象
		2、方法区中的类静态属性引用对象
		3、方法区中的常量引用对象
		4、本地方法栈中的native方法的引用的对象
		
	finalize()：	
	对象进行根搜索就发现没有与gc roots相连接的引用链，需要看对象是否覆盖finalize(),没有覆盖或者该方法已经被jvm调用过，则对象没必要执行finalize()。
	对象死亡需要经过两次至少两次的标记，一次就是gc roots的不相连接，执行finalize()会对f-queue队列中的对象第二次标记，只要重新与引用链上的任何一个对象建立关联，那么将移除即将回收的集合，即执行finalize()，是对象的自我拯救方法，对象依然可以存活，在被gc时自我拯救，且对象只能执行一次该方法。
		
		
	在堆中，尤其在新生代中，垃圾回收的效率很高，但是在永久代中（只要是废弃常量和无用的类），效率很低，
	
	新生代中：主要是用来存放新生的对象。一般占据堆的1/3空间。由于频繁创建对象，所以新生代会频繁触发MinorGC进行垃圾回收。
		对象优先在Eden区分配
		Eden区：Java新对象的出生地(如果新创建的对象占用内存很大，则直接分配到老年代)。
		ServivorTo：保留了一次MinorGC过程中的幸存者。
		ServivorFrom：上一次GC的幸存者，作为这一次GC的被扫描者。
		默认Eden与单个Survivor默认比例是8:1
		
	老年代的对象比较稳定，所以MajorGC不会频繁执行。

	在进行MajorGC前一般都先进行了一次MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足够大的连续空间分配给新创建的较大对象时也会提前触发一次MajorGC进行垃圾回收腾出空间。
	
	内存分配与回收策略
		对象内存分配，往大方向上讲，就是在堆上分配，对象主要分配在新生代的eden区上
		1、对象优先在eden分配
			当Eden区内存不够的时候就会触发MinorGC，对新生代区进行一次垃圾回收。
		2、大对象直接进入老年代
			指的是需要大量连续内存空间的java对象，典型的是很长的字符串和数组，比如byte[]，
		3、长期存活的对象将进入老年代
			默认gc后年龄计数器+1，达到15进入老年代，参数可配置
		4、动态对象年龄判断
			当年大于survivor空间的一半，大于等于该年龄的直接进入老年代
		5、空间分配担保
			发生minor GC,jvm会检测室之前晋升到老年代的平均值大小，再根据老年代的剩余空间大小，够就开启担保（避免频繁full gc），允许就执行minor gc，不允许就full gc，不够直接full gc，如果担保失败，也进行full gc。
			
			
	虽然java的垃圾回收机制仅是回收堆区的资源，而对于非堆区无效，这种只能凭借开发人员自身的约束来解决。（堆区有java回收机制、非堆区开发人员能够很好的解决），
	配置堆区：-Xms 、-Xmx、-XX:newSize、-XX:MaxnewSize、-Xmn
	配置非堆区：-XX:PermSize、-XX:MaxPermSize
	
内存溢出：	
	第一种OutOfMemoryError： PermGen space   永久区内存溢出 修改PermSize  MaxPermSize，又叫非堆内存溢出，永久保存区域是存放class信息和meta信息，分配了后，jvm是不会去回收的
	发生这种问题的原意是程序中使用了大量的jar或class，使java虚拟机装载类的空间不够，与Permanent Generation space有关。解决这类问题有以下两种办法：
	1. 增加java虚拟机中的XX:PermSize和XX:MaxPermSize参数的大小，其中XX:PermSize是初始永久保存区域大小，XX:MaxPermSize是最大永久保存区域大小。
	如针对tomcat6.0，在catalina.sh 或catalina.bat文件中一系列环境变量名说明结束处（大约在70行左右） 增加一行：JAVA_OPTS=" -XX:PermSize=64M -XX:MaxPermSize=128m"
	如果是windows服务器还可以在系统环境变量中设置。感觉用tomcat发布sprint+struts+hibernate架构的程序时很容易发生这种内存溢出错误。使用上述方法，我成功解决了部署ssh项目的tomcat服务器经常宕机的问题。
	2. 清理应用程序中web-inf/lib下的jar，如果tomcat部署了多个应用，很多应用都使用了相同的jar，可以将共同的jar移到tomcat共同的lib下，减少类的重复加载。

	第二种OutOfMemoryError：  Java heap space 堆内存溢出 Xms 和Xmx
	发生这种问题的原因是java虚拟机创建的对象太多，在进行垃圾回收之间，虚拟机分配的到堆内存空间已经用满了，与Heap space有关。解决这类问题有两种思路：
		1. 检查程序，看是否有死循环或不必要地重复创建大量对象。找到原因后，修改程序和算法。
		2. 增加Java虚拟机中Xms（初始堆大小）和Xmx（最大堆大小）参数的大小。如：set JAVA_OPTS= -Xms256m -Xmx1024m
		
	定位永久区的内存溢出，jstat -gcpermcapacity pid  ,数据都是以kb为单位的
	内存配置默认是物理内存的1/64;JVM最大分配的内存由-Xmx指定，默认是物理内存的1/4。
	默认空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制;空余堆内存大于70%时，JVM会减少堆直到-Xms的最小限制。因此服务器一般设置-Xms、-Xmx相等以避免在每次GC 后调整堆的大小
		
		
jvm的性能监控域处理工具   jconsole 和jvisualVM 可视化监控工具，目前主推的是jvisualVM这款的功能
	jps：显示指定系统所有的hotspot jvm进程 常用的是使用-l查看完整的类路径和jar包的位置
	jstat：手机hotspot jvm各方面（类装载，内存，垃圾收集）的运行数据				运行期定位jvm性能首选
	jinfo： 显示虚拟机的配置信息
	jmap：生成jvm的内存转储快照（heapdump文件），java内存映像工具
	jhat：分析heapdump文件，会建立一个http/htm服务器，让用户可在浏览器上查看分析结果
	jstack：显示jvm的线程快照  可定位线程长时间未响应的原因
	
	后续也可以使用VisualVM和Jconsole可视化监视工具监控系统的内存
	new byte[64*1024],创建一个64kb大小的字节数组
	处于作用域中的gc是无效的，比如gc在测试主函数内
	
	JConsole远程连接配置 	https://blog.csdn.net/dumbant/article/details/80392506
	
	eclipse的启动优化，中使用-Xverify:none，禁止掉启动过程的字节码验证,
	在eclipse.in 中
		-Xverify:none			禁止掉启动过程的字节码验证,//属于通联钱包的需求,直接提现相关金额
	                		UserResult userResult = userInfoService.getUserInfoByUserCode(null, request.getToAcctNo());
	                		//1、校验用户资金平衡		2、金额校验、提现校验  3、认证校验
//	                		Result vResult = userManagerService.userAccountValidate(request.getToAcctNo());//放过,log_user_trade无法校验，
	                		Result vResult = new Result();
	                		vResult.setSuccess(true);
	                		String withDrawMoney=String.valueOf(OrderCodeUtil.fengToYuan(request.getTranAmt()));
	                		Result valiResult = withdrawService.validateAmount(withDrawMoney, userResult.getBalance(), userResult,"0");
	                		
	                		if(vResult.isSuccess() && StringConstants.ONE.equals(userResult.getAuthFlagDto()) && valiResult.isSuccess()){
	                    		userResult.setCardNo("0123456789");//默认卡号123
	                    		// 提现,默认pc端的余额提现
	                    		Result submitResult = withdrawService.submit(userResult, withDrawMoney, "11",null,"0");
	                    		if (!submitResult.isSuccess()) {
	                    			//短信通知
	                    			String handleMsg=String.format("账户：%s提现处理错误,错误信息:%s,单号:%s",request.getToAcctNo(),submitResult.getMessage(),xyeOrderExtSnStr);
	                    			LOGGER.info("通联钱包验收提现处理错误:"+handleMsg);
	                    			ExceptionSmsUtil.send("通联钱包验收提现处理错误---","handleExceptionMsg:"+submitResult.getMessage(), xyeOrderExtSnStr,request.getToAcctNo(),null,request.getTranAmt());
	                    		}
		-XX:+DisableExplicitGC  取消显示的system.gc
	实际测试效果不是很明显

class加载的问题
	编译器将java代码编译成存储字节码的class文件（对应的结构，顺序和长度都是固定的），就可以在jvm中运行
	
jvm的类加载机制：jvm把描述类的数据从class文件加载到内存，并对数据进行校验，转换解析和初始化，最终形成可被jvm直接使用的java类型，	
	对于静态字段，只有直接定义这个字段的类才会初始化，因此通过其子类来引用父类中的定义的静态字段，只会触发父类的初始化而不会触发子类的初始化
	静态代码块static{}用来初始化信息
	加载的几个阶段：加载，验证，准备，解析，初始化，使用，卸载，前5个就是类的加载过程，2-4属于连接
	加载：1.获取类的二进制字节流，2.将其代表的静态存储结构转化为方法区的运行时数据结构，3.在堆中生成代表该类的class对象，作为方法区这些数据的访问入口。
	验证：确保class文件的字节流中包含的信息符合当前虚拟机的要求，并不会危害jvm自身安全
	准备：在方法区中，为类变量(被static修饰的变量，不包括实例变量)分配内存并设置类变量的初始值，实例变量将会在对象实例化时随着对象一起分配在java堆中，
	解析：jvm将常量池内存内的符号引用替换为直接引用的过程
	初始化：真正开始执行类中定义的java程序代码(或者说是字节码)
	
	
	
	对于任意一个类，都需要有加载它的类加载器和这个类本省一同确立其在jvm中的唯一性。
	
	在jvm的角度将，只存在两种不同的类加载器，一种是启动类加载器，另一种是所有其他的类加载器（独立于虚拟机外部，全部继承自抽象类java.lang.classLoader），
	
	代码编译的结果从本地机器码转变为字节码，是存储格式发展的一小步，确实编程语言发展的一大步
	
	
	volatile保证了多线程操作时变量的可见性，而普通变量则不能保证这一点
	线程是cpu调度的最基本单位
	
	
	final这类的不可变对象一定是线程安全的。典型的String类就是
	
	线程安全的实现方法
		1互斥同步 主要的问题就是进行线程阻塞和唤醒带来的性能问题，也称为阻塞同步
			典型的是synchronized
			
	一个thread对象中都有一个threadlocalmap的对象，该对象存储了一组以threadlocal.threadlocalhashcode为键，以本地线程变量为值的k-v值对，这样就保证了线程变量的唯一性
	Thread.ThreadLocalMap<ThreadLocal, Object>;
	
	
	
分布式锁一般有三种实现方式：1. 数据库乐观锁；2. 基于Redis的分布式锁；3. 基于ZooKeeper的分布式锁。

满足的条件
	系统是一个分布式系统（关键是分布式，单机的可以使用ReentrantLock或者synchronized代码块来实现）
	共享资源（各个系统访问同一个资源，资源的载体可能是传统关系型数据库或者NoSQL）
	同步访问（即有很多个进程同事访问同一个共享资源。没有同步访问，谁管你资源竞争不竞争）
	

	
	
	
aop事务的动态代理实现：

/**
 * @ClassName: TransactionHandler
 * @Description: 动态代理封装事务
 * @author: 十期-牛迁迁
 * @date: 2015-10-11 下午2:59:15
 */
public class TransactionHandler implements InvocationHandler
{
    private Object targetObject;

    public Object newProxyInstance(Object targetObject)
    {
        this.targetObject = targetObject;
        //使用Proxy类，通过反射得到一个动态的代理对象
        return Proxy.newProxyInstance(targetObject.getClass().getClassLoader(),
                targetObject.getClass().getInterfaces(), this);
    }

     //在invoke方法中做一些其他操作
    @Override
    public Object invoke(Object proxy, Method method, Object[] args)
            throws Throwable
    {
        Connection conn = null;
        Object ret = null;
        try
        {
            // 从ThreadLocal中取得Connection
            conn = ConnectionManager.getConnection();
            if (method.getName().startsWith("add")
                    || method.getName().startsWith("del")
                    || method.getName().startsWith("modify"))
            {
                // 手动控制事务提交
                ConnectionManager.beginTransaction(conn);
            }
            // 调用目标对象的业务逻辑方法
            ret = method.invoke(targetObject, args);
            if (!conn.getAutoCommit())
            {
                // 提交事务
                ConnectionManager.commitTransaction(conn);
            }
        }
        catch (ApplicationException e)
        {
            // 回滚事务
            ConnectionManager.rollbackTransaction(conn);
            throw e;
        }
        catch (Exception e)
        {
            e.printStackTrace();
            if (e instanceof InvocationTargetException)
            {
                InvocationTargetException ete = (InvocationTargetException) e;
                throw ete.getTargetException();
            }
            // 回滚事务
            ConnectionManager.rollbackTransaction(conn);
            throw new ApplicationException("操作失败！");
        }
        finally
        {
            ConnectionManager.closeConnection();
        }
        return ret;
    }
	
	
网关路由的mvc中requestmapping具体实现，
	Spring是怎样检测并处理我们@RequestMapping注解的：?
	扫描所有注册的Bean?遍历这些Bean，依次判断是否是处理器，并检测其HandlerMethod?遍历Handler中的所有方法，
	找出其中被@RequestMapping注解标记的方法。?获取方法method上的@RequestMapping实例。?
	检查方法所属的类有没有@RequestMapping注解??将类层次的RequestMapping和方法级别的RequestMapping结合? (createRequestMappingInfo)?当请求到达时，
	去urlMap中需找匹配的url，以及获取对应mapping实例，然后去handlerMethods中获取匹配HandlerMethod实例。?将RequestMappingInfo实例以及处理器方法注册到缓存中。

	
	
	使用@Aspect的aop代理中，暂时默认@before和@after是无法终止原来的方法的，只有@around可以终止原来的方法，截到具体的方法后，直接return 对象即可终止方法，

	dubbo的负载均衡：
		
		4种策略
			1、随机
			2、轮询
			3、按照活跃数少的优先调用，最少活跃调用数，相同活跃数的随机，活跃数指调用前后计数差。使慢的提供者收到更少请求，因为越慢的提供者的调用前后计数差会越大。
			3、hash一致：一致性hash，默认对第一个参数hash，相同参数请求发送统一提供者
		
		3、权重，可以在dubbo中配置，也可以在dubbo后台管理中配置权重
	

	
根据基本的线程知识，可以不加思索的想到下面的一些方法： 
	1、秒杀在技术层面的抽象应该就是一个方法，在这个方法里可能的操作是将商品库存-1，将商品加入用户的购物车等等，在不考虑缓存的情况下应该是要操作数据库的。那么最简单直接的实现就是在这个方法上加上synchronized关键字，通俗的讲就是锁住整个方法； 
	2、锁住整个方法这个策略简单方便，但是似乎有点粗暴。可以稍微优化一下，只锁住秒杀的代码块，比如写数据库的部分； 
	3、既然有并发问题，那我就让他“不并发”，将所有的线程用一个队列管理起来，使之变成串行操作，自然不会有并发问题。
	
	
分布式锁的必要性：
	如果不同的系统或是同一个系统的不同主机之间共享了一个或一组资源，那么访问这些资源的时候，往往需要互斥来防止彼此干扰来保证一致性，在这种情况下，便需要使用到分布式锁。
	
	对接接口的安全性，1、使用同一的token校验，2、增加ip白名单过滤，3、获取动态口令，优先时间60秒
	
	
	
java.net.SocketTimeoutException: connect timed out

系统间的调用，会出现超时的情况，关键的回调，需要做job的补偿回调。对于及时性比较高的，需要在超时间内，得到补偿信息

一直以为spring的ioc容器生成的对象都是代理对象，其实这个是错误的。spring ioc默认的都是原生对象  只有通过aop增强的对象才是代理对象



MyBatis 拦截器 （实现分页功能） 
	@Intercepts({ @Signature(type = StatementHandler.class, method = "prepare", args = { Connection.class }) })
	具体的原理是在StatementHandler上进行拦截，并进行代理，实现的思路是StatementHandler-> BOUNDSQL-->加工boundsql-->return ivk.proceed();
	
	
	MapperScannerConfigurer可以对basePackage下所有Mapper接口创建代理对象
	
	SqlSessionFactoryBean,主要是把*Mapper*.xml文件与*Mapper*.java加载进来，根据namespace加载对应的接口类到MapperRegistry，把方法名与*Mapper*.xml里的Select id对应起来等等。MapperRegistry相当于是一个缓存，后面创建代理对象是会用到。
	 
	创建一个代理核心MapperProxy，并使用jdk的动态代理创建代理类，将sqlsession封装在invoke方法中
	public static <T> T newMapperProxy(Class<T> mapperInterface, SqlSession sqlSession) {
    ClassLoader classLoader = mapperInterface.getClassLoader();
    Class<?>[] interfaces = new Class[]{mapperInterface};
    MapperProxy proxy = new MapperProxy(sqlSession);
    return (T) Proxy.newProxyInstance(classLoader, interfaces, proxy);
  }

	
	
tomcat简单额session缓存共享
	1.Tomcat-redis-session-manager
	2.配置tomcat配置文件context.xml
	3.3、添加Tomcat-redis-session-manager的jar包到tomcat/lib目录下，需要的jar包如下：
			commons-pool2-2.2.jar
　　　　	jedis-2.5.2.jar
　　　　	tomcat-redis-session-manage-tomcat7.jar




hashmap的扩容问题
	底层是数组+链表的结构，数组的长度是固定的，当元素大于长度的时候就需要扩容，叫做resize，默认的数组大小是16。这个扩容过程有点像jvm的动态增加内存一样
	HashMap()：构建一个初始容量为 16，负载因子为 0.75 的 HashMap。超过16*0.75=12，就扩容一倍，比较消耗性能，最好指定已知的初始容量，和合适的负载因子
	
HashMap 可以接受 null 键值和值，而 HashTable 则不能
HashMap 使用 LinkedList 来解决hash碰撞问题，其中存放改的是entry


优化hash冲突的方法，。一些优秀的开发者会指出使用不可变的、声明作 final 的对象，并且采用合适的
equals()和 hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够
缓存不同键的 hashcode，这将提高整个获取对象的速度，使用 String，Interger 这样
的 wrapper 类作为键是非常好的选择。


不可变性
是必要的，因为为了要计算 hashCode()，就要防止键值改变，如果键值在放入
时和获取时返回不同的 hashcode 的话，那么就不能从 HashMap 中找到你想
要的对象。不
	
	主要区别
	1）.HashTable 的方法前面都有 synchronized 来同步，是线程安全的；HashMap 未经同步，是非线程安全的。
	2）.HashTable 不允许 null 值(key 和 value 都不可以) ；HashMap 允许 nul(key 和 value 都可以
	
	
	
	ConcurrentHashMap 和 Hashtable 主要区别就是
	围绕着锁的粒度以及如何锁,可以简单理解成把一个大的 HashTable 分解成多个，形成了锁分离。
	如图:而 Hashtable 的实现方式是---锁整个 hash
	
	
	
	
作为键的条件，是创建之后的hashcode就不能变了
	
	集合在遍历时候，不能修改本身否则或发生并发修改异常
	
多线程的实现
继承 Thread 类、实现 Runnable 接口Future 实现有返回结果的多线




在 java 中有以下 3 种方法可以终止正在运行的线程：
1. 使用退出标志，使线程正常退出，也就是当 run 方法完成后线程终止。
2. 使用 stop 方法强行终止，但是不推荐这个方法，因为 stop 和 suspend 及 resume 一样都是过期作废的方法。
3. 使用 interrupt 方法中断线




27.如何保证线程安全
对非安全的代码进行加锁控制；
使用线程安全的类；
多线程并发情况下，线程共享的变量改为方法级的局部变



Lock的锁定是通过代码实现的，lock是一个类，通过该类可实现同步访问，而 synchronized 是java的关键字，是在 JVM 层面上实现的，
synchronized 会自动释放锁，而 Lock 一定要手工释放，且须在finally 中释放。Lock 锁的范围有局限性，块范围，而 synchronized 可以锁住块、对象、类



synchronized 缺点：
	代码块被 synchronized 修饰，当一个线程获取了对应的锁，并执行该代码块时，其他线程便只能一直等待，等待获取锁的线程释放锁，而这里获取锁的线程释放锁只会有两种情况：
	 1）获取锁的线程执行完了该代码块，然后线程释放对锁的占有；
	 2）线程执行发生异常，此时 JVM 会让线程自动释放锁。
	 那么如果这个获取锁的线程由于要等待 IO 或者其他原因（比如调用 sleep 方法）被阻塞了，但是又没有释放锁，其他线程便只能干巴巴地等待，影响程序执行效率
	 
	 意思就是lock可以控制等待的时间
	 
	 还有尝尽个就是读写操作的，使用synchronized关键字的话，多个读操作就要相互等待，浪费资源，
	 
因此就需要有一种机制可以不让等待的线程一直无期限地等待下去（比如只等待一定的时间或者能够响应中断），通过 Lock 就可以办到



Lock lock = new ReentrantLock(); //注意这个地方
在 insert 方法中的 lock 变量是局部变量，每个线程执行该方法时
都会保存一个副本，那么理所当然每个线程执行到 lock.lock()处获取的是不同的锁，所以就不会发生冲突。

5.Lock 和 synchronized 的选择
	 1）Lock 是一个接口，而 synchronized 是 Java 中的关键字，synchronized 是内置的语言实现；
	 2）synchronized 在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而 Lock 在发生异常时，如果没有主动通过 unLock()去释放锁，则很可能造成死锁现象，因此使用 Lock 时需要在 finally 块中释放锁；
	 3）Lock 可以让等待锁的线程响应中断，而 synchronized 却不行，使用synchronized 时，等待的线程会一直等待下去，不能够响应中断；
	 4）通过 Lock 可以知道有没有成功获取锁，而 synchronized 却无法办到。
	 5）Lock 可以提高多个线程进行读操作的效率。

1、可重入锁：synchronized 和 ReentrantLock 都是可重入锁，进入对象的第二个锁方法，不需要重新获取锁
	class MyClass {
		public synchronized void method1() {
		method2();
		}
		public synchronized void method2() {
		}
	}
2、可中断锁	synchronized 就不是可中断锁，而 Lock 是可中断锁。

3、公平锁
	公平锁即尽量以请求锁的顺序来获取锁。比如同是有多个线程在等待一个锁，当这个
	锁被释放时，等待时间最久的线程（最先请求的线程）会获得该所，这种就是公平锁。
	
	synchronized 就是非公平锁，它无法保证等待的线程获取锁的顺序。
	ReentrantLock 和 ReentrantReadWriteLock，它默认情况下是非公平锁，但是可以设置为公平锁
	
4、读写锁
	ReentrantReadWriteLock并未实现 Lock 接口，它实现的是ReadWriteLock 接口
	可以通过 readLock()获取读锁，通过 writeLock()获取写锁。


	ConcurrentHashMap 锁住的不是全部的hash表，而是以多个segment的形式锁住单独的区域， 相当于把之前的数组分成多个segment，
	segment 可以看成是 HashMap 的一个部分，（ConcurrentHashMap 基于concurrencyLevel 划分出了多个 segment 来对 key-value 进行存储）每次操作都只对当前segment 进行锁定，从而避免每次 put 操作锁住整个 map。

	
	
	线程修改变量的过程：
		每一个线程运行时都有一个线程栈，线程栈保存了线程运行时候变量值信息。
		当线程访问某一个对象时候值的时候，首先通过对象的引用找到对应在堆内存
		的变量的值，然后把堆内存变量的具体值 load 到线程本地内存中，建立一个变
		量副本，之后线程就不再和对象在堆内存变量值有任何关系，而是直接修改副
		本变量的值，在修改完之后的某一个时刻（线程退出之前），自动把线程变量
		副本的值回写到对象在堆中变量。这样在堆中的对象的值就产生变化了
		
		Java内存模型规定了所有的变量都存储在主内存中。
		每条线程有自己的工作内存，其中使用的变量是主内存中的拷贝的变量副本，线程对变量的所有操作（读取，赋值）都必须在工作内存中进行。
		不同线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。
		
		
		
	ConcurrentHashMap 默认情况下采用将数据分为 16 个段进行存储，并且每个段各自拥有自
	己的锁，锁仅用于 put 和 remove 等改变集合对象的操作，基于 voliate 及 hashEntry 链表
	的不变性实现读取的不加锁?
	
	方法区用于存放 Class 相关信息，需要足够大内存的方法区用于保证动态生成的Class可以加载入内存。
	
新生代中的算法:停止-复制
年轻代可以分为 3 个区域：Eden 区（伊甸园，亚当夏娃偷吃禁果生娃娃的地方，用来表示内存首次分配的区域，再 贴切不过）
和两个存活（Survivor 0 、Survivor 1,并且两个servivor区中必须有一个是空白的）内存分配过程为，最终gc后存活的就进入老年代，
这种垃圾回收的方式就是著名的“停止-复制（Stop-and-copy）”清理法（将 Eden 区和一个 Survivor 中仍然存活的对象拷贝到另一个 Survivor 中），

需要明确一点，就是在新生代采用的停止复制算法中，“停 止（Stop-the-world）”的意义是在回收内存时，需要暂停其他所 有线程的执行。这个是很低效的，现在的各种新生代收集器越来越优化这一点，但仍然只是将停止的时间变短，并未彻底取消停止。


	

老年代中的算法：标记-整理
	如果使用停止-复制算法，则相当低效。一般，老年代用的算法是标记-整理算法，即：标记出仍然存活的对象（存在引用的），将所有存活的对象向一端移动，以保证内存的连续

JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块Survivor区域是空闲着的,复制完就清空。存活区默认切换15次就会进入老年代了。
	
	
	
	
 方法区（永久代）： 永久代的回收有两种：常量池中的常量，无用的类信息，常量的回收很简单，没有引用了就可以被回收。对于无用的类进行回收，必须保证 3 点：
 1. 类的所有实例都已经被回收
 2. 加载类的 ClassLoader 已经被回收
 3. 类对象的 Class 对象没有被引用（即没有通过反射引用该类的地
	

sleep()方法是 Thread 类中方法，而 wait()方法是 Object 类中的方法。
sleep()方法导致了程序暂停执行指定的时间，让出 cpu 该其他线程，但是他的
监控状态依然保持者，当指定的时间到了又会自动恢复运行状态，
sleep()方法，线程不会释放对象锁。
wait()方法，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用 notify()方法后本线程才进入对象锁定池准备。


当两个进程在进行远程通信时，彼此可以发送各种类型的数据。无论是何种类型的数据，都会以二进制序列的形式在网络上传送。所以需要序列化和反序列化。


一.PreparedStatement 是预编译的,对于批量处理可以大大提高效率. 也叫JDBC 存储过程
二.使用Statement 对象。在对数据库只执行一次性存取的时侯，用Statement 对象进行处理。PreparedStatement对象的开销比 Statement 大，对于一次性操作并不会带来额外的好处。
三.statement 每次执行 sql 语句，相关数据库都要执行 sql 语句的编译，preparedstatement 是预编译得,preparedstatement 支持批


预编译可以多次执行根据参数不同sql不同

web 服务器在调用 doFilter 方法时，会传递一个 filterChain 对象进来，filterChain 对象是
filter 接口中最重要的一个对象，它也提供了一个 doFilter 方法，开发人员可以根据需求决
定是否调用此方法，调用该方法，则 web 服务器就会调用 web 资源的 service 方法，即
web 资源就会被访问，否则 web 资源不会被访问



权限相关的东西：用户-角色-路径

装饰者模式（Decorator）,使用例子：
	ServletRequestWrapper 和 HttpServletRequestWrapper 提供对 request 对象进行包装的
	方法，但是默认情况下每个方法都是调用原来 request 对象的方法，
	也就是说包装类并没有对 request 进行增强在这两个包装类基础上，继承 HttpServletRequestWrapper ，覆盖需要增强的方法即可
	
	
	
	
二级缓存
MyBatis 包含一个非常强大的查询缓存特性,它可以非常方便地配置和定制。默认情况下是没有开启缓存的。
1. 映射语句文件中的所有 select 语句将会被缓存。
2. 映射语句文件中的所有 insert,update 和 delete 语句会刷新	
	
	
	
	
	
一级缓存也称本地缓存，sqlSession级别的缓存。一级缓存是一直开启的；与数据库同一次回话期间查询到的数据会放在本地缓存中。
如果需要获取相同的数据，直接从缓存中拿，不会再查数据库。有点事务开启到提交这期间的过程。
二级缓存：全局缓存；基于namespace级别的缓存。一个namespace对应一个二级缓存。
　　　　　　工作机制：1.一个会话，查询一条数据，这个数据会被放在当前会话的一级缓存中。
　　　　　　　　　　　2,如果会话被关闭了，一级缓存中的数据会被保存带二级缓存。新的会话查询信息就会参照二级缓存。
　　　　　　　　　　　	不同的namespace查出的数据会放在自己对应的缓存中。
　　　　　　　　　　　效果：查出的数据首先放在一级缓存中，只有一级缓存被关闭或者提交以后，一级缓存数据才会转移到二级缓存



事务的第一个方面是传播行为（propagation behavior）。当事务方法被另一个事务方法调用时，必须指定事务应该如何传播

嵌套事务一个非常重要的概念就是内层事务依赖于外层事务。外层事务失败时，会回滚内层事务所做的动作。而内层事务操作失败并不会引起外层事务的回，两个方法之间有个savepoint的概念，这个就是嵌套事务的关键点。
	默认事务只有遇到运行期异常时才会回滚，
	

Spring 提供了对编程式事务和声明式事务的支持：
	编程式事务允许用户在代码中精确定义事务的边界，而声明式事务（基于 AOP）有助于用户将操作与事务规则进行解耦。
	简单地说，编程式事务侵入到了业务代码里面，但是提供了更加详细的事务管理，即使用 TransactionTemplate,直接事务模板处理，可以返回自定义的result。
	而声明式事务由于基于 AOP，所以既能起到事务管理的作用，又可以不影响业务代码的具体，即使用aop事务，@transactional
	
	1、配置事务管理器	transactionManager
	2、配置事务拦截器 	transactionInterceptor 	配置事务的传播属性
	
	
	一：事务的拦截器
	二：tx aop哦诶之
	三：全注解
	
	
	事务拦截器的aop配置,tx配置，这种应该是xml中比较合适的通配方法
	 <tx:advice id="txAdvice" transaction-manager="transactionManager">
		 <tx:attributes>
			<tx:method name="*" propagation="REQUIRED" />
		 </tx:attributes>
	 </tx:advice>
	 <aop:config>
		<aop:pointcut id="interceptorPointCuts" expression="execution(* com.bluesky.spring.dao.*.*(..))" />
		<aop:advisor advice-ref="txAdvice" pointcut-ref="interceptorPointCuts" /> 
	 </aop:config>
	
	
	
	
	全注解事务，方便可用
	<tx:annotation-driven transaction-manager="transactionManager"/>
	一般拦截器
	<context:annotation-config />
    <context:component-scan base-package="com.oumyye"/>
    <bean id="logInterceptor" class="com.oumyye.aop.LogInterceptor"></bean>
    <aop:config>
        <aop:pointcut expression="execution(public * com.oumyye.service..*.add(..))" id="servicePointcut"/>
        <aop:aspect id="logAspect" ref="logInterceptor">
            <aop:before method="before"  pointcut-ref="servicePointcut" />
        </aop:aspect>
    </aop:config>
	
	在springmvc中，DispatcherServlet 根据 HandlerMapping 找到对应的 Handler,将处理权交给 Handler
	（Handler 将具体的处理进行封装），再由具体的 HandlerAdapter 对 Handler 进行具体的调用。
	
	
分布式锁的相关：
	可行的一些方案：
	1、基于数据库资源表的分布式锁，这里是乐观锁(版本号的更新概念)
	2、使用了Redis 的 setnx()和 expire()的分布式锁解决的问题
	3、使用了 memecahed 的 add()方法(不常用)
	4、使用 zookeeper，用于分布式锁。(不常用)
	
	
	ReentrantLock 的 lock 和 unlock 要求必须是
	在同一线程进行，而分布式应用中，lock 和 unlock 是两次不相关的请求，因此肯
	定不是同一线程，因此分布式锁中，无法使用 ReentrantLock。

	乐观锁的：
		(1). 这种操作方式，使原本一次的 update 操作，必须变为 2 次操作: select 版本号一次；update 一次。增加了数据库操作的次
		(2).基于数据库操作，在高并发的要求下，对数据库连接的开销一定是无法忍受的
	
	使用redis的锁实现分布式的相关操作：
		1. setnx(lockkey, 1) 如果返回 0，则说明占位失败；如果返回 1，则说明占位成功
		2. expire()命令对 lockkey 设置超时时间，为的是避免死锁问题。
		3. 执行完业务代码后，可以通过 delete 命令删除 key。
		方案的弊端就是，在设置超时时间的时候，会出现宕机，这样就会出现死锁问题。
		**********redis实现的原理***************
		所以如果要对其进行完善的话，可以使用 redis 的 setnx()、get()和 getset()方法来实现分布式锁。方案待定，不一定适用。
		
		1. setnx(lockkey, 当前时间+过期超时时间) ，如果返回 1，则获取锁成功；如果返回 0 则没有获取到锁，转向 2。
		2. get(lockkey)获取值 oldExpireTime ，并将这个 value 值与当前的系统时间进行比较，如果小于当前系统时间，则认为这个锁已经超时，可以允许别的请求重新获取，转向 3。
		3. 计算 newExpireTime=当前时间+过期超时时间，然后 getset(lockkey, newExpireTime) 会返回当前 lockkey 的值 currentExpireTime。
		4. 判断 currentExpireTime 与 oldExpireTime 是否相等，如果相等，说明当前getset 设置成功，获取到了锁。如果不相等，说明这个锁又被别的请求获取走了，那么当前请求可以直接返回失败，或者继续重试。
		5. 在获取到锁之后，当前线程可以开始自己的业务处理，当处理完毕后，比较自己的处理时间和对于锁设置的超时时间，如果小于锁设置的超时时间，则直接执行delete 释放锁；如果大于锁设置的超时时间，则不需要再锁进行处
	
	connection 类本身提供了对事务的支持，可以通过设置connection 的 autocommit 属性为 false 然后显式的调用 commit 或 rollback 方法来实现。
	
	使用 select…for update 会把数据给锁住，不过我们需要注意一些锁的级别，MySQL InnoDB 默认行级锁。行级锁都是基于索引的，如果一条 SQL 语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意
	
	注入过程的工作方式是提前终止文本字符串，然后追加一个新的命令。 提前;-- 结束
	防止sql注入的方法：
	1、普通用户与系统管理员用户的权限要有严格的区分。普通用户不能有Drop Table等表结构的权限
	2、强迫使用参数化语，不能让sql直接嵌入进去,参数化的语句使用参数而不是将用户输入变量嵌入到 SQL 语句中。类似的就是sql中的#和$
	3、加强对用户输入内容的检查与验证，在 SQLServer 数据库中，有比较多的用户输入内容验证工具，检查输入内容的合法性，比如拒绝包含二进制数据、转义序列和注释字符的输入内等
	   测试用户输入内容的大小和数据类型，强制执行适当的限制与转换。这即有助于防止有意造成的缓冲区溢出，对于防治注入式攻击有比较明显的效果
	   故始终通过测试类型、长度、格式和范围来验证用户输入，过滤用户输入的内容。这是防止 SQL 注入式攻击的常见并且行之有效的措施
	   
		如果管理员采用了 Parameters 这个集合的话，则用户输入的内容将被视
		为字符值而不是可执行代码。即使用户输入的内容中含有可执行代码，则数据库也会过滤
		掉。因为此时数据库只把它当作普通的字符来处理。使用 Parameters 集合的另外一个优
		点是可以强制执行类型和长度检查，范围以外的值将触发异常。
		
	在经常使用在 WHERE 子句中的列上面创建索引，加快条件的判断速度
		
	如果索引是建立在多个列上, 只有在它的第一个列(leading column)被 where 子句引用时,优化器才会选择使用该索引. 这也是一条简单而重要的规则，当仅引用索引的第二个列时,优化器使用了全表扫描而忽略了索引
		
	索引有两个特征，即唯一性索引和复合索
	在复合索引中，列的排列顺序是非常重要的，因此要认真排列列的顺序，原则上，应该
	首先定义最唯一的列，例 如在（COL1，COL2）上的索引与在（COL2，COL1）上的索引是
	不相同的，因为两个索引的列的顺序不同；为了使查询优化器使用复合索引，查询语 句中的
	WHERE 子句必须参考复合索引中第一个列；当表中有多个关键列时，复合索引是非常有用
	的；使用复合索引可以提高查询性能，减少在一个表中所创建的 索引数量
	
	where 语句中索引独立出现，索引才会起作用，不要放在表达式中(如: 转换函数一般放在值那边，不要放在列那边)，或发生不合适的隐式转换

	1. 如果条件中有 or，即使其中有条件带索引也不会使用(这也是为什么尽量少用 or 的原(注意：要想使用 or，又想让索引生效，只能将 or 条件中的每个列都加上索引)
	2.对于多列索引，不是使用的第一部分，则不会使用索引
	3.like 查询是以%开头
	4.如果列类型是字符串，那一定要在条件中将数据使用引号引用起来,否则不使用
	5.如果 mysql 估计使用全表扫描要比使用索引快,则不使用
	
	
	HSET key field value 设置域值 常用的是字符串类型， 这边使用的是散列类型，相当于以field为key，key-value为value，其他的还有散列和集合类型
	
	公私钥，公钥是钥匙，私钥是锁
	
	https的传输使用的是证书，证书之间传递相当于加密了一个公用的私钥，通过私钥，两者之间实现，信息的传输,相关的配置是tomcat和nginx的使用
	用约定好的HASH方式（如md5），把握手消息取HASH值，  然后用 随机数加密 “握手消息+握手消息HASH值(签名)”  并一起发送给服务端
    使用加密签名的方式，用于验证握手消息在传输过程中没有被篡改过。
	这样就完成了一次请求，后续是用公用的随机key使用对称加密算法进行加密即可
	
	握手的时候使用的非对称加密算法 ，用来加密握手之后的请求和应答
	传输信息的时候使用的对称加密，
	保证数据的完整性用的是hash算法(数字签名)
	
	1.客户端发送自己支持的加密规则给服务器，代表告诉服务器要进行连接了
	2.服务器从中选出一套加密算法和hash算法以及自己的身份信息(地址等)以证书的形式发送给浏览器，证书中包含服务器信息，加密公钥，证书的办法机构
	3.客户端收到网站的证书之后要做下面的事情： 
		验证证书的合法性
		如果验证通过证书，浏览器会生成一串随机数，并用证书中的公钥进行加密
		用约定好的hash算法计算握手消息，然后用生成的密钥进行加密，然后一起发送给服务器
	4.服务器接收到客户端传送来的信息，要求下面的事情： 
		用私钥解析出密码，，用密码解析握手消息，验证hash值是否和浏览器发来的一致
		使用密钥加密消息，回送
	5.如果计算法hash值一致，握手成功
	
	那么这样看ca证书就是对两者之间的传输key进行了加密，确保两者之间的传输key的安全性，这个证书其实就是公钥，认证加密后的公钥，即是证书，又称为CA证书，证书中包含了很多信息，最重要的是申请者的公钥。
	
	CA机构在给公钥加密时，用的是一个统一的密钥对，在加密公钥时，用的是其中的私钥，所以ca证书就是ca机构的密钥对中的公钥，ca机构的私钥对发送方的公钥加密。
	ca证书中包含的是发送方的公钥，有了这个公钥之后，就可以解密证书，拿到发送方的公钥，然后解密发送方发过来的签名，获取摘要，重新计算摘要
	
	使用Quartz做计划任务时，默认情况下，当前任务总会执行，无论前一个任务是否结束。  
        设置 <property name="concurrent" value="false" /> 可以让Job顺序执行。  
        设置 <property name="concurrent" value="true" /> 可以让Job并行执行，而不用管上一个Job是否结束。


对称加密：加密数据用的密钥，跟解密数据用的密钥是一样的。

对称加密的优点在于加密、解密效率通常比较高。缺点在于，数据发送方、数据接收方需要协商、共享同一把密钥，并确保密钥不泄露给其他人。此外，对于多个有数据交换需求的个体，两两之间需要分配并维护一把密钥，这个带来的成本基本是不可接受的。

非对称加密：加密数据用的密钥（公钥），跟解密数据用的密钥（私钥）是不一样的。

私钥能解开公钥加密的数据，但忽略了一点，私钥加密的数据，同样可以用公钥解密出来（公钥是公开的，那么由服务器-》客户端的就存在安全隐患）


1.小明访问XX，XX将自己的证书给到小明（其实是给到浏览器，小明不会有感知）
2.浏览器从证书中拿到XX的公钥A
3.浏览器生成一个只有自己知道的对称密钥B，用公钥A加密，并传给XX（其实是有协商的过程，这里为了便于理解先简化）
4.XX通过私钥解密，拿到对称密钥B
5.浏览器、XX 之后的数据通信，都用密钥B进行加密



下载完ssl相关的内容，其中包含了各个web服务器的证书，比如ningx和tomcat相关的
使用OPENSSL 命令行来生成 KEY+CSR2 个文件，Tomcat，JBoss，Resin 等使用 KEYTOOL 来
生成 JKS 和 CSR 文件
配置ssl证书后可使用301重定向到https的访问页面
使用https的访问，tomcat中需要配置秘钥相关
所有加了https安全证书转换的，post请求都要是https请求
<Connector SSLEnabled="true" clientAuth="false" keystoreFile="d:\tomcat.keystore" keystorePass="123456" maxThreads="150" port="9443" protocol="org.apache.coyote.http11.Http11Protocol" scheme="https" secure="true" sslProtocol="TLS"/>


多个dubbo的服务
<dubbo:protocol name="dubbo" port="20881"/>
做集群的时候，两台服务器的都暴露的是20881端口，是服务端暴露
如果要在同一台服务器上启动多个不同的服务server，那么就需要启动多个提供者，暴露多个dubbo的端口，但是注册到统一的zookeeper上

主从数据库：
	修改的254从库，但是生产是从253主库读取的，
	所以页面读取不到（253主-从，但是254的数据库只是备份用的）254修改后没反应，
	生产读取的是253的库，254只是备份用的库，只能算是展示功能，
	

	1.静态化页面

	效率最高、消耗最少的就是纯静态化的html页面。对于一些更新频率不频繁而又被大量访问的页面，我们就可以做静态化处理，来避免大规模的数据库访问。

	2.通过缓存加速数据库的访问。

	大部分的网站都是符合二八原则的。即80%的用户会访问20%的数据库资源。那么，为了加速用户访问，同时缓解数据库的访问压力，我们就可以用缓存技术。很多语言都有自己的内置缓存，比如php的cache。除此之外，还有很多缓存技术，如mamcache、redis、mongodb等。都可以对数据进行缓存，加速用户访问的同时，也缓解了数据库的压力。

	3.对数据库分库分表，读写分离
	可以解决容量和性能问题。
	读写分离：就是将数据库分成读库和写库，再通过主从来属性同步数据库。
	分库分表：分为水平切分和垂直切分。水平切分就是将一个特大的表拆分成多个小的表。垂直切分则是根据业务的不同来切分。
	关于数据库的优化，在另一篇文章中有记录。

	4.使用CDN加速全国用户的静态文件访问
		这里简单记录一下CDN原理：将数据内容缓存到附近的机房，用户访问时先从最近的机房获取数据，减少网络访问的路径，提高用户访问网站的响应速度和网站的可用性。解决网络宽带小、用户访问量大、网点分布不均等问题。

	5.反向代理（可归类为5）
		Nginx反向代理的作用：
		1.保护网络安全：任何的请求都必须先经过代理服务器，可以过滤一些非安全请求。
		2.通过配置缓存功能加速web请求。可以缓存服务器上的某些静态资源，减轻服务器的负载压力。
		3.实现负载均衡：充当负载均衡服务器均衡的分发请求，平衡集群中各个服务器的负载压力。
		
		
	负载均衡：是高可用系统必须的，一般应用通过负载均衡实现高可用，分布式服务通过内置的负载均衡实现高可用，关系型数据库通过主备方式实现高可用。
	服务化：将多个子系统公用的功能/模块，进行抽取，作为公用服务使用。比如本案例的会员子系统就可以抽取为公用的服务。
	读写分离解决的是读压力大的问题
	
	数据库读写分离会遇到如下问题：
	数据复制问题： 考虑时延、数据库的支持、复制条件支持。不要忘了，分机房后，这个更是问题。
	应用对于数据源的路由问题
	
	主从数据库的
	热备份是实时备份，发生倒换也不影响业务；冷备份则是周期性备份（如：定时每天凌晨开始备份），发生倒换时，备机的数据不是最新的。
	
	
-- 并发实践  书写的不怎么样
	
	线程共享进程范围内的资源，但是每个线程都有自己的程序计数器，栈，本地变量，统一进程中的线程访问统一变量，从同一堆中分配对象，实现了数据共享，但是也可能修改了其他线程正在使用的数据。提供资源利用率和吞吐量
	程序调度的基本单位是线程
	在单线程的应用程序中，有一个io操作阻塞了，不仅意味自身的请求停止了，还意味着这期间对所有的请求都终止了，于是单线程的服务器被迫使用非阻塞式的io，这样每个请求都有一个自身的线程，那么阻塞就不会影响其他的请求
	线程共享相同的内存地址空间，且并发的运行，那么访问共享的变量就需要使用同步的机制来限制。

	当调度程序临时挂起当前运行的线程，另一个线程开始运行。保存和恢复线程执行的上下文，离开执行现场，cpu的时间会花费在对线程的调度而不是运行上。
	常用的框架入time定时，timetask访问其他的程序正在访问的数据，需要考虑线程安全的问题，最简单的是确保timetask访问的对象本身是线程安全的。
	
	比如，多个servlet中访问的对象中，程序范围内的：servletContext和httpsSession，不能的线程请求是共享这些的，这需要线程安全

	多线程下访问变量，且存在写操作，就必须使用同步来协调线程对该变量的访问。
	没有同步的情况下，多线程访问同一个变量能量，方案：
		1、不要跨线程共享变量
		2、变量不可变
		3、使用同步访问状态变量
	
	线程安全的类封装了任何必要的同步，使用者不需要自己提供
	线程有自己的本地变量，这些本地变量存储在线程的栈中。
	无状态的对象永远是线程安全的(状态性待定，状态变量的概念)
	count++，获得当前值，加1，写回新值，是3个离散的操作，是一个读-改-写的操作过程。
	
	原子操作：该操作对于所有的操作，包括自己，都满足前面描述的状态
	当其他线程想要查看或者修改一个状态时，必须在我们线程开始之前或者完成之后，而不能在操作过程中。
	吞吐量――默认情况下表示每秒完成的请求数（Request per Second）
	
	synchronized,锁对象和方法(就是该方法所在对象本身)，静态的synchronized方法从class对象上获取锁
	内部锁在java中是互斥锁的存在，但是会带来的响应性的问题。性能问题和线程安全问题是一定程度上互斥的
	
	通过缩小synchronized块的范围来维护线程安全性，容易提升并发的性能，尽量将耗时的不影响共享状态的操作分离出来
	
	像i/o等耗时的计算或操作，执行这些操作期间不要占有锁
	
	锁不仅关于同步与互斥，也关于内存可见。确保线程都能看到共享，可变变量的最新值，读取和写入线程必须使用公共的锁进行同步。
	加锁可以保证可见性和原子性，volatile变量只能保证可见性
	(可见性，理解是get操作等待另一个线程的set操作，保证值是最新的)
	
	并发涉及到的三个特性
		1、原子性：即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。
		2、可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。
		3、有序性：即程序执行的顺序按照代码的先后顺序执行。
	
	处理器在进行重排序时是会考虑指令之间的数据依赖性，指令重排序不影响单线程的处理，了解即可，那么理解就是按顺序执行就行（暂不了解）
	
	可见性：（涉及到本地线程内存和主内存的概念，运算结束，高速缓存（相当于本地的线程内存，也叫工作内存）中的数据刷新到主存当中）
		对于可见性，Java提供了volatile关键字来保证可见性,但是不能保证原子性(在多个线程访问的时候，原子性就不能保证了，单线程是可以的)
　　		当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去主内存中读取新值。
　　		而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。
　　		另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性

	对于volatile修饰的变量，jvm虚拟机只是保证从主内存加载到线程工作内存的值是最新的(相当于get 和reload操作)

	如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条指令，将这个变量所在缓存行的数据写回到系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。
	在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。
	总结下来：

	第一：使用volatile关键字会强制将修改的值立即写入主存；
	第二：使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；
	第三：由于线程1的工作内存中缓存变量的缓存行无效，所以线程1再次读取变量的值时会去主存读取。
	最重要的是：

	可见性：对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。
	原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。

原子性：
	1.即操作过程被其他线程干扰导致信息错误和信息丢失，原子操作在操作完毕之前不会线程调度器中断
	***2.提供了互斥访问，同一时刻只能有一个线程对它进行操作***
	
	解决本地缓存不一致的情况：
	　为了解决缓存不一致性问题，通常来说有以下2种解决方法：

　　	1）通过在总线加LOCK#锁的方式
			如果一个线程在执行 i = i +1，执行过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，
			其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。但是在锁住总线期间，其他CPU无法访问内存，导致效率低下。

　　	2）通过缓存一致性协议
			所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。
			它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，
			因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。

　　	这2种方式都是硬件层面上提供的方式。

　
	
	threadlocal提供了get和set访问器，为使用它的线程维护一份单独的拷贝，get总是返回由当前执行线程通过set设置的最新值
	threadlocal<T>可以看作是map<thread,t>，存储了与线程相关的值。是线程限制
	***实现变量的初始化***
	ThreadLocal<Integer> iin=new ThreadLocal<Integer>(){
				 public Integer initialValue() {
					 	int a=1;
				        return a;
				    }
				};
	
	将单 ―》多线程中，可将共享的全局变量转换成threadlocal类型，但是将应用级别的缓存编程一堆线程本地缓冲，那么是没有意义的
	常用用法：和context结合使用，将context和线程关联起来，降低了每个方法传递执行上下文信息的需要。
　　便于线程的上下文传输，隐藏参数传递


	注意这里是静态持有上下文的，有两个特性，一个是封闭隐藏，一个是传输性，
	虽然可降低重用性，但会引入隐晦的类间耦合。
	public class ApplicationContext implements Serializable
	{
    /** 应用上下文线程变量 */
	private static final ThreadLocal<ApplicationContext> opContextHolder = new ThreadLocal<ApplicationContext>();
	
	private Map<String, Object> parameters;
    private Object info;
    public static ApplicationContext getContext()
    {
        ApplicationContext context = opContextHolder.get();
        if (null == context)
        {
            context = new ApplicationContext();
            opContextHolder.set(context);
        }
        return context;
    }
	
	生产者和消费者之间，使用有界队列（阻塞队列）对资源进行管理,可以平衡二者的工作时间
	有界队列防止应用程序过载而耗尽内存
	executor基于生产者-消费者模式实现的，提交任务的执行者是生产者，执行任务的线程是消费者。
	

	
<分布式服务架构：原理、设计与实战>
	单体架构无法突破耦合在一起的模块化组件的性能瓶颈。soa就是讲模块化组件从单一进程进一步拆分，形成独立的对外提供服务的网络化组件（需要定义标准的对外接口）。
	服务化的过程就是拆分的过程，各个服务之间是独立的，相互解耦的。
	单体架构只可对包含多个模块化组件的整体jvm进程水平扩展，无法针对某个模块化组件进行水平扩展
	综合看：微服务架构更灵活并且可水平伸缩，可以让专业的人来做专业的事。针对某个单一组件优化，耦合性低，接口变动才需要跨团队协调.
			单一微服务更容易水平扩展的目的。拆分粒度细，分工明确，通过多个服务组合来实现业务流程
			之后每隔模块组件最为子服务都是一个团队，单体结构的上线沟通你怎么协调？难以维护，跨团队的沟通效率是会大大降低的。
	
	
	
	最后需要强调，微服务架构并不是为了拆分而拆分，真正的目的是通过对微服务进行水平扩展，解决传统的单体应用在业务急剧增长时遇到的问题，而且由于拆分的微服务系统中专业的人做
	业的事，人员和项目的职责单 、低藕合、高内聚，所以产生问题的概率就会降到最小。
	

	每个服务都有多个实例在运行，每个实例可以运行在容器化(tomcat)平台内，打到平滑伸缩的效果(根据性能需求独立水平伸缩,大白话就是加机器)
	每个服务都有自己的数据存储，实际上每个服务都应该有自己独享的数据库、缓存、消息队列等资源
	
	
	对于异构系统之间的交互标准，通常可以使用工具来补偿。
	
	读者容错模式：消费者建议使用宽松的校验策略，只取所需的数据，
	
	server端需要做幂等和滤重处理
	
	*****服务化的范围选择，核心同步服务化，非核心的异步处理即可*****
	在构建微服务架构系统时，通常会梳理核心系统的最小化服务集合，这些核心的系统服务使用同步调用，而其他核心链路以外的服务可以使用异步消息队列进行异步化

	流行的就是spingcloud,dubbo,hessian,thrift
	
	tips: 永远不要在本地事务中调用远程服务，在这种场景下如果远程服务出现了问题你，则会拖长事务，导致应用服务器占用太多的数据库连接，让服务器负载迅速攀升，严重情况下，会压垮数据库
	
	hessian将对象序列化与语言无关的二进制协议，跨语言，适合传输较小的对象，服务化结构中大量的服务调用是大规模、高并发的短小请求，比较适用
	
	jdk内置的序列化机制是java专用的，不能跨语言
	
	dubbo：
		使用的zookeeper作为注册中心，负载均衡算法包括：随机、轮询、最少活跃调用数、一致性哈希等。
		Dubbo 服务框架是 SOA 服务化时代的产物，对微服务化提出的各种概念如熔断、限流、服务隔离等没有做精细的设计和实现
	
	互联网中拆分：
		水平拆分：从单节点扩展为多个节点，具有一致功能，组成一个服务池，所有节点共同处理大规模请求，简单讲就是做集群
		垂直拆分：就是按照功能进行拆分，专业人干专业事情，产品迭代快，敏捷开发
		
		
	在 fai over 重试或者补偿的场景下，重复请求是 定会发生的，也是服务化系统必 处理的）

	几个一致性问题：
		1.下单和扣库存，两个服务之间最终的一致性
		2.同步调用超时，a调用b，a系统是可以得到超时反馈的，但是b不知道，处理情况类似之间的hessian处理，增加缓存补偿，设置超时时间
		3.异步回调超时，补偿做job重新发即可
		
		
	数据库mysql等是具有强一致性的，
	上述问题1中， 在数据量较小的情况下，可以利用关系型数据库的强一致性解决， 也就
	是把订单表和库存表放在同一个关系型数据库中，利用关系型数据库进行下订单和扣库存两
	紧密相关的操作，达到订单和库存实时一致的结果
	
	一种更好的办法是用 Write-Ahead Log （写前日志），这和数据库的 Bin Log （操作日志〉相似，在进行每个操作步骤时，都先写入日志，
	如果操作遇到问题而停止，则可以读取日志井按照步骤进行恢复，继续执行未 成的工作，后达到一致的状态。
	
	多数业务系统还是使用数据库记录的字段来记录任务的执行状态，也就是记录中间的 “软状态飞 个任务的状态流转一般可以通过数据库的行级锁来实现，这比使用写前日志实现更简单、快速。
	
	有了 BASE 思想作为基础，我们对复杂的分布式事务进行拆解，对其中的每个步骤都记录
	其状态，有问题时可以根据记录的状态来继续执行任务（或者终止），达到最终一致。
	通过这种方法我们可以解决 2.2 节案例 中下订单和扣库存的 致性问题。说白了就是增加操作日志
	
	多系统间的调用，补偿的job还是很有必要的
	
	
	两阶段提交协议把分布式事务分为两个阶段一个是准备阶段，另一个是提交阶段 准备
	阶段和提交阶段都是由事务管理器发起的 为了接下来讲解方便，我们将事务管理器称为协调者
	将资源管理器称为参与者。
	
	
	两阶段提交：
		准备阶段： 写 redo 或 undo 日志，然后锁定资源，
		提交阶段：预留资源和执行操作成功，则变更释放资源，否则回退执行undo，释放锁定资源
		
	三阶段提交：新增超时机制，解决阻塞问题，新增询问阶段
		询问阶段：协调者询问参与者是否可以完成指令，无需执行真正的操作，超时会终止
		
	目前tcc,try confirm cancel
		我们给出一个使用 TCC 的实际案例，在秒杀的场景中，用户发起下订单请求，应用层先
		询库存，确认商品库存还有余量，则锁定库存，此时订单状态为待支付，然后指引用户去支付
		由于某种原因用户支付失败或者支付超时，则系统会自动将锁定的库存解锁以供其他用户秒杀。
		
	金融系统与社交应用在技术上的本质区别为：社交应用在于量大，而金融系统在于数据的准确性
		
	在微服务中，保证最终一致性的模式：
		1.查询模式
			提供查询接口，用来输出服务操作执行状态。
			使用查询模式了解被调用服务的处理情况，决定下一步做什么。例如：补偿未完成操作还是回滚已完成操作。
			为了能够实现查询，每个服务操作都需要有唯 的流水号标识，也可使用此次服务操作对应的资源 ID 来标识，例如：请求流水号、订单号等
			
		2.补偿模式
		为了让系统最终达到一致状态而做的努力叫做补偿。
		对于服务化系统中同步调用的操作，若业务操作发起方还没有收到业务操作执行方的 明确返回或者调用超时，可使用查询模式去查，再做相应的操作(类似之前的redis标记)
			
			补偿操作根据发起形式分为以下几种:
			自动恢复：程序根据发生不一致的环境，通过继续进行未完成的操作，或者回滚己经完成的操作，来自动达到 致状态。
			
			通知运营：如果程序无法自动恢复，并且设计时考虑到了不一致的场景，则可以提供运营功能，通过运营手工进行补偿。
			
			技术运营：如果很不巧，系统无法自动回复，又没有运营功能，那么必须通过技术手段来解决，技术手段包括进行数据库变更或者代码变更，这是最糟的 种场景，也是我们在生 中尽 避免的场景
			
		3.异步确保模式
		 通过异步的方式进行处理，处理后把结果通过通知系统通知给使用方 。这个方案的最大好处是能够对高并发流量进行消峰.案例是job
		 
		4.定期校对模式
			关键是有全局唯一的id
			通过补偿操作来达到最终一致性，但是如何来发现需要补偿的操作呢？
			可以在事后异步地批量校对操作的状态，如果发现不一致的操作，则进行补偿。
		
		5.可靠消息模式 （发送可靠和消费可靠）
			使用消息队列处理可异步处理的操作，发送前存入数据库，未发送成功的定时补发
			幂等处理，因为保证消息可靠发送需要有重试机制，消息就一定会重复，那么我们需要对重复的问题进行处理。
			
			保证幂等性的常用方法：
				1).使用数据库表唯一键滤重，拒绝重复的请求
				2).使用分布式表对请求滤重
				3).使用状态流转的方向性滤重，通常使用数据库的行级锁实现
			
			
	6. 缓存一致性模式
	使用缓存来保证一致性的最佳实践。
		如果性能要求不是非常高，则尽量使用分布式缓存(redis)，而不要使用本地缓存(session 和cookies)。
		写缓存时数据一定要完整， 如果缓存数据的一部分有效 另一部分无效，则宁可在需要时回源数据库，也不要把部分数据放入缓存中。
		读的顺序是先读缓存，后读数据库，写的顺序要先写数据库，后写缓存。
		
		
	微服务的交互模式：
		1.同步调用模式 				服务1调用服务2，等待返回处理结果
		2.接口异步调用模式			服务1调用服务2，即刻返回受理结果，受理成功，服务2异步处理，处理成功后再通知服务1
		3.消息队列异步处理模式
		
		消息队列异步处理模式与接口异步调用模式类 ，多应用于非核 链路上负载较高的处理环节中，井且服务的上游不关心下游的处理结果，下游也不需要向上游返回处理结果
		
		如果性能不是问题，或者所处理的操作是短小的轻量级处理逻辑，那么同步调用方式是最理想不过的，因为这样不需要引入异步化的复杂处理流程。
		而是在同步过程中完成请求的受理和处理过程，这也是为什么不推荐将大数据存储到关系型数据库中，关系型数据库只存储交易相关的最小化核心信息。
		
		两状态同步接口：成功，失败
			使用方---服务1--服务2
			场景1，同步超时发生在使用方调用此同步接口的过程中，这时候是可以异步查询，重试请求的
			场景2，超时发生在内部服务1调用2过程中，使用快速失败原理，同时调用服务2的冲正处理，若成功则回退处理
			原因可能是内部的涉及上下游，超时两端都可能有问题，快速失败比较好
		
		三状态同步接口：成功，失败，处理中
			这里就是尽可能做补偿，两状态就是严格的成功失败
			主要涉及的就是查询接口，重试机制，幂等处理。必要时快速失败
			
		异步调用模式使用的是受理模式，异步接口很好操作，只需要异步查询就可以了
		
		
	日志相关：
	localhost_acces log.*.txt   Tomcat存取日志：
		位于 Tomcat log 目录下，清晰地记录了 HTTP 服务请求的来源、响应时间、返回的 HTTP 代码等，可用于统计服务的成功数和失败数，也可用于统计接口的响应时间，还可用于统计服务的请求数和吞吐量等。
	
	catalina.out	Tomcat控制台目志
		位于 Tomcat log 目录下，包含 Tomcat是否成功启动、启动所使用的时间，以及应用打印的控制台日志等信息。
	
	localhost. *. txt	Tomcat 本地日志
		位于 Tomcat log 目录下，程序异常在没有被捕获时会被一直抛出到容器层，容器处理后记录在这个目志里。
		
	ELK的适用场景：日志采集器，日志缓冲队列和日志解析器	
		对集群中个节点的日志又不方便通过 Linux 命令行进行聚合查找和统计。为了解决这个问题，大多数公司都会构建大数据 日志系统，通常采用 ELK ( Elasticsearch LogstashKibana ）架构来实现。
		日志缓冲队列是大数据日志处理器系统的核心，连接了日志收集器和日志解析器	
		
		
		
		
	***分布式调用链跟踪系统***：		
	在实践中想在分布式系统中迅速定位问题时，可通过分布式系统的调用链跟踪系统进行，	
	它能够跟踪 个请求的调用链。调用链是从二维的维度跟踪一个调用请求 最后形成一个调用树，其原理可参考谷歌 Dapper 论文及它的 个流行的开源实现项目 Pinpoint
		
		
	该模式中需要在请求调用跨越的系统问执行校对操作。我们通过事后异步地批量校对，基于全局的唯一流水 ID 一个请求在分布
	式系统中的流转路径聚合，然后使用调用过程中传递和保存的 SpanID 将聚合的请求路径通过树形结构进行展示，让开发、应急和运维人员轻松地发现系统出现的问题，并能够快速定位出现问题的服务节点，提高应急效率。
	
	谷歌的 Dapper 论文通过增加应用层的标记来对服务化中的请求和响应建立联系，例如：它
	通过 HTTP 协议头携带标记信息，标记信息包括标识调用链的唯一流水 ID ，这里叫作 TraceID,
	以及标识调用层次和顺序的 SpanID和ParentSpanID
	
	上面每种类型的远程调用信息包含：调用端或者被调用端的IP 、系统 ID ：本次请求的
	TraceID SpanID(一般包含ParentSpanID，ParentSpanID为－1 的节点为调用树的根节点，也是调用请求的源头请求。) 时间戳、调用的方法名称及远程调用信息的类型， 等等
	
	
	线上应急必须有组织、有计划、有条不紊地进行，该做决策的时候要 不犹豫地做决策，该升级的时候要果断。
	线上应急 般分为 个阶段：发现问题、定位问题、解决问题、消除影响、回顾问题、避免措施。
	
	必须建立上线流程和上线评审机制，每 次上线都需要有快速回滚方案。
	
	
<大型网站技术架构：核心原理与案例分析> 内容稍微浅，经验之谈，不够深入
	二八定律：80%的业务集中在20%的数据上，现实中的财富分配也一样。
	
	应用服务器实现集群是网站可伸缩集群架构设计中简单成熟的方式，重点体现在可伸缩，搭配负载均衡使用效果更佳(解决服务器的性能瓶颈)
	
	读：先缓存后数据库（可能部分不命中 ，缓存过期），写：先数据库后缓存
	
	主流数据库是主从热备(一般是基于binlog实现复制)，实现读写分离，
	为了方便读写分离后的数据库，通常在应用服务使用专门的数据库访问模块，应用服务器通过一个统一的数据访问模块访问各种数据
	
	
	
	
	cdn部署在网络提供商的机房，使请求近地区机房获取数据；而反向代理提供在网站的中心机房
	
	
	控制并发访问的量，适当的使用排队机制，业务驱动，类似退款的额轧差处理，业务上可以优化
	
	集群：多台服务器部署相同应用构成一个群体，通过负载均衡设备共同对外提供服务，这里使用了失效转移机制
	
	
	数据库热备：一般用于保证服务正常不间断运行，用两台机器作为服务机器，一台用于实际数据库操作应用,另外一台实时的从前者中获取数据以保持数据一致.如果当前的机器熄火,备份的机器立马取代当前的机器继续提供服务
	冷备：冷备份指在数据库关闭后,进行备份,适用于所有模式的数据库.定期复制
	1.冷备份：服务器不运行，数据库服务停止，执行的备份就是冷备份。
	2.热备份：其余的都是热备份。
	
	
	冗余：资源备份，保证高可用性
	
	
	网站核心架构要素：
		性能：
		可用性：冗余，备份，失效转移
		伸缩性：集群，提高吞吐能力
		扩展性：
		安全性：
		
		
	使用异步消息加快请求响应及实现雪峰
	
	缓存实现：
	session复制：效率低
	cookie记录session：
	
	session服务器
	
	cap   一致性，可用性，伸缩性
	
	
	网站的伸缩性:1、根据功能进行物理分离实现伸缩，即服务化，多个机器不同服务
				 2、单一功能通过集群实现伸缩，多个机器同服务
	
	
	首页是不应该访问数据库的，一般从缓存服务器或者搜索引擎服务器获取数据
	
	
	
《大型网站系统与JAVA中间件实践》中间内容还可以，后面就是水  
	本书中需要多次理解的内容：nio(128页)

	常见的session管理方案，
		1、session的同步复制，但是集群数量过多的时候不适用
		2、session集中管理，建立session存储，可以是数据库也可以是分布式存储
		3、通过cookie传递
	
	数据库读写分离：写操作走主库，事务中的读也要走主库，主备库之间是存在一定延迟的
	垂直拆业务，按照业务拆分成多个表，不同表拆到不同数据库中
	水平拆,把统一个表中的数据拆到两个数据库中，往往是数据量达到了单库的瓶颈，同一个表拆分到不同的数据库中
	但是水平拆库后，使用自增id会受到影响
	
	
	
	中间件的好处：异步和解耦
	主要的三种中间件：
	1、远程过程调用和对象访问中间件：解决分布式环境下的应用互相访问，服务化的基础      缓解了数据防连接的访问压力
	2、消息中间件：解决应用之间的消息传递，异步和解耦问题
	3、数据库中间件：解决应用访问数据库的共性问题的组件
	
	
	创建线程是用的是threadpoolexecutor，需要注意的是executor.newCachedThreadPool()，该方法返回的线程池是没有线程上限的，可能占用过多内存。
	尽量使用有固定线程上限的线程池
	
	
	静态代理和动态代理：
		静态代理每次都会生成一个代理类，注入被代理对象然后调用方法
		
		动态代理是使用proxy统一创建一个对象，统一进入invoke方法，更加简洁，那么三个重要的参数，类加载器，代理的接口，和invocationhandle核心处理类，
		更注重的是通用的实现，使用通用的代理模板类，同样的事情的代理只要实现一遍，就可以提供给多个不同的委托类使用
		
		
	反射中
		newinstance构造对象的时候，对象类必须要有一个无参构造
		
        Class.forName("com.test.mytest.ClassForName"); 后续可以再接着newinstance()创建一个实例
        ClassLoader.getSystemClassLoader().loadClass("com.test.mytest.ClassForName");
		根据运行结果得出Class.forName加载类是将类进了初始化，而ClassLoader的loadClass并没有对类进行初始化，只是把类加载到了虚拟机中。
		ClassLoader通过一个类的全限定名来获取描述此类的二进制字节流”，获取到二进制流后放到JVM中。Class.forName()方法实际上也是调用的CLassLoader来实现的。
		class文件本来就是二进制文件,是字节码文件
		
		可以动态的执行方法和操作属性
		Method method=clazz.getdeclaredmethod("add",int.class,int.class);
		method.invike(this,1,1);
		
		Field field=clazz.getdeclaredField("name");
		field.set(this,"Test");
		
	服务化：分而治之
		服务化的调用端：
			1、获得可用服务地址列表
			2、确定目标的机器
			3、建立连接，序列化，请求，接收结果，解析结果
			
		发现服务，一般采用的是完整的类名+版本号作为key去注册的服务列表中查找相应的服务
		
		
		服务端：定位服务，一般基于名称和版本号定位，处理返回
		在服务化框架中：
			三个基础的属性，
				interfacename：通过接口生成代理对象，供本地调用
				version：区分的版本号，留个印象即可，可能是分机器调用吧
				group：分组调用，
		客户端调用服务端并不是每次都从服务注册中心查找地址，而是把地址缓存在客户端本地，当有变化时主动从服务中心发起通知，告诉客户端可用服务提供者的列表变化
		负载均衡的实现一般是随机，轮询，权重的方式
		
		
		常用的异步远程通信方式：
			oneway，是一个单向的同时，
			callback，是一种被动的方式，callback的执行不是在原请求中，一般需要创建新线程来执行回调
			future，是一种主动控制超时、获取结果的方式，并且执行仍在原请求线程中
			
			
		异步调用多个线程，基础是abc之间没有相互依赖的关系，并行调用优化(future方式的支持)
		
		服务提供端的工作线程是一个线程池，类似之前的监听线程和工作线程，也可以根据不同的服务调用不同的线程池。
		
		cap理论和base理论
		
		分库是把数据分到了不同的数据分组中，决定分组后，还要决定访问分组中的哪个库
		数据库分库分表后的相关问题
			垂直分表的时候，跨库join，数据冗余(常用数据冗余)；分多次查询；借助外部系统：搜索引擎等
		
		幂等：多次调用会得到同样的结果
		注册中心的两个基本职能：
			1、聚合地址信息，形成服务地址信息列表
			2、生命周期感知，更新服务地址信息，通过长连接的心跳机制，实现上下线的感知
			
			
			
			
mysql中的重要的日志文件：
	redo log：保证数据可靠的入磁盘
		作用：确保事务的持久性。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。
		生命周期：事务开始之后就产生redo log，在事务执行过程中，就写入redo log文件中，
				  当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用（被覆盖）。
				  使某个事务还没有提交，Innodb存储引擎仍然每秒会将重做日志缓存刷新到重做日志文件。(随着事务的开始，逐步开始的)
　　			这一点是必须要知道的，因为这可以很好地解释再大的事务的提交（commit）的时间也是很短暂的。

	undo log:	用于回滚
		作用：保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读
		生命周期：事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性
				  当事务提交之后，undo log并不能立马被删除，
　　			  而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。
	
	binlog：记录的就是sql语句
		作用：
		　　1，用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。
		　　2，用于数据库的基于时间点的还原。
		生命周期：事务提交的时候，一次性将事务中的sql语句按照一定的格式记录到binlog中。
	
	mysql内部的xa事务提交 ，以 binlog 的写入与否作为事务提交成功与否的标志
	MySQL通过两阶段提交过程来完成事务的一致性的，也即redo log和binlog的一致性的，理论上是先写redo log，再写binlog，两个日志都提交成功（刷入磁盘），事务才算真正的完成。 
	
	
	
	
	
开源的一些项目：
	ruoyi：
		
		
		
		
		

docker:《第一本docker书》 大概浏览一遍就行，先简单用用
	虚拟机虚拟的是一个完整的操作系统，
	docker的核心组件：
		1、docker的客户端和服务端，		连接方式：命令行工具或api调用
		2、docker镜像					相当于容器的“源代码”，生命周期中的构建或者打包阶段
		3、registry						相当于远程/私有库 										官方的使用的是docker hub
		4、docker容器					启动或者执行阶段
		
	总结docker容器就是：一个镜像格式，一系列标准的操作，一个执行环境
	
	查看docker toolbox的ip地址（即decker服务器的localhost或者ip地址）：$ docker-machine ip default
	docker toolbox创建了一个本地虚拟机，拥有自己的网络接口和ip地址
	
	docker程序是docker守护进程的客户端程序
	
	开始：
	从下往上，由基础镜像往上，最终生成一个可写容器，创建dockerfile时，每条run指令都会创建一个镜像层，指令成功，镜像层提交
	
	相关的linux命令：
		1、cat命令主要用来查看文件内容，创建文件，文件合并，追加文件内容等功能。
		2、ps -aux 查看容器的进程
	
	创建一个可交互的容器， 这样就创建了新容器，直接root进入了容器操作，/bin/bash就是交互的shell，交互式容器
		sudo docker run -i -t ubuntu /bin/bash  	也可以使用--name来给容器命名，跟在run后面 创建交互式的容器
		exit 										退出容器(容器停止运行)，回到宿主机命令提示符，容器仍然存在，只有在指定的/bin/bash命令运行时，容器才运行。
		docker ps -a 								查看当前系统中的容器列表，不带-a查看运行中的
		sudo docker start test_linux				重新启动容器
		sudo docker attach test_linux				重新附着到容器的会话上
		
		
		sudo docker run --name daemon_dave ubuntu /bin/sh -c "while ture; do echo hello world; sleep 1; done" 创建守护式容器，-d 创建守护容器
		sudo docker logs -f daemon_dave 			查看容器日志
		sudo docker top test_linux					查看容器中的进程
		docker exec 								容器内启动新进程
		docker stop test_linux						停止容器
		docker rm test_linux						删除容器
		docker images								查看镜像
		docker pull fedora:20 						从远程拉取镜像
		docker rmi									删除镜像
		
		docker build -t="jamtur01/static_web" .      基于dockerfile(vim编写)创建一个镜像，其中设置了仓库和名称
		
		下载war挂在到数据卷中，然后启动带有tomcat的容器，最后会将数据卷中的war挂载到tomcat对应的容器执行
		
		启用微服务，在dockerfile中的 配置容器启动后执行的命令，ENTRYPOINT ["java","-jar","/app.jar"],打成镜像，配置端口，直接run即可
		
		
		
		
对必须要有一致性的功能是无法进行读写分离的，可以采用多库不区分读写以及memcache缓存技术来实现。

手写一个rpc框架的实现：核心就是动态代理一个单独的接口，socket实现参数的传输的接收，同步阻塞等待获取
	可以对一个实现类实现动态代理，也可以只对一个单独的接口实现动态代理，这里rpc框架以及mapper使用的就是这种单独接口代理的方法

	rpc的demo中，创建sock连接的时候是阻塞的，在一次连接中，client写一个参数，server接收一个参数，直到接收完成返回
	其中使用new ObjectOutputStream(socket.getOutputStream()) write传参数和new ObjectInputStream(socket.getInputStream()) read 读信息，加入功能所以需要需要封装下
	实现一个注册的map,private static final HashMap<String, Object> implRegistry = new HashMap<>();(final修饰的List同Map，都是可以改变内部的值，而不允许指向新的地址。)
	
	序列化机制的核心作用就是对象状态的保存与重建。字节序列和Java对象之间的转换
	为什么要用序列化？进程通信实现文本图片音频等传输外（二进制序列形式），java对象传输必须序列化
	
	
缓存共享，session共享
	1、最原始的是：直接通过tomcat自带的复制功能，即访问其中一台tomcat服务器就会在其他配置好的tomcat服务器上各复制一份session，存在一定的延迟，同时若并发量一大的话也会有网络风暴的风险
	2、使用tomcat-redis-session-manager,使用redis同步各tomcat之间的缓存（依赖tomcat，需要修改context.xml文件），但是目前只支持到jdk1.7
	3、更新使用spring session，存储在第三方存储容器redis的spring session，是配置在项目和代码中的
	
	spring session相关：使用springboot项目很简单
		spring session在spring框架中的实现原理，其实就是在请求request上通过DelegatingFilterProxy代理过滤器封装了一层，将原来存储在容器缓存的session变成存储在redis的session，所以在web.xml中的此filter必须得是在所有filter的前面。
		用了spring session后，web.xml中设置session过期时间是无效。因为已存储在redis的session。
		相应的springSessionRepositoryFilter需要放在filter最前面
		jedisPoolConfig、connectionFactory、过期时间，springSessionRepositoryFilter,组装redisTemplate
		
		
job调用多个soa服务，多个微服务，只有服务端才需要暴露相应的dubbo端口，客户端只要填写zookeeper地址即可，统一在注册中心找服务


netty内容：
	Netty 对 JDK 自带的 NIO 的 API 进行了封装,是异步高性能的通信框架。往往作为高性能基础通信组件被这些 RPC 框架使用。

	传统的i/o模式，每个请求都需要独立的线程完成数据read，业务处理，数据write的完整操作问题，容易阻塞
	Netty 的非阻塞 I/O 的实现关键是基于 I/O 复用模型，使用了多路复用器selector，一个 I/O 线程可以并发处理 N 个客户端连接和读写操作，这从根本上解决了传统同步阻塞 I/O 一连接一线程模型，架构的性能、弹性伸缩能力和可靠性都得到了极大的提升。
	传统的 I/O 是面向字节流或字符流的，以流式的方式顺序地从一个 Stream 中读取一个或多个字节, 因此也就不能随意改变读取指针的位置。

	在 NIO 中，抛弃了传统的 I/O 流，而是引入了 Channel 和 Buffer 的概念
	Netty 的线程模型基于主从 Reactor 多线程
	Netty 基于 Selector 对象实现 I/O 多路复用，通过 Selector 一个线程可以监听多个连接的 Channel 事件。
	当向一个 Selector 中注册 Channel 后，Selector 内部的机制就可以自动不断地查询(Select) 这些注册的 Channel 是否有已就绪的 I/O 事件（例如可读，可写，网络连接完成等），这样程序就可以很简单地使用一个线程高效地管理多个 Channel 
	
	
	在io模型中一个连接需要开一个线程
	NIO解决这个问题的方式是数据读写不再以字节为单位，而是以字节块为单位。每次从缓存区读取一块数据
	
	class java.nio.channels.Selector 是Java 的非阻塞 I/O 实现的关键。它使用了事件通知 API，可在任何的时间检查任意的读操作或者写操作的完成状态，一个单一的线程便可以处理多个并发的连接。统一处理多个socket连接
	
	ChannelFutureListener提供的通知机制消除了手动检查对应的操作是否完成的必要
	Netty 完全是异步和事件驱动的。这里体现监听事件是否完成，
	
	编码解码的事情：这两种方向的转换的原因很简单：网络数据总是一系列的字节
	
	网络数据的基本单位总是字节。Java NIO 提供了 ByteBuffer 作为它的字节容器，但是这个类使用起来过于复杂，而且也有些繁琐
	Netty 的 ByteBuffer 替代品是 ByteBuf，一个强大的实现，既解决了 JDK API 的局限性，又为网络应用程序的开发者提供了更好的 API。
	bio，传统的一请求一应答通信模型，一请求产生一个线程，交互完成，线程销毁，线程资源不可控，会阻塞
	后来出现了线程池，这是伪异步i/o,采用线程池和任务队列可以实现一种叫做伪异步的 I/O 通信框架，线程资源可控，但是还是会阻塞
	
	
	
	
	Reactor模式：
			connection per thread,早起的tomcat就是这样实现的
			一个线程只能对应一个socket
			改进：采用基于事件驱动的设计，当有事件触发时，才会调用处理器进行数据处理。使用Reactor模式，对线程的数量进行控制，一个线程处理大量的事件。
			
			实际上的Reactor模式，是基于Java NIO的，在他的基础上，抽象出来两个组件――Reactor和Handler两个组件：
		（1）Reactor：负责响应IO事件，当检测到一个新的事件，将其发送给相应的Handler去处理；新的事件包含连接建立就绪、读就绪、写就绪等。

		（2）Handler:将自身（handler）与事件绑定，负责事件的处理，完成channel的读入，完成处理业务逻辑后，负责将结果写出channel。

 
 
 序列化问题
	jdk序列化写入不仅是完整的类名，也包含整个类的定义，包含所有被引用的类。类定义可以是相当大的，也许构成了性能和效率的问题.
	
	
	序列化是输出，用out流，反序列化是输入用input流，用到的就是 ByteArrayOutputStream()，ObjectOutputStrea/ByteArrayInputStream,ObjectInputStream;	
 
	使用protostuff序列化，将大大减小序列化后的数组大小，
	需要引入的jar有protostuff-collectionschema，protostuff-core，protostuff-runtime，protostuff-api
	
	
	

设计模式
	模板方法
			模板方法中某些方法是超类处理，某些方法是子类处理。需要由子类提供的方法，必须在超类中申明为抽象。
			
			抽象类可以定义一些默认行为，并促使子类提供任意特殊化行为。但是接口好像是全实现。
			抽象类是作为基类的，子类必须实现其操作
			
			被申明为final的方法是不能重写的，公用的实现类可以直接写在父类，特性方法的可以实现父类的抽象方法
			子类继承抽象类必须实现其中抽象方法，除非子类为抽象类。
			抽象类就是可以吧多个接口公用部分放在抽象类中，然后各子类在实现特性方法
			抽象类是为了代码的复用，而使用接口的动机是为了实现多态性。复用的是公用的逻辑
			
			在超类中提供了基础方法，达到代码的复用，并允许子类指定行为。
			
			**********
				抽象类中  抽象方法必须子类实现，普通方法可选，但是加上final就不能重写了
				抽象实现特定，普通方法实现共性
			**********
	
	单例模式		
		*****确保一个类只有一个实例，并且提供一个全局访问点。*****分别对应构造私有和静态访问
		确保只有一个实例会被创建
		线程池，日志对象只能有一个实例。
		单例实现：构造私有化，并提供static访问实例的方法即可
		
		典型代码：
		这里可能会有线程问题，使用双重检查加锁，性能还可以
		public class Singleton{
			private static Singleton uniqueInstance;//利用一个静态变量记录该类的唯一实例
			
			private Singleton(){};
			
			public static Singleton getInstance(){
				if(uniqueInstance==null){
					uniqueInstance=new Singleton();
				}
				
				return uniqueInstance;
			}
		
		这里使用静态变量有两层意思：1.静态方法类中变量必须是静态变量。2.单例就是共享一个实例，符合静态共享
		private static Singleton uniqueInstance=new new Singleton();  这个就是线程安全的
		
		}
			
		
		java中实现单例模式需要：1私有构造，2静态方法 和3静态变量
	
	
	工厂模式
			用来封装对象的创建，让子类决定该创建的对象时什么。
			定义了一个创建对象的接口，由子类决定要实例化的接口是哪一个。工厂方法让类把实例化推迟到子类。
			将对象创建的方法封装起来
		没有细细研究
		
	
	
	
spring实战			296
	创建bean的几种方式,注入属性等			@autowire等
	所有的spring bean都是单例的，默认单例 ，也可以指定多例
	最少xml配置
		
	<context:component-scan>
	
	@configuration等价xml配置中的<beans>元素
	
	
	@bean				---- 向spring注册了一个bean。方法名作为bean的id
	public Performer duke(){
		return nre Juggler()
	}
	
	--引用创建bean
	@bean			
	public Performer duke2(){
		return nre Juggler(duke())					---并不是调用，spring拦截找到该bean
	}
	
	aop中的概念：
	通知  切面（通知和切点的结合）的工作
	切点 
	连接点  
	
	aspect 是区别于spring aop的
	
	全有或全无的操作称为事务
	将几个操作组合成一个全有或全无的工作单元，这个工作单元也是事务
	
	一致性是对数据可见性的约束，保证在一个事务中的多次操作的数据中间状态对其他事务不可见的。
	因为这些中间状态，是一个过渡状态，与事务的开始状态和事务的结束状态是不一致的.
	
	一致性是事务的最终目的，原子性、隔离性、持久性都是为了实现一致性。数据一致性啊等等
	
	事务的隔离级别：脏读 幻读 不可重复读
	脏读又称无效数据读出。一个事务读取另外一个事务还没有提交的数据叫脏读。
	不可重复读是指在同一个事务内，两个相同的查询返回了不同的结果。
	幻读，读取的记录数量前后不一致
	
	<tx:annotation-driven>配合注解使用更加快捷
	
	Spring的TransactionTemplate就是一种编码式事务，注入容器 或者启动初始化，在支付系统中就是这种方式
	
	contextloaderlistener是servlet的监听器，用来加载除dispatcherservlet创建的上下文以外，加载其他的配置
	文件到spring应用的上下文中，
	<listener>
		<description>spring监听器</description>
		<listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
	</listener>
	默认加载  /WEB-INF/applicationContext.xml这个配置文件。
	一般我们人工指定，
	<context-param>
		<param-name>contextConfigLocation</param-name>
		<param-value>	
				classpath:config/spring.xml,
				classpath:config/spring-mybatis.xml,
				classpath:config/spring-dubbo.xml,
				classpath:config/spring-threadpool.xml
		</param-value>
	</context-param>
	
	前段传参数到controller
		@requestParam不是必须的，默认是绑定到同名查询参数上
		
		
	通过重定向到另一个页面我们能够避免表单的重复提交
	
	
	
	文件功能  apachecommonsIo的fileUtils操作工具类，写到本地服务器或者上云
	
	soa的核心理念是，应用程序可以并应该被设计成依赖于一组公共的核心服务，而不是每个应用都重新实现相同的功能
		
	rpc是面向服务的，并关注行为和动作；rest是面向资源的，强调描述应用程序的事务和名词
	
	rest就是将资源的状态以最合适的形式从服务器端转移到客户端
	
	就简单理解：基于url的web服务
	@responsebody注解完全绕过视图解析，返回显示
	
	
精通Spring 4.x  企业应用开发实战		挺好的，可以复读
内容还可以，可以多读几遍
quartz不是很透，简单了解了下。

	spring 主要分为5个模块：
		1.IOC	依赖注入
			BeanFactory接口是spring框架的核心，实现了容器许多核心的功能
			Context模块构建于核心模块之上，其中applicationcontext是该模块的核心接口，扩展了BeanFactory，添加了bean生命周期控制，jndi获取，资源加载等。
		2.AOP
			区别于aspect框架，不是同一个事物框架
			借助该功能，实现了声明式事务的功能
		3.数据可访问和集成
		4.web及远程操作
			可通过listener或Servlet初始化Spring容器，将其注册到web容器中 
		5.测试框架

	repository 一般有中央仓库，公共仓库，私有仓库以及本地仓库
	
	ant 风格资源地址匹配：
	?: 匹配文件名中的一个字符
	*：匹配文件名中任意字符	
	**：匹配多层路径
	
	实际上applicatincontext就叫做spring容器,是面向spring框架的开发者，这个也可以简称为spring容器
	BeanFactory是面向spring框架的基础设施，面向spring本身。是ioc容器。
	
	beanfactory会缓存bean实例到ioc容器中，缓存原理是一个hashmap实现的缓存器，key是beanname，value是单例bean
	bean的初始化动作发生在第一个调用时，
	ApplicationContext是BeanFactory的一个不补充详细，是面向开发者的。实际开发中普遍使用前者，后者功能比较少

	如果配置文件放在类路径下，则优先考虑使用classpathxmlapplication(classpath:...)
	如果配置文件放在文件系统路径下，则考虑优先使用fileSystemXmlApplication实现类(file:...)

	ApplicationContext和BeanFactory初始化不同：
	BeanFactory：初始化容器时，没有实例化bean，第一次访问才实例化目标bean
	ApplicationContext：在初始化应用上下文时就实例化所有的单例bean，时间稍微长点

	从Spring 3起，JavaConfig功能已经包含在Spring核心模块，它允许开发者将bean定义和在Spring配置XML文件到Java类中。就是基于@configuration和@bean，区别于以往的xml配置
	使用AnnotationConfigApplicationContext可实现基于Java的配置类加载Spring的应用上下文。手工注册配置类。避免使用application.xml进行配置。相比XML配置，更加便捷。
	
	webapplicationcontext可以获得servletcontext引用,（扩展了applictioncontext,可以通过contextloaderlistener初始化）整个web上下文将作为属性放置到servletcontext中，这样web应用就可以访问spring应用上下文。
	
	父子容器，子容器可以访问父容器中的bean，反之不行，在容器内bean id唯一，但子容器可以有一个和父容器id相同的bean

	BeanPostProcessor接口的作用是：
	我们可以通过该接口中的方法在bean实例化、配置以及其他初始化方法前后添加一些我们自己的逻辑。动态代理和aop都是通过该接口实现的
	
	PostConstruct也是BeanPostProcessor的一个实现类加载识别的
	BeanPostProcessor是spring的后处理器。工厂后处理器是容器级的，仅在应用上下文初始化时调用一次，完成配置文件的加工处理工作。
	
	
	该接口的实现类为“后处理器”，一般不由bean本身实现，当spring容器创建bean的时候，可以合理对bean进行加工处理。也就是代理的思想
	
	bean级生命周期的几个常用控制接口，
		beannameaware：是通过set注入当前bean在容器中的bean_ID，
		beanfactoryaware：让bean获得配置文件中对应的配置名称
		InitializingBean
		DisposableBean

	一般情况不用上述接口，但是BeanPostProcessor很重要，
		
	spring是有个容器缓存池，在单例模式中是打开。
	applicationcontext启动时，将配置文件中的<bean>生成一个beandefinition对象（是<bean>在spring容器中的内部表示），一个个的BeanDefinition形成了bean的注册列表。
	
	
	容器后处理器：	实现BeanFactoryPostProcessor接口，在spring容器启动之后会查找实现了BeanFactoryPostProcessor接口的bean，并实例化调用postProcessBeanFactory()方法。需加入@component。只处理实现相应接口的地方
	bean后处理器：	实现BeanPostProcessor接口，在容器创建了bean对象实例之后，调用bean的初始化方法之前后会调用相关方法。需加入@Component。统一处理的地方

	
	spring提供了用于启动webApplicationContext的web容器监听器：ContextLoaderListener,通过容器的上下文参数contextConfigLocation获取Spring配置文件的位置
	
	
	xml schema 
		bean配置信息定义了bean实现和依赖关系，spring内部建立bean注册表，根据注册表，加载相关的bean，并放在bean缓存池中，供外层的程序调用
		
		xml的schema中的  xmlns是默认命名空间，xmlns:xsi是标准的命名空间，xmlns:aop这种就是自定义的命名空间（1.指定命名空间的名称，2.指定命名空间的Schema文档格式文件的位置）
		其中aop就是命名空间的别名（用以区分文档后面的元素），对应的还有权限定名和schema文件地址。
	
		命名空间使用全限定名，一般使用一个引用的url地址指定命名空间对应的schema文件。
		在spring4中，配置的schema文件放置在各模块jar文件内一个名为config的目录下。作为各个依赖jar的功能单独存放。
		
		如果在<bean>中没有指定bean的id，那么自动将全限定类名作为bean的名称
		<bean>中使用的<property>,就是set注入，需要在类中有对应的set方法
	
	
	
		可注入多种对象，list、map、set、实体类、property等
		1.java中的属性命名规范：xxx属性对应setXxx()方法，但是重点是：变量的前两个字母要么全大写，要么全小写，否则xml中set注入会报错。比如iDCode和iCcard。
		2.使用构造函数，类中必须要存在有参构造，可以显示指定入参顺序，使用index 和type配合使用，复杂属性类用ref引用
		3.工厂方法注入  不推荐
		
		循环依赖问题
			spring对构造函数配置的bean实例化前提是，入参引用需要准备就绪，如果两个bean都采用构造函数注入，会发生循环依赖，改为属性注入即可
		
		bean之间的可以继承，依赖(depend on)，引用(ref)
		
		在两个xml中有包含关系的时候，加载主动包含的那个xml即可
		
		因为spring利用aop和localthread功能，对非线程安全的变量特殊处理，是器变为线程安全的类，所以spring将bean默认作用域为singleton。
		
		spring的 applicationContext启动时，会自动实例化所有单例bean，并缓存在容器中，
		在默认情况下，spring容器启动不实例化prototype的的bean。多例bean交给调用者后，不在管理生命周期
		
		FactoryBean方法在spring中挺重要的，使用getbean是调用了对应的getobject方法
		
		不管是xml还是注解，他们都是表达bean定义的载体，本质都是为spring容器提供bean定义的信息。
		
		使用autowired,如果有一个以上的bean，则可以通过@qualifier注解限定bean的名称
		对集合类型的注入，会将符合类型的所有bean都注入到集合中，这个在注入批量插件时有用
		
		使用<bean>配置的时候，可通过init-method指定初始化方法，对应的注解使用@postconstruct。
		
		bean创建过程：
		spring先调用bean的构造函数实例化，再执行@autowired注入，然后执行@postConstruct初始化。
		
		@configuration 配合@bean 替代xml中配置，并且@#configuration 注解本身也相当于标注了@component,可以其他类中直接注入（也可以被xml扫描进入）
		*****spring会对配置类所有标注@bean的方法进行aop增强(需要使用到spring-aop和cglib)，将堆bean的生命周期管理的逻辑植入进来，即不是简单执行方法逻辑，而是从容器中返回相应的bean单例*****
		
		
		xml可以扫描@configuration配置类，@configuration配置类也可以通过importResource,加载xml，这两种bean定义可以智能装配
		
		bean三种配置方式
		XML配置和注解配置方式向结合的开发方式，一般不推荐使用基于Java类的配置方式(提供了bean实例化逻辑，适用复杂的bean实例化场景)
		
		  @Bean
		  public Person personOne() {
			  return new Person(); //实例化的逻辑
		  }
		  
		defaultlistablebeanfactory是一个可以独立使用的ioc容器，可以编码实现动态注入bean。一般也用不到
		
		spring扩展自定义标签，spring中自定义组件标签(定义然后解析，了解就行，暂时用不到)
			1.采用xsd描述自定义标签的元素属性
			2.编写bean定义的解析器
			3.注册自定义标签解析器
			4.绑定命名空间解析器
			
		
		spring中的beanDefinition是注册bean的定义(是配置文件中<bean>在容器内部的表示)，并在beanDefinitionRegistry中注册(相当于是spring配置信息的内存数据库，后续操作直接从中读取配置信息，一般容器启动时加载解析，除非容器刷新或者重启，信息不会发生变化，也可以编程调整)，
		
		cglib采用底层的字节码技术，创建一个类的子类，在子类中采用方法拦截的技术拦截所有父类方法的调用，并顺势植入横切逻辑
		不能对目标类中的final或者private方法进行代理。
		通过切面将切点和advice增强组装起来，aop就是负责实施切面的框架，将切面定义的逻辑织入切面指定的连接点
		关键点 1.定位连接点   2，增强中编写切面代码 说白了就是定位切入点，将逻辑织入
		
		手工实现代理 ，一个个bean很麻烦，spring有自动代理的机制
		
		spring提供了自动代理机制，让容器自动生成代理，使用beanPostProcessor来实现（自动在容器实例化bean时为匹配的bean生成代理实例）
		在内部调用方法的时候没有走aop代理，需要注入自身的bean才能实现aop代理的功能，事务方法调用的问题
		
		spring提供多种方式访问数据源，dao，jpa等，这些支持类都继承于dao.support.DaoSupport类，DaoSupport类实现了InitializingBean接口，在afterpropertiesSet接口方法中检查模板对象和数据源是否被正确设置，否则抛出异常
		所有支持的类都是abstract的，其目的是希望被继承使用，而非直接使用。
		
		创建数据源的三种方式，
		1.xml配置一个数据元
		2.使用jndi
		3.代码创建数据源，DriverManagerDataSource(没有提供池化连接，适合单元测试用)
		
		事务的四个特性中，数据"一致性"是最终目标其他特性都是为达到这个目标而采取的错失、要求或手段
		
		数据库中的锁
		根据锁定对象的不同分为
			表级锁
			行级锁
		从并发事务锁定的关系上看：
			共享锁，又称为读锁，获得共享锁之后，可以查看但无法修改和删除数据。
			排他锁，又称为写锁、独占锁，获得排他锁之后，既能读数据，又能修改数据。
			
		mysql默认的事务处理级别是'REPEATABLE-READ',也就是可重复读
		
		insert、update、delete、select for update 都会隐式采用必要的行锁定
		
		jdbc2.0中事务最终只能有两个操作：提交和回滚。在jdbc3.0（java1.4）后引入了新特性:保存点（savepoint），可以将事务分割多个阶段，方便指定回滚到事务的特定保存点。这个特性一般用的也不多
		事务只能被提交或者回滚(或回滚到某个保存点后提交)
		
		spring通过各种模板类降低了开发者使用各种数据持久化技术的难度，模板类使用threadlocal可以在无需线程同步情况下实现线程安全。
		
		threadlocal，并不是一个线程，是保存线程本地化对象（即本地线程变量副本）的容器，属于当前线程的专有属性，与其他线程相隔离
		可能被多个线程共用一个实例，但是运行时是使用各自的线程本地副本
		这个变量一般是跟着private tatic用的，在一个共同的外部类使用threadlocal保存资源。
		实现原理：
			在Threadlocal类中有一个Map，用于存储每个线程的变量副本，key-线程对象，value-对应线程的变量副本
		
		使用同步机制要求：1.变量读写时间，2.锁定对象的时间 3.释放对象的时间
		同步机制：		时间换空间，访问串行化，对象共享化。同一份变量，排队
		threadlocal：	空间换时间，访问并行化，对象独享化。不同变量副本，不用排队
		
		spring事务管理spi的抽象层主要包括3个接口，分别是
		platformtransactionmanager:  负责commit或者rollback事务
		transactionDefinition: 定义了传播属性，隔离级别等
		transactionStatus: 代表事务的具体运行状态，使得异常回滚事务的方式更具可控性，继承了savepointManager接口
		
		
		spring为不同的持久化框架提供了platformtransactionmanager接口的不同实现类。 jpa、datesource等manager
		
		在事务的注解上，方法注解会覆盖类上的该注解。
		
		没有配置事务管理的情况，直接就是数据源的自动commit持久化到数据库（）。
		没有事务管理的情况下，dao照样可以顺利进行数据操作。
		
		
		分层是层次清楚，特殊的可以一个类就有三层合一，可以做到事务和dao 和controller简化，一般测试用吧
		分层只是一种参考的开发模式，并非是事务管理工作的前提条件
		
		
		spring的事务管理器是通过线程相关的threadlocal来保存数据访问基础设施(Connection)，再结合Ioc和Aop实现高级声明式事务的功能。
		spring通过threadlocal将bean无状态话，可以运行在多线程环境中。
		
		只有public修饰的接口才能实现jdk动态代理，但是public static也不行
		由于final static private 修饰方法不能被继承，所以不能ciglib动态代理
		这两种只是不能启动事务，但是可以工作在外层的事务中
		在一些简单的查询中jdbcTemplate也是方便使用的
		
		**********
		spring事务和数据库连接：
			当spring事务方法运行时，会产生一个事务上下文，
			该上下文在本事务执行线程中针对同一个数据源绑定了一个唯一的数据连接，所有被该事务上下文传播的方法都共享这个数据连接
			这个数据连接从数据源获取到返回给数据源都在spring的掌控之中。使用安全。
			
			
		spring中手工获取数据库连接，有自带的工具类,dataSourceUtil,事务环境下(即有事务注解标注)通过这个获取数据连接。尽可能使用jdbctemplate等模板进行数据访问操作，避免直接获取数据连接的操作
		
		建议尽量少用数据库的自增键，外键，触发器，存储过程，数据库函数等高级功能，让数据库只负责数据存储和查询
		（在进行表设计时，只应关注表空间、索引、非空限制及唯一值限制等和存储查询相关的特性），不要让它负责业务逻辑，业务逻辑处理应在应用层中进行
		
		场景：不但要求单个系统内表主键唯一，还要全局内是唯一，类似数据集中汇合。使用自增就不合适了。这时适合采用应用层主键方案。
				候选的主键方案是采用分段长整型编码方案。将主键编码分段，这样可以创建一个全局唯一的整数型主键值
		
		每个mybatis应用程序都以一个sqlsessionfactory对象的实例为核心。
		编写好的dao接口，1.通过sqlSessionTemplate.getMapper获取实例(需要在xml中配置好对应的sqlSessionTemplate bean)
						 2.使用mapperscaner 扫描生成接口实例
						 
		mybatis-spring中mapperScannerConfigurer,可以将映射接口直接转换为spring容器中的bean，即可注入service使用。
		扫描basepackage所指定的包下所有接口类（包括子包），如果在sql映射文件中定义过，则将他们定义为一个spring bean。
	
		dao的设计
			dao基类的设计：使用通用baseDao<T>设计基类，将常用方法封装，后续子dao继承。
			
		缓存命中率=从缓存中读取的次数/总读取次数
		
		java对象的缓存和序列化是息息相关的，一般情况下，需要被缓存的实体类需要实现seralizable，这样jvm才可以对其对象进行序列化。
		
		job中有内存化任务（默认策略） 和 持久化任务
		
		spring中使用quartz, jobDetail  trigger   scheduler,schedulerFactoryBean允许用户将quartz配置文件中的信息转义到spring配置文件中
		
		spring api 中  requestContextHolder能在controller中获取request 和 session，但是需在web.xml中配置requestcontextlistener
		
		xml 和java对象关系比较近的是xstream, 是java 对象和xml之间的一个双向转换器。
		xstream可以 别整dom xpath（复杂的xml处理模型） 啥了   费劲
		
		xml 和 json都是数据交换的一种规范。但是在web service中 xml用的比较多
		
		
-- 临时记录		
	编程式手工回滚  TransactionAspectSupport.currentTransactionStatus().setRollbackOnly()
	从上面可以看出主要检查一下几个属性，是否都有：
		transactionAttributeSource 事物属性源，我们所有的method对应的事物配置都在这里
		transactionManager 我们执行的方法要使用的transactionManager
		beanFactory 从spring中找到配置
		如果这些都有值的话，那么就完成了我们的这个类基本功能的所有属性要求，就可以使用TransactionAspectSupport(手工回滚)。
		这里暂定是需要加上事务注解支持的，不然缺少transactionAttributeSource。

	
			
		
	